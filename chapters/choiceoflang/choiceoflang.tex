\chapter{Choice of model, programming language and library}

\section{Selection of theoretical model}
\gls{csp} vs actors vs join calculus vs pi calculus etc.  Why I think one of them is the right choice

Message passing as discussed here is different to the message passing of the Message Passing Interface (how?)

\begin{itemize}
    \item Synchronous vs asynchronous message passing?
    \item Actors
    \item Join-calculus
    \item Pi calculus
    \item Communicating Sequential Processes
    \item Shared memory only
    \item Reactive approach?
\end{itemize}

\subsection{Why not Actors?}
Of the many theoretical models for concurrency, perhaps the two most rooted in concepts of individual \glspl{prox} passing messages between themselves are \gls{csp} and Actors.  On paper, the key difference between them is that \gls{csp} involves \glspl{prox} \emph{synchronously} exchanging messages through channels, which need not be associated with a particular \gls{prox}, whereas Actors \emph{asynchronously} exchange messages which are placed directly in their own mailbox.

% In general, asynchronicity is considered preferable, because it permits the \glspl{prox} to process at their own pace, without having to wait for another 

In practice, \gls{cml} has a major advantage in terms of resource requirements.  Actor implementations usually can support perhaps \num{100 000} or so individual actors per \si{\gibi\byte} of memory, but \gls{cml} implementations can stretch into the millions \cite{Butcher2014}.  This arises because there is no need to provide a mailbox to and store an unbounded number of messages for each \gls{prox}.  Channels and events do take a small amount of memory, but this has been found to be on the order of tens of bytes \cite{Reppy1991}.  Furthermore, it has been shown that, to a certain extent, the two can be done away with when operating in a parallel fashion \cite{Reppy2007a}.

Move the above into the introduction perhaps?

\subsection{Beyond Go}
Go is the obvious shared-memory message-passing language at the time of writing, but it doesn't have the full complement of \gls{cml} primitives (instead, it rougly corresponds to \gls{csp}).  For this reason, this work needs to consider far beyond simply Go (or indeed, many other equivalent options).

\section{Requirements}
% Requirements:
% \begin{itemize}
%     \item Must support \gls{csp}/Pi Calculus/etc. approach.  In particular, needs to enable multi-threaded, parallel message passing.  Should have some concept of channels or rendezvous, but needs to support more than just that.  I.e. needs to support the actual \gls{csp} approach/\gls{cml} features.  And needs to be highly scalable.
%     \item Needs to support tail call optimisation/tail recursion.  Or at least has a strong and clear path to trampolining in order to simulate TCO.
%     \item The message passing must be \emph{extremely} lightweight.
%     \item \emph{Must} have good linear algebra capabilities somehow
%     \item Comes with some ability to work with common image formats -- this is more a convenience than strictly necessary, since under normal circumstances these images will be coming through just as numeric arrays or similar, but it'll make testing things out a lot easier.
%     \item On the above note, not only should it be able to do IO, but it would be good if the library has things like histogram equalisation built in.  Not actually necessary though, since I could always write a quick command line tool to do that for me.
%     \item Preferably, has some degree of FFI/interop with C
%     \item Ideally includes some capacity to support GPU programming with CUDA, OpenCL, OpenGL etc. or at least has good C/C++ interop so that one can call libraries written in those languages (OpenCL 1.2 support is strongly to be preferred, as that's the best that the RPi can support, with the VC4CL library -- this may not be true later on, with the release of the RPi 4 Model B, but certainly VC4CL won't be there yet)
%     \item On the same line as above, the language really needs to make some form of vectorization available (better if it can do some automatically, but I probably will want the ability to control it manually also)
%     \item Probably doesn't necessarily need terribly strong concepts of typing to be honest, since almost all values that will be used will be numeric -- much more important would be memory safety
%     \item Still somewhat under active development/being supported
%     \item \emph{Preferably} not just someone's toy research language
%     \item If I'm (roughly) going to be treating every pixel as a separate computing unit, then the individual units must be extremely lightweight also.  Instantiation time isn't too big a deal, as that can be considered to be amortised, but it needs to be possible to manage a boatload of them.  Probably an argument against actors.
%     \item Must be able to be used across Linux implementations, as the embedded systems pretty much all use some form of Linux.
%     \item Needs to be able to produce native, \emph{dependency-free and standalone} executables \emph{for both x86-64 and ARM} - anything using a big VM will probably be too heavyweight (not definite though)
%     \item It would be better if there are already high quality implementations of stereo matching algorithms available for the given language, though that is not necessarily the be-all and end-all.
%     \item Also needs to have some degree of viable support for optimisation techniques such as gradient descent/Levenberg-Marquardt/RANSAC
% \end{itemize}

\subsection{Strict Requirements}
If a possible option does not meet even one of the below, it will not be considered further.

\begin{itemize}
    \item Suitable support for \gls{csp}/\gls{cml} style concurrency.  At a minimum, not only must there be capacity to send and receive over channels, but furthermore selecting over channels is \emph{mandatory}.  Simply having channels and the ability to select over them is the bare minimum required, but it does not make something a full \gls{cml} implementation.  The other combinators (e.g. \texttt{wrap} \& \texttt{guard}), and the ability to compose them, must be provided for it to be a full \gls{cml} implementation.  The message passing mechanics themselves must be lightweight, in terms of memory requirements and the number of instructions that need to be executed.
    \item Support of last-call optimisation, or an equivalent capability (this somewhat is implied by the above).
    \item Currently supported, or at least receiving regular maintenance
    \item Almost goes without saying, but includes some sort of green threads/fibers system, so that all the concurrent processes can be scheduled onto the processors efficiently.  This system must operate across multiple cores when they are available.
    \item Support for data-parallel programming, such as CPU vector instructions and/or OpenCL, in some capacity (either explicit or compiler-done).  The ability to use other frameworks and standards such as OpenMP, OpenACC or CUDA would be a bonus.
    \item Available for `standard' Linux distributions, such as those derived from Debian (e.g. Ubuntu, Mint) or Red Hat Enterprise Linux (e.g. Fedora, CentOS).  \emph{Most} languages target/support Linux in general, and thus this shouldn't be an issue typically.
\end{itemize}

\subsection{Desirable Qualities}
The absence of one or more of the below requirements will not necessarily disqualify an option, but having more of them will be a benefit.

\begin{itemize}
    \item Support for working with common image formats.  If need be, it should be relatively trivial to open an image elsewhere and convert it to something which I could parse relatively simply, like a .ppm/.pgm file, or some sort of binary file that is just all the pixel values jammed together.
    \item Support for common standard image processing routines.  Again, not necessarily needed, but it would save me the effort of implementing them if they turn out to be required.
    \item Support for compilation to native executable binaries, rather than relying on a virtual machine.
    \item High-quality implementations of stereo matching algorithms already available.  This is preferred simply so that it provides an easy comparison between what is implemented for this work against what someone else has created (probably using more of a traditional imperative style).  Using the same language for the comparisons helps to remove uncontrolled variables that could be confounding factors.
    \item Easy inter-operation with C, or equivalent (e.g. a Foreign Function Interface to C).
    \item An integrated or otherwise easy-to-use benchmarking system.
\end{itemize}

\section{Possible options}
Languages and their relevant libraries

% See also \url{https://github.com/kevin-chalmers/cpa-lang-shootout} and \url{www.teigfam.net/oyvind/home/technology/135-towards-a-taxonomy-of-csp-based-systems/} and \url{https://arrayfire.com/}\footnote{On top of ArrayFire, there's also Thrust \url{https://thrust.github.io/}  and ConcurrencyKit \url{http://concurrencykit.org/} and LibCDS \url{https://github.com/khizmax/libcds}}.  ArrayFire is the only one that appears to have bindings for any other languages besides C/C++, however.  Also, Furthark \url{https://futhark-lang.org/}

% \begin{itemize}
% \item \gls{cml}/\gls{csp}/Pi calculus
% \begin{itemize}
    % \item Standard ML -- it seems that MLTon is still under development, and it provides a recent implementation of Standard ML and \gls{cml}.\footnote{see \url{http://mlton.org/ConcurrentML}}
    % \item \sout{Concurrent C?  Appears to be loooong dead.}
    % \item Concurrent Haskell -- It's not entirely clear what the status of \gls{cml}/\gls{csp} style stuff is in Haskell.  Most up-to-date part seems to be Communicating Haskell Processes,\footnote{\url{https://hackage.haskell.org/package/chp}} though that appears to have been unmaintained for a few years.  See also Transactional Events.\footnote{\url{https://www.cs.rit.edu/~mtf/research/tx-events/}}
    % \item \sout{Occam?  Looks like Occam-Pi is the only version that's even close to current, and it doesn't look like that's under active development}\footnote{\url{https://github.com/concurrency/kroc}}
    % \item \sout{F\# with Hopac (Hopac seems to be fairly well no longer under development) and CoreRT.\footnote{For useful CoreRT references, see \url{https://github.com/dotnet/corert}, \url{https://github.com/dotnet/corert/tree/master/samples/HelloWorld} and \url{https://github.com/FoggyFinder/FSharpCoreRtTest}}}  Could possibly use System.Threading.Channels myself, it's apparently super-fast.\footnote{See e.g. \url{https://ndportmann.com/system-threading-channels/}}  Could perhaps alternatively use the TPL Dataflow library (F\# utility wrappers here:  \url{https://github.com/TheAngryByrd/FSharp.TPLDataflow})
    % \item Fibers in Guile Scheme
    % \item OCaml with Events module
    % \item SML/NJ is still going apparently\footnote{\url{https://www.smlnj.org}} although I'm not sure if \gls{cml} is up to date enough to work with it.  Bigger problem is that I \emph{think} it doesn't support parallelism at all.  There's also PolyML (\url{https://www.polyml.org/}) but it doesn't appear to include \gls{cml} at all.
    % \item Clojure with core.async using an AOT compiler or lightweight JVM.  GraalVM\footnote{\url{https://www.graalvm.org/}} appears to offer the former, while OpenJ9\footnote{\url{https://www.eclipse.org/openj9/index.html}} is apparently the latter, but as of writing it appears that neither of them supports targeting ARM (looks like Graal does kinda now).  See \url{https://neanderthal.uncomplicate.org/} and \url{} apparently for fast linear algebra operations.  There's also \url{http://docs.paralleluniverse.co/quasar/}, which apparently basically does Go fibers in Java - but it hasn't been updated in a while, and it looks like the company behind it might have gone out of business.
    % \item Rust\footnote{see \url{https://doc.rust-lang.org/book/ch16-02-message-passing.html}} with Crossbeam and its subcrates -- see also Tokio and Actix, as well as Desync\footnote{\url{https://github.com/logicalshift/desync/}}, Grease\footnote{\url{https://github.com/cambridgeconsultants/grease}} and Threadpool\footnote{\url{https://github.com/rust-threadpool/rust-threadpool} and see also \url{https://gsquire.github.io/static/post/a-rusty-go-at-channels/}} plus \url{https://gluon-lang.org/} (Gluon is a Haskell-y version of Rust, essentially).  Also \url{https://crates.io/crates/single_value_channel/1.2.1}.
    % \item Manticore is kinda sorta a successor to SML/NJ apparently, with a strong focus on \gls{cml}-style parallelism\footnote{\url{http://manticore.cs.uchicago.edu/}}
    % \item Go?  \sout{Apparently Crystal has a very similar \gls{csp}-derived built-in basis for Concurrency.}\footnote{While Crystal has similar built-in support for channels like Go, it apparently doesn't yet do parallelism - see near the start of \url{https://crystal-lang.org/reference/guides/concurrency.html}}  \url{https://www.gonum.org/}  Go's support for SIMD seems to be kinda clunky:  \url{https://medium.com/@c_bata_/optimizing-go-by-avx2-using-auto-vectorization-in-llvm-118f7b366969}, \url{https://www.reddit.com/r/golang/comments/ep4vyp/question_how_do_you_implement_simd_in_go/}, \url{https://goroutines.com/asm}, \url{https://golang.org/doc/asm}, \url{https://github.com/minio/simdjson-go}, \url{https://github.com/golang/crypto/tree/master/blake2b}, \url{https://www.reddit.com/r/golang/comments/42zppi/is_there_any_way_to_use_simd_intrinsics_in_gccgo/}.  Could an events library over the top of what's in Go be viable?
    % \item Is there anything in C++?  (Couldn't find anything when I looked the other day)\footnote{but see \url{https://docs.microsoft.com/en-us/cpp/parallel/concrt/concurrency-runtime?view=vs-2017} which is Windows only I think, also \url{https://www.cs.kent.ac.uk/projects/ofa/c++csp/} and \url{https://stackoverflow.com/questions/218786/concurrent-programming-c}}.  Also, there are a number of Boost libraries which come close, but none of which do precisely what I need:  \url{https://www.boost.org/doc/libs/?view=category_concurrent}.  MicroC++ (\url{https://plg.uwaterloo.ca/~usystem/uC++.html}) is similar.  Also, Stackless Coroutines introduced channels, but it looks like that is a dead experiment:  \url{https://github.com/jbandela/stackless_coroutine/tree/channel_dev} \& \url{https://github.com/CppCon/CppCon2016/blob/master/Presentations/Channels%20-%20An%20Alternative%20to%20Callbacks%20and%20Futures/Channels%20-%20An%20Alternative%20to%20Callbacks%20and%20Futures%20-%20John%20Bandela%20-%20CppCon%202016.pdf}  Actually, Boost:Fiber \emph{might} provide what I need.  See its channels, and \texttt{when_any} construct.
    % \item \sout{Smalltalk -> Objective-C \& Parallax (all of these have been out of active development for too long, but they probably will make good references)}\footnote{see \UrlBreaks{https://stackoverflow.com/questions/6145421/what-other-programming-languages-have-a-smalltalk-like-message-passing-syntax}}
    % \item Pharo(?)\footnote{\url{http://www.pharo.org/web}} -- a modern version of Smalltalk, apparently.  Also, Squeak.\footnote{\url{https://squeak.org}}
    % \item Ada (something about rendezvous).  Supposedly has a proper real-time focus, might be worth looking at.
    % \item Kotlin.  Has channels, and apparently an (experimental) implementation of selection:  \url{https://kotlinlang.org/docs/reference/coroutines/channels.html} ... ``Only single-threaded code (JS-style) on Kotlin/Native is currently supported.'' (\url{https://github.com/Kotlin/kotlinx.coroutines})
% \end{itemize}
% \item Join Calculus
% \begin{itemize}
%     \item F\# with Joinads
%     \item JOCaml
%     \item Scala with Chymist
%     \item \sout{Polyphonic C\#/C\(\omega\)}
% \end{itemize}
% \item Actors
% \begin{itemize}
%     \item Erlang / Elixir
%     \item Halide with message-passing?  There's \url{https://doi.org/10.1016/j.sysarc.2017.10.005}, \url{https://doi.org/10.1007/s11265-017-1283-1}, and Aaron Epstein's Masters Thesis at MIT, ``A Distributed Backend for Halide'', but with regards to message passing they all seem to focus on MPI.%  I couldn't find anything on \gls{cml} style in Halide.
%     \item \sout{Don't forget Pony...  (almost certainly not stable enough at this point)}
%     \item Rust with Actix
% \end{itemize}
% \item Julia?\footnote{\url{https://docs.julialang.org/en/v1/manual/parallel-computing/index.html} \& \url{https://docs.julialang.org/en/v1/manual/control-flow/\#man-tasks-1}} -- it is supposed to be very close to mathematical notation, so that's a big plus.  Can't find anything suggesting that there's a \gls{cml}/\gls{csp}/Pi calculus type thingy out there yet, though they do have lightweight threads and channels.  Plus, parallelism is apparently not really a big thing in it yet.
% \item What of the LMAX Disruptor approach?\footnote{\url{https://github.com/LMAX-Exchange/disruptor}} -- looks like that would have me working on the JVM, so probably Java/Scala/Kotlin/Ceylon/Clojure/probably something else is out there too.  There is a .NET port of it too.\footnote{\url{https://github.com/disruptor-net/Disruptor-net}}  Definitely looks like it would be worth investigating, but it doesn't follow the \gls{csp} model, so it is out-of-scope for this particular work.  Also \url{https://github.com/lthibault/turbine}.
% \item Scala with Chymist \sout{(there was also JCSP (\url{https://www.cs.kent.ac.uk/projects/ofa/jcsp/}), which seems to be long dead now, but see Communicating Scala Objects, though I can't find an actual implementation of that available anywhere)}
% \item \sout{SCOOP (Betrand Meyer) \& Eiffel (too OO, not really close enough to \gls{csp} it looks like)}
% \item \sout{Does ATS \cite{Shi2013} include anything? (couldn't find anything)}  Or D?\footnote{relevant: \url{http://www.informit.com/articles/article.aspx?p=1609144} and \url{https://wiki.dlang.org/Go_to_D}}  Or Nim?  \sout{Idris?  C++?}\footnote{There's C++CSP, but despite the most recent paper apparently being published in 2016, I couldn't find anywhere that actually hosted a usable version.  Could only find \url{https://www.cs.kent.ac.uk/projects/ofa/c++csp/doc/index.html} \& \url{https://github.com/olahol/cpp-csp}, neither of which are complete or recently-updated.}  Looks like I should check C++ Concurrency in Action, 2nd Edition -- it'll probably cover this if anything does (update: it doesn't).
% \item Further C++ \gls{csp} libraries:  SObjectizer\footnote{\url{https://stiffstream.com/en/products/sobjectizer.html}}, libmill\footnote{\url{http://libmill.org/index.html}} \& libdill\footnote{\url{http://libdill.org/index.html}}, LibProxC++\footnote{\url{https://github.com/edvardsp/libproxcplusplus} (also LibProxC \url{https://github.com/edvardsp/libproxc})}.  High Performance ParallelX\footnote{\url{http://stellar-group.org/libraries/hpx/}} claims to be a replacement to/improvement over \gls{csp} (see \url{https://stellar-group.github.io/hpx/docs/sphinx/tags/1.4.0/html/why_hpx.html#what-is-hpx}).
% \item \sout{How can strong typing be used beneficially? (if at all?)}
% \item \sout{Probably don't need transactional memory (?)}
% \item \sout{Lock-free is better than locking, but how to achieve?  Is that a relevant consideration here?  In theory at least, should be able to leave that up to the implementation I'm using.}
% \item \sout{Can F*, Adga, Coq or similar be of any use here? (not clear how)}
% \item \sout{Reppy has recently been working on Diderot, ``a Parallel Domain-specific Language for image analysis and visualization'', but it seems like that probably isn't what is needed here.}  Diderot doesn't seem to be ready for others to play with yet.
% \item Ferret\footnote{\url{https://ferret-lang.org}} appears to be a lot of what is needed, but it doesn't have its own channel/message-passing implementation, and I don't think it interoperates with Clojure.  Not entirely clear how one uses multi-threading with it, except possibly just calling out to C++.
% \item Single-Assignment C.\footnote{\url{http://www.sac-home.org/} \& \url{https://github.com/SacBase}}  It looks like development on it has more-or-less stopped in the past couple of years, but it \emph{might} still be suitable for my purposes.  It appears to come with some built-in support for image processing (e.g. parts of the standard lib directed towards using .pgm files), but I'm struggling to see anything on concurrency/parallelism -- it might be the case that all of that is done implicitly, e.g. there's \url{https://github.com/SacBase/NASParallelBenchmarks}, but I couldn't see any explicit handling of parallel constructs in it.
% \item Checked Dart, but it seems to be focused on making apps with responsive UIs.  It has a concept called `isolates' which seem to be moderately similar to fibers, but they seemingly are asynchronous only (Wikipedia explicitly compares it to Erlang).
% \item Checked Io, which is another Smalltalk-esque language, but it apparently only does asynchronous.  Not clear that it does parallelism across multiple cores, either.
% \item Checked X10, which doesn't seem to provide any sort of \gls{csp} style support, and appears to be focused primarily at HPC.
% \item Even the latest version of OpenMP doesn't seem to have anything \gls{csp}-ish.
% \item Looks like there \emph{might} be some chance to use C# for some of this stuff:  \url{https://github.com/DragonSpit/HPCsharp}, \url{https://github.com/chrisa23/fibrous}, possibly \url{https://github.com/domn1995/Marathon}.  \url{https://linksplatform.github.io/Hardware.Cpu/}, \url{https://github.com/jackmott/LinqFaster}, \url{https://gitlab.com/pomma89/object-pool}.
% \item Other ones that could be mentioned include Mozart \url{https://github.com/mozart/mozart2}, Red \url{https://www.red-lang.org/}, P \url{https://github.com/p-org/P}, OForth \url{https://www.oforth.com/}, Esterel \url{http://www.esterel.org/}.
% \end{itemize}

% Other Rust resources:  Bastion \url{https://github.com/bastion-rs/bastion} (see also it's sub-libraries Bastion Executors and LightProc); Actix \url{https://docs.rs/actix/0.9.0/actix/} (the underlying Actix system, \emph{not} Actix-Web); Greenie \url{https://github.com/playXE/greenie}, but it appears to have only just started; Rust-Executors \url{https://github.com/Bathtor/rust-executors}, though I can't work out precisely what it does.  It basically seems to say that it lets you choose between some threading runtimes; Par-Array-Init \url{https://crates.io/crates/par-array-init/0.0.5} looks like it was set up and then abandoned, but \emph{might} still be useful for my purposes; RustaCUDA \url{https://github.com/bheisler/RustaCUDA} \& Accel \url{https://gitlab.com/termoshtt/accel};  Also, Testbench \url{https://github.com/HadrienG2/testbench} and Criterion \url{https://github.com/bheisler/criterion.rs}.  Emu for OpenCL \url{https://calebwin.github.io/emu/} and Ocl \url{https://github.com/cogciprocate/ocl/tree/master}, but the latter is looking fairly abandoned.

% Other Nim resources: Memo \url{https://github.com/andreaferretti/memo}; Loop-fusion \url{https://github.com/numforge/loop-fusion}; Nim-Schedules \url{https://github.com/soasme/nim-schedules}; Shared \url{https://github.com/genotrance/shared}; Nim-Chronos \url{https://github.com/status-im/nim-chronos} (not clear that this is relevant);  Stew \url{https://github.com/status-im/nim-stew}; Stones \url{https://github.com/binhonglee/stones} (not really clear precisely what it provides); Nim-CLBlast \url{https://github.com/numforge/nim-clblast}; Nim-Optionsutils \url{https://github.com/PMunch/nim-optionsutils}; Nimterop \url{https://github.com/nimterop/nimterop}; Neo \url{https://github.com/unicredit/neo}; Nim-GLM \url{https://github.com/stavenko/nim-glm}; Memviews \url{https://github.com/ReneSac/memviews}; Nim-Curry \url{https://github.com/zer0-star/nim-curry};

%For OCaml, be sure to check \url{https://ocaml.xyz/}  (also take a look at \url{https://www.eff-lang.org/} and \url{https://github.com/kayceesrk/effects-examples})

\subsection{Ranking of of possible options}
% The ones chosen to assess \emph{must} meet all the criteria below.  If they fail even one, then they are excluded from further consideration.

% \begin{itemize}
%     \item Support for \gls{csp}/\gls{cml} style concurrency
%     \item Tail/Last call optimisation, or something equivalent
%     \item \emph{Extremely lightweight} message passing and representations of processing elements
%     \item Linear Algebra support
%     \item Support for vectorization and/or OpenCL
%     \item Maintained or under development
%     \item Usable on most Linux distributions
%     \item Can produce executable files for both x86\_64 and ARM
% \end{itemize}

The ones (that probably will be) finally chosen to assess are among:
\begin{itemize}
\item C++ with Boost:Fiber or one of the \gls{csp} libraries
% \item Clojure with core.async -- core.async seems to be a channels + selection library only
% \item Go -- base Go is channels + selection only, and there don't seem to be any full \gls{cml} libraries out there for it.
\item Guile Scheme with Fibers library -- Fibers is a full \gls{cml} library
% \item Kotlin -- Not 100\% clear.  It looks like Kotlin's coroutines go beyond just channels + selection, but if it goes to full \gls{cml}, the combinators go by different names.
% \item Manticore -- has a full \gls{cml} library
\item MLTon -- has a full \gls{cml} library
% \item Nim -- Unfortunately, Nim does not appear to have any selection over channels capability
\item OCaml with Events module -- Events is a full \gls{cml} library, but OCaml is (currently) single-core only
% \item Pharo
\item Rust with Crossbeam crate -- Crossbeam seems to be channels + selection only
\item Racket with its Sync library
\item Felix-lang (?) (\url{https://github.com/felix-lang/felix})
\end{itemize}

Big table assessing what features they in fact have goes here (?).  That can be used as the basis of choosing, say, the top 3-5 languages that seem like they would be best suited to what I want to do, and those ones can be further assessed.



Further distinguishing criteria are examined below.  These are not as critical, so if an option lacks one but has others strongly, it may still be the best choice.

\subsubsection{Support for working with common image formats}

\paragraph{C++}

\paragraph{Clojure}
Almost certainly, though I couldn't find a current library in a quick search.  JavaFX (\url{https://openjfx.io/}) provides something it seems.  There seem to be some basic classes in Java.AWT and Javax.ImageIO.  Seems like it is also possible to interact with OpenCV via Java bindings (best as I can tell).

\paragraph{Go}
Yes - built in.

\paragraph{Guile}
Yes -- at the very least Guile-CV \url{https://www.gnu.org/software/guile-cv/}

\paragraph{Racket}

\paragraph{Kotlin}
JavaFX (\url{https://openjfx.io/}) provides something it seems.  There seem to be some basic classes in Java.AWT and Javax.ImageIO.  Seems like it is also possible to interact with OpenCV via Java bindings (best as I can tell).  Also see JavaCV \url{https://github.com/bytedeco/javacv}, BoofCV \url{https://github.com/lessthanoptimal/BoofCV} and AlgART \url{https://algart.net/java/AlgART/}

\paragraph{Manticore}
Doubtful.

\paragraph{MLTon}
Unclear.  There are many old libraries around, but none of the ones found dealt with images.  Matthew Fluet has stated (via email) that he is unaware of any libraries, and has suggested using the C FFI to work with one of the C libraries that performs the task.

\paragraph{Nim}
Yes.  At least, partial (see e.g. \url{https://github.com/nim-lang/needed-libraries/issues/77}).  Looks like NiGui \url{https://github.com/trustable-code/NiGui/blob/master/examples/example_11_image_processing_cli.nim} includes some capability for interacting with images...  Also, Flippy \url{https://github.com/treeform/flippy}; 

\paragraph{OCaml}
Yes, e.g. Bimage \url{https://github.com/zshipko/ocaml-bimage} or CamlImages \url{https://bitbucket.org/camlspotter/camlimages/src/default/}.

\paragraph{Rust}
Yes.

\subsubsection{Support for common standard image processing routines}

\paragraph{C++}

\paragraph{Clojure}
Almost certainly, though I couldn't find a current library in a quick search.

\paragraph{Go}
Most likely - haven't found it, but given Go's popularity it seems highly likely.

\paragraph{Guile}
Yes.

\paragraph{Kotlin}
At least as much as Clojure it looks like.

\paragraph{Manticore}
Couldn't find any.

\paragraph{MLTon}
Couldn't find any.

\paragraph{Nim}
Yes: \url{https://github.com/numforge/laser}

\paragraph{OCaml}
Yes (some, at least).


\paragraph{Rust}
Yes.


\subsubsection{Inter-operation with C/C++}

\paragraph{C++}
N/A

\paragraph{Clojure}
It is likely possible, but not sure that it is \emph{easy}.

\paragraph{Go}
Yes, with something called `cgo' \url{https://blog.golang.org/c-go-cgo}

\paragraph{Guile}
Yes, definitely, although perhaps not in quite the same way as other languages -- one of the goals of Guile is to permit the incorporation of Guile elements into a C program.

\paragraph{Kotlin}
Yes. \url{https://kotlinlang.org/docs/reference/native/c_interop.html}

\paragraph{Manticore}
Not entirely clear, but almost certainly can be done.

\paragraph{MLTon}
Yes.

\paragraph{Nim}
Yes.  Nim actually transpiles to C, which is then compiled as normal.

\paragraph{OCaml}
Yes.

\paragraph{Rust}
Yes.


\subsubsection{Ahead-of-time compilation to native executables}

\paragraph{C++}
Yes

\paragraph{Clojure}
Kinda with OpenJ9.  Yes with GraalVM.

\paragraph{Go}
Yes.

\paragraph{Guile}
Yes, by `embedding' the Guile program into a C program.

\paragraph{Kotlin}
Yes - though it appears that only 32-bit ARM is supported for Linux right now: \url{https://kotlinlang.org/docs/reference/native-overview.html}.

\paragraph{Manticore}
Yes - though it's not clear what backend is used by default.

\paragraph{MLTon}
Has it - through GCC and LLVM

\paragraph{Nim}
Yes (in fact, they brag they're particularly good at it)

\paragraph{OCaml}
Yes.

\paragraph{Rust}
Yes.

\subsubsection{High-quality implementations of stereo matching algorithms already available}

\paragraph{C++}
Er... OpenCV?

\paragraph{Clojure}
Didn't find anything.  It seems unlikely.  I did see somewhere that there is apparently a Clojure wrapper of OpenCV, though.

\paragraph{Go}
Not sure, but it's likely.

\paragraph{Guile}
Couldn't find any.  There's presumably some in C, however.

\paragraph{Kotlin}
OpenCV if nothing else (and I didn't find anything else).

\paragraph{Manticore}
Couldn't find any.

\paragraph{MLTon}
Couldn't find any.

\paragraph{Nim}
There are wrappers over OpenCV, at least.

\paragraph{OCaml}
Couldn't find any.

\paragraph{Rust}
Didn't find any, but could well be out there.

\subsubsection{Works on x86* \emph{and} ARM}

\paragraph{C++}
Yes - GCC definitely supports ARM targets, I'm pretty sure LLVM does too.

\paragraph{Clojure}
Not 100\% clear.  It basically comes down to whether a JVM implementation supports targeting more architectures than x84-64.  It \emph{looks like} OpenJ9 doesn't support ARM, and neither does GraalVM.

\paragraph{Go}
Yes.

\paragraph{Guile}
Looks like it does x86* and ARMv7 specifically.

\paragraph{Kotlin}
It has a native compilation feature, which supports x86-64, and one of ARM32 or ARM64 I think (I have seen references to one or the other, but not both at once).

\paragraph{Manticore}
No.  x86-64 only.

\paragraph{MLTon}
Potentially, yes, if you fiddle with the GCC settings it uses.

\paragraph{Nim}
Yes (I believe it should work for whatever architectures GCC and Clang/LLVM support).

\paragraph{OCaml}
Yes.

\paragraph{Rust}
Yes.

\subsubsection{More than one individual's toy/research language, and still under active development/support}

\paragraph{C++}
Yes.

\paragraph{Clojure}
Yes.

\paragraph{Go}
Yes.

\paragraph{Guile}
Doesn't have a huge team or wealthy company behind it, but it is a central part of GNU these days, and has been in development for a long time.

\paragraph{Kotlin}
Yes.

\paragraph{Manticore}
Not really, it is a research language with a small core group, most of whom are inactive.

\paragraph{MLTon}
Yes.  It appears that development is still in progress to some degree.

\paragraph{Nim}
Yes.

\paragraph{OCaml}
Yes.

\paragraph{Rust}
Yes.

% \subsubsection{Support for optimisation algorithms}

% \subsection{Excluded options}
% The following options were investigated but excluded from consideration due to a variety of issues.  These include that they emulate a related model such as Join Calculus or Actors, but not \gls{csp}.  

% \subsubsection{Actors}
% \begin{itemize}
%     \item Erlang / Elixir
%     \item Halide with message-passing?  There's \url{https://doi.org/10.1016/j.sysarc.2017.10.005}, \url{https://doi.org/10.1007/s11265-017-1283-1}, and Aaron Epstein's Masters Thesis at MIT, ``A Distributed Backend for Halide'', but with regards to message passing they all seem to focus on MPI.%  I couldn't find anything on \gls{cml} style in Halide.
%     \item \sout{Don't forget Pony...  (almost certainly not stable enough at this point)}
%     \item Rust with Actix
%     \item \gls{mpi}
% \end{itemize}

% \subsubsection{Join Calculus}
% \begin{itemize}
%     \item \fsharp{} with Joinads
%     \item JOCaml
%     \item Scala with Chymist\footnote{\url{https://github.com/Chymyst}}
%     \item \sout{Polyphonic C\#/C\(\omega\)}
% \end{itemize}


\section{Assessment of chosen candidates}
Sample applications, and results of profiling them.  Comparison with other pre-existing implementations.

Probably want to do one or more stress tests on each system, to see how they cope, as well as see how easy it is to program with them reasonably effectively.  E.g. implementations of the median filter ala my IVCNZ 2018 paper.

\subsection{Criteria}
How to assess?
\begin{itemize}
    \item Mean runtime (minimum is suggested to be better as it more accurately reflects ONLY the process in question, but mean is probably going to happen more often in practice - particularly relevant with garbage collections)
    \item Peak \& average memory use
    \item `Code quality' measures
\end{itemize}

\subsection{Tests}

\subsection{Test results}
What applications?...  Preferably something similar to what I actually expect to be doing.  Running these on the sample input images, perhaps set up to be a stream of images (even if it is the same one over and over again - though could that advantage some algorithms or specific implementations?), while measuring relevant metrics.  %If possible, try to deploy one of them into the field in some fashion.

% \section{Heterogeneous computing}
% I.e. effective combined use of the CPU and GPU?

\section{Final language choice}
And the winner is...


\section{Appendix}
List of languages that were investigated but fell at the first hurdle, namely not meeting one of the essential requirements above.  This is not a complete list.

\begin{itemize}
    \item \texttt{Standard ML of New Jersey} with \texttt{\gls{cml}}:  The original \gls{cml} implementation was in fact intended only for concurrent programming, and not parallel.  Thus, it does not support modern multiprocessors well.  Instead, MLTon or Manticore can perhaps be used.  (MLton is single-threaded-only, it turns out)
    \item \texttt{Julia}:  Does not have support for parallelism in its channels operations.  ``The current version of Julia multiplexes all tasks onto a single OS thread.'' (from \url{https://docs.julialang.org/en/v1/manual/parallel-computing/#Coroutines-1}, accessed on 2 February 2020).  --- It \emph{looks like} the situation has changed, and Julia now supports running tasks across multiple cores.  Need to investigate further.  Seems pretty likely that it doesn't have Events, but \emph{maybe} they could be implemented with relatively little difficulty.
    \item \texttt{Concurrent C}:  Long dead.
    \item \texttt{Crystal}:  At present, Crystal does have fibers, but not support for parallelism.  ``At the moment of this writing, Crystal has concurrency support but not parallelism: several tasks can be executed, and a bit of time will be spent on each of these, but two code paths are never executed at the same exact time.'' (from \url{https://crystal-lang.org/reference/guides/concurrency.html}, accessed on 2 February 2020)
    \item \texttt{\fsharp{}} with \texttt{Hopac}:  More-or-less abandoned at this point, it seems.  Apparently (according to gossip) the original creator doesn't even work in \fsharp{} anymore, and the `current maintainer' doesn't seem to have much interest.  Also looked at .NET with \texttt{System.Threading.Channels}, but it doesn't seem to have any ability to select over channels.
    \item \texttt{Concurrent Haskell}:  There have been a number of \gls{csp}-inspired libraries implemented in Haskell.  The most recent known one, however is Communicating Haskell Processes, which has not been updated since 2014 (see \url{https://hackage.haskell.org/package/chp}).  Matthew Fluet suggested his Haskell `Transactional Events' (see \url{https://www.cs.rit.edu/~mtf/research/tx-events/} and \url{https://hackage.haskell.org/package/transactional-events})
    \item \texttt{Eiffel} with \texttt{SCOOP}:  SCOOP implements synchronous rendezvous, but does not seem to support actual message-passing.  It should be considered for future efforts, but is not close enough to \gls{cml} to be appropriate here.
    \item \texttt{Occam/Occam-\(\pi\)}:  The latest version of an Occam compiler, KRoC,\footnote{https://github.com/concurrency/kroc/} has not been updated since April 2017.
    \item \texttt{Haxe}:  It claims to be fast, and run cross-platform.  Unfortunately, no message-passing system could be found for it, in the standard library or user-created libraries.
    \item \texttt{Single Assignment C}:  No longer being maintained it seems, plus there doesn't seem to be any capacity for explicit concurrency mechanisms.
    \item \texttt{Python} with \texttt{PyCSP}:\footnote{\url{https://github.com/runefriborg/pycsp}}  Actually implements a lot of what I would need, but is unlikely to be all that performant.  Plus, it hasn't been updated in nearly four years.
    \item \texttt{Stackless Python}:\footnote{\url{http://www.stackless.com/}} This appears to have some of the basics, but no provision for selective choice.  Same story with \texttt{PyPy}\footnote{\url{https://www.pypy.org/}}.
    \item \texttt{Ada}:  In most ways it would be an excellent fit for this, but this work focuses specifically on channel-based implementations, and Ada doesn't come with channels by default (it has a similar-but-different mechanism).  One was implemented \cite{Atiya2005}, but it doesn't appear to have been incorporated into the language or made widely available.
    \item \texttt{D}:  The D language has nearly everything desired, but does not appear to have support for selection over channels.  No trace of it could be found in the standard library.  Mention of it is made in \url{https://wiki.dlang.org/Go_to_D}, but the library referred to there\footnote{\url{https://github.com/nin-jin/go.d}} seems to have been an unfinished prototype, and has not been updated in years.
    \item \texttt{Scala} with \texttt{Scala Communicating Objects}:\footnote{\url{https://www.cs.ox.ac.uk/people/bernard.sufrin/personal/CSO/}}  While it seems like it's probably a good library, it appears to have been one person's research experiment, which has no support and has not been updated for a while.
    \item \texttt{Pharo} or \texttt{Squeak}:  In most ways they would be suitable, but they don't \emph{quite} follow the \gls{cml} explicit channels approach.  They're more akin to Ada.
\end{itemize}