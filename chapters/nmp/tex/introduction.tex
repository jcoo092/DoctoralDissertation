\section{Introduction}
This \namecref{chap:nmp} presents a framework for passing messages between discrete points on a finite lattice, where each point updates its internal data (and thus the messages it sends) based on messages received.  Each point is uniquely connected to other points and so has its own \emph{neighbourhood}, being the specific other points it communicates with.  A key aspect of this \emph{\gls{nmp}} computation is that the messages to a given neighbour depend upon the messages received previously from \emph{all} neighbours, \emph{except} the neighbour to which the current message is sent.    This necessarily means that in \gls{nmp} each grid location must have at least two neighbours.  A single neighbour cannot form a meaningful neighbourhood.  This \namecref{chap:nmp} focuses on the \emph{square lattice} but, \gls{nmp} applies equally to lattices of any shape, dimension or connectivity.

For the purposes of this \namecref{chap:nmp}, the individual computational units in the lattice are termed \emph{\glspl{pe}}.\footnote{The short form ``\gls{pe}'' is derived from ``processing element'' in the same way that ``pixel'' is derived from ``picture element''.}  These are the logical base units for computation for current purposes and are represented by \gls{cps} \glspl{tlc}.  A visual example of the \gls{nmp} process for the \emph{\gls{fne}} on the square lattice is shown in \cref{fig:nmp:gridmessaging}.  A \gls{pe} in the grid received messages from its neighbours to the left, right, and bottom at generation \(t - 1\), and has used the data from those messages in preparing its new message to be sent to the neighbour above at iteration \(t\).  The same is performed for each other neighbour too.

\begin{figure}
    \centering
    \includegraphics[keepaspectratio,width=1.0\linewidth]{chapters/nmp/images/bp_diagram_recoloured_iotacentre.pdf}
    \caption[Diagram of the central concept of \gls{fne} \glsxtrlong{nmp} on a grid]{Diagram of the central concept of \gls{fne} \gls{nmp} on a grid \cite{lbpmpsmpic}.  Each circle represents a \gls{pe}, labelled following the pattern of \cref{fig:nmp:iota_proxels_environment_oracle}.  The central \gls{pe} \(\iota\) needs to compute a new message to send at time \(t\) to the \gls{pe} \(1\) above it, so it performs a computation to combine the results of the messages received from the other three neighbouring cells (\(2\), \(3\) \& \(4\)) at time \(t - 1\) (indicated by the thin and fat arrows).  The same is applied to every other neighbour, too.}
    \label{fig:nmp:gridmessaging}
\end{figure}

Conceptually, there are two distinct aspects of the \gls{nmp} process.  The message passing itself, which occurs externally to \glspl{pe} over channels connected to other \glspl{pe}, and the data/message updates, which occur internally.  The focus of this \namecref{chap:nmp} is the external side, and it uses communication with an oracle to represent the internal computation, which is largely orthogonal to the inter-\gls{pe} communication.

There are (at least) two separate ways to model the \glspl{pe}' communication:  a \emph{\gls{gs}} system-wide view, where the states and steps taken occur across the system as a whole and every \gls{pe} carries out its operations simultaneously according to the same rules.  Or, a per-\gls{pe} view, where each \gls{pe} has its own state and advances \emph{asynchronously} without regard to others' objects, states, and rulesets.  This \namecref{chap:nmp} explores both and finds in the process that an intermediate third, \emph{\gls{ls}}, model arises naturally as a hybrid of the other two.

The modelling and implementation of \gls{nmp} proves unexpectedly challenging.  On the surface, it seems as if it should be a straightforward problem, and in the synchronous (hereafter \emph{\gls{gs}}) form (\cref{sec:nmp:systemwide}) it \emph{is} reasonably simple.  It requires only nine rules, most of which have exactly one term on both the left-hand- and right-hand-sides and none of which use promoters or inhibitors (see \cref{chap:cpsystems} for more on these concepts).

The challenge arises in modelling the asynchronous version.  The possibility of messages for the same iteration arriving at separate times necessitates bookkeeping.  There is a need to track from which neighbours messages have been received for a given generation to decide which neighbours the \gls{pe} is now ready to send a new message to.  This gives rise to inescapable complexity and opens up the undesirable possibility of deadlock through an unsuitable design.

This \namecref{chap:nmp} begins with describing a straightforward \gls{gs} \gls{nmp} system.  Then, it provides an asynchronous \gls{pe}-specific version of the same, followed by an adaptation of the asynchronous system to a \gls{ls} system. Next is a short example of a potential evolution of the asynchronous system to clarify the expected operation of the system.  Lastly, this \namecref{chap:nmp} analyses the asynchronous system and reports the results of comparative computer experiments for all three systems.  The analysis proves that the asynchronous system sends precisely the same number of messages as the \gls{gs} system (one per generation per neighbour) but that the data used to compute new messages may vary slightly depending on the ordering of messages received.  Furthermore, the empirical results verify the operation of the asynchronous system and support the hypothesis that the \gls{ls} and asynchronous systems are faster than an equivalent \gls{gs} version.

\begin{anfxwarning}{Belief Prop?}
Should I include a little bit here explaining how this was motivated by \gls{bp}.  Moreover, explaining how there actually isn't any exploration of \gls{bp} in this chapter?
\end{anfxwarning}

\begin{anfxerror}{Generation counts}
I really should include a brief description of how the number of iterations is termed/counted as `generations' of message passing.
\end{anfxerror}