\subsection{\label{sec:tsp:cpsystems}\texorpdfstring{\gls{cps}}{cP systems} : \texorpdfstring{\gls{ps}}{P systems} with Complex Symbols}
% --------------------------------------------------

In the interests of self-containment, we present here some material describing the background of \gls{cps}, for the benefit of readers as yet unfamiliar with the topic.  More extensive presentation of \gls{cps} has appeared most recently in \cite{Nicolescu2018}, and it is recommended that the interested reader peruse that paper as well.  There are two notable additions shown here that are not in \cite{Nicolescu2018}, however: the stronger semantics for inhibitors, to fully implement logical negation; and the minimum-finding algorithm explained in \autoref{sec-min}, used in solving the \gls{tsp}.  We wish to point out that, while \gls{cps} is transitively bio-inspired through its basis in \gls{ps}, it has not been developed with the aim of simulating or modelling real-world biology, and instead is intended as a useful theoretical model for computation.

\subsubsection{Complex symbols as subcells}

\emph{Complex symbols} or \emph{subcells}, 
play the roles of cellular micro-compartments or substructures,
such as organelles, vesicles or cytoophidium assemblies (``snakes''),
which are embedded in cells or travel between cells, 
but without having the full processing power of a complete cell.
In our proposal, \emph{subcells} represent nested labelled data compartments
with no processing power of their own;
instead, they are acted upon by the rules of their enclosing cells.

Our basic vocabulary consists of \emph{atoms} and \emph{variables}, 
collectively known as \emph{simple symbols}.
\emph{Complex symbols} are similar to Prolog-like \emph{first-order terms}, 
recursively built from \emph{multisets} of atoms and variables.
Together, complex symbols and simple symbols (atoms, variables) are called \emph{symbols},
%We omit a formal grammar for them here.
and can be defined by the following formal grammar:

\begin{framed}
\vspace{-0.5cm}
\begin{small}
\begin{alltt}
    <symbol> ::= <atom> | <variable> | <term> 
    <term> ::= <functor> '(' <argument> ')'
    <functor> ::= <atom>
    <argument> ::= \(\lambda\) | ( <symbol> )+
\end{alltt}
\end{small}
\vspace{-0.5cm}
\end{framed}

\emph{Atoms} are typically denoted by lower case letters (or, occasionally, digits), 
such as $a$, $b$, $c$, \(\cpundig\). 
\emph{Variables} are typically denoted by uppercase letters, 
such as $X$, $Y$, $Z$.
\emph{Functors} are term (subcell) labels; here functors can only be atoms, not variables.

For improved readability, we also consider \emph{anonymous variables}, which are denoted by underscores (``$\_$'').
Each underscore occurrence represents a \emph{new} unnamed variable
and indicates that something, in which we are not interested, must fill that slot.

Symbols that do \emph{not} contain variables are called \emph{ground}, e.g.:
\begin{itemize}
\item Ground symbols:
$a$, $a(\lambda)$, $a(b)$, $a(b c)$, $a(b^2 c)$, $a(b(c))$, $a(bc(\lambda))$, $a(b(c)d(e))$, $a(b(c)d(e))$, $a(b(c)d(e(\lambda)))$, $a(bc^2 d)$.

\smallskip
\item Symbols which are not ground:
$X$, $a(X)$, $a(bX)$, $a(b(X))$, $a(XY)$, $a(X^2)$, $a(XdY)$,  $a(Xc())$, $a(b(X)d(e))$, $a(b(c)d(Y))$, $a(b(X^2)d(e(Xf^2)))$;
also, using anonymous variables: $\_$, $a(b\_)$, $a(X\_)$, $a(b(X)d(e(\_)))$.

\smallskip
\item This term-like construct which starts with a variable is not a symbol (this grammar defines first-order terms only):
$X(a Y)$.
\end{itemize}

Note that we may abbreviate the expression of complex symbols 
by removing inner $\lambda$'s as explicit references to the empty multiset, 
e.g.~$a(\lambda) = a()$.

In \emph{concrete} models, \emph{cells} may contain \emph{ground} symbols only (no variables).
Rules may however contain \emph{any} kind of symbols, atoms, variables and terms (whether ground or not).

\medskip
\noindent
\textbf{Unification.} 
All symbols which appear in rules (ground or not) can be (asymmetrically) \emph{matched} against \emph{ground} terms,
using an ad-hoc version of \emph{pattern matching}, 
more precisely, a \emph{one-way first-order syntactic unification} (one-way, because cells may not contain variables).
An atom can only match another copy of itself, but
a variable can match any multiset of ground terms (including $\lambda$).
This may create a combinatorial \emph{non-determinism}, 
when a combination of two or more variables are matched against the same multiset,
in which case an arbitrary matching is chosen. 
For example:
\begin{itemize}
\item Matching $a(b(X)fY) = a(b(cd(e))f^2g)$ deterministically creates a single set of unifiers:
$X, Y = cd(e), fg$.

\smallskip
\item Matching $a(XY^2) = a(de^2f)$ deterministically creates a single set of unifiers: 
$X, Y = df, e$.

\smallskip
\item Matching $a(b(X)c(\cpundig X)) = a(b(\cpundig^2)c(\cpundig^3))$ deterministically creates one single unifier: 
$X = \cpundig^2$.

\smallskip
\item Matching $a(b(X)c(\cpundig X)) = a(b(\cpundig^2)c(\cpundig^2))$ fails.

\smallskip
\item Matching $a(XY) = a(df)$ non-deterministically creates one of the following four sets of unifiers: 
$X, Y = \lambda, df$; $X, Y = df, \lambda$; $X, Y = d, f$; $X, Y = f, d$. 
\end{itemize}

\iffalse
\noindent
\textbf{Performance note.}
If the rules avoid any matching non-determinism, then
this proposal should not affect the performance of P~simulators running on existing machines.
Assuming that bags are already taken care of, e.g.~via hash-tables,
our proposed unification probably adds an almost linear factor.
Let us recall that, in similar contexts (no occurs check needed), 
Prolog unification algorithms can run in $O(n g(n))$ steps,
where $g$ is the inverse Ackermann function.
Our conjecture must be proven though, 
as the novel presence of multisets may affect the performance.
\fi

% -------------------------------------------------

\subsubsection{High-level or generic rules}

Typically, our rules use \emph{states} and are applied top-down, in the so-called \emph{weak priority} order.

\smallskip
\noindent
\textbf{Pattern matching.}
Rules are matched against cell contents using the aforementioned \emph{pattern matching},
which involves the rule's left-hand side, promoters and inhibitors -- 
promoters and inhibitors are further discussed below, in a following paragraph.

Generally, variables have \emph{global rule scope};
these are assumed to be introduced by \emph{existential} quantifiers preceding the rule
-- with the exception of inhibitors, which may introduce \emph{local variables}, 
as further discussed below. 

The matching is \emph{valid} only if, after substituting variables by their values, 
the rule's right-hand side contains ground terms only
(so \emph{no} free variables are injected in the cell or sent to its neighbours),
as illustrated by the following sample scenario:
\begin{itemize}
\item The cell's \emph{current content} includes the \emph{ground term}:\\
%\smallskip
$n(a \, \phi(b \, \phi(c) \, \psi(d)) \, \psi(e))$

\smallskip
\item The following (state-less) \emph{rewriting rule} is considered: \\ 
%\smallskip
$n(X \, \phi(Y \, \phi(Y_1) \, \psi(Y_2)) \, \psi(Z)) ~ \rightarrow ~ v(X) \: n(Y \, \phi(Y_2) \, \psi(Y_1)) \: v(Z)$

\smallskip
\item Our pattern matching determines the following \emph{unifiers}: \\
%\smallskip
$X = a$, $Y = b$, $Y_1 = c$, $ Y_2 = d$, $Z = e$.

\smallskip
\item This is a \emph{valid} matching and, after \emph{substitutions}, 
the rule's \emph{right-hand} side gives the \emph{new content}: \\
%\smallskip
$v(a) ~ n(b \, \phi(d) \, \psi(c)) ~ v(e)$
\end{itemize}

\noindent
\textbf{Generic rules format.}
We consider rules of the following \emph{generic} format 
(we call this format generic, because it actually defines templates involving variables):
\begin{framed}
\vspace{-0.6cm}
\begin{align*}
\emph{current-state} ~~ \emph{symbols} \dots ~ \rightarrow_\alpha ~ & \emph{target-state} ~~ (\emph{in-symbols}) \dots ~~ \\
 & (\emph{out-symbols})_\delta \dots \\
 & | ~  \emph{promoters} \dots ~~ \neg ~  \emph{inhibitors} \dots
\end{align*}
\vspace{-0.8cm}
\end{framed}
Where:
\begin{itemize}
\item \emph{current-state} and \emph{target-state} are atoms or terms;

\smallskip
\item \emph{symbols}, \emph{in-symbols}, \emph{promoters} and \emph{inhibitors} are symbols;

\smallskip
\item \emph{in-symbols} become available after the end of the current step only, as in traditional \gls{ps}  (we can imagine that these are sent via an ad-hoc fast \emph{loopback} channel); 

\smallskip
\item subscript $\alpha$ $\in$ $\{1$, $+\}$, 
indicates the application mode,
as further discussed in the example below;

\smallskip
\item \emph{out-symbols} are sent, at the end of the step, to the cell's structural neighbours.
These symbols are enclosed in round parentheses which further indicate 
their destinations, above abbreviated as $\delta$. 
The most usual scenarios include: 

\begin{itemize}
\item $(a)\downarrow_i$ indicates that $a$ is sent over outgoing arc $i$ (unicast); 

\item $(a)\downarrow_{i,j}$ indicates that $a$ is sent over outgoing arcs $i$ and $j$(multicast); 

\item $(a)\downarrow_\forall$ indicates that $a$ is sent over all outgoing arcs (broadcast). 
\end{itemize}

All symbols sent via one \emph{generic rule} to the same destination form one single \emph{message} and they travel together as one single block (even if the generic rule is applied in mode $\scriptstyle + \displaystyle$).
\end{itemize}

\smallskip
\noindent
\textbf{Promoters and inhibitors.}
To define additional useful matchings expressively, 
our promoters and inhibitors may also use virtual ``equality'' terms, 
written in infix format, with the $=$ operator.
For example, including the term $(ab = XY)$ indicates the following additional matching constraints on variables $X$ and $Y$: either $X, Y = ab, \lambda$; or $X, Y = a, b$; or $X, Y = b, a$; or $X, Y = \lambda, ab$.

To usefully define inhibitors as logical negations,
variables which only appear in the scope of an inhibitor are assumed to have \emph{local scope}. 
These variables are assumed to be defined by \emph{existential} quantifiers, immediately after the negation. 
Semantically, this is equivalent as introducing these variables at the global rule level, 
but by \emph{universal} quantifiers, after all other global variables,
which are introduced by \emph{existential} quantifiers.

As an illustration, consider a cell containing $a(c) ~ a(ccc)$ and contrast two rules, 
containing the following two sample promoter/inhibitor pairs 
(for brevity, other rule details are omitted here).

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
... $\mid$  $a(cXY)$     $\neg$  $a(X)$    #\hfill (1)\enspace#
... $\mid$  $a(cZ)$     $\neg$  $(Z=XY)$  $a(X)$    #\hfill (2)\enspace#
\end{lstlisting}

These two rules appear quite similar and their inhibitor tests share the same expression: 
NO $a(X)$ may be present in the cell.

Rule (1) uses two global variables, $X, Y$. 
According to its promoter, $a(cXY)$, these variables can be matched in four different ways:
(1a) $X, Y = \lambda, \lambda$; (1b) $X, Y = cc, \lambda$; (1c) $X, Y = \lambda, cc$; (1d) $X, Y = c, c$.
Three different unifications, (1a), (1b), (1c), pass the inhibitor test, 
as there are no cell terms $a()$, $a(cc)$, $a()$, respectively. 
Unification (1d) fails the inhibitor test, because there IS one cell term $a(c)$.

Rule (2) uses one global variable, $Z$, and two local inhibitor variables, $X, Y$.
According to its promoter, $a(cZ)$, variable $Z$ can be matched in two different ways: 
(2a) $Z = \lambda$; (2b) $Z = cc$.
Unification (2a) passes the inhibitor test, because it only generates one local unification,
$X, Y = \lambda, \lambda$, and there is NO cell term $a()$.
Unification (2b) fails the inhibitor test, because it generates all the following three local unifications:
(2b1) $X, Y = cc, \lambda$; (2b2) $X, Y = \lambda, cc$; (2b3) $X, Y = c, c$; 
and there IS a cell term corresponding to (2b3), $a(c)$.

The pattern of rule (2) will be used later, in \autoref{sec-min}, 
to define a single step minimum-finding ruleset.

\smallskip
\noindent
\textbf{Application modes -- $1$ and $+$.}
To explain our two rule application modes, $1$ and $+$,
let us consider a cell, $\sigma$, containing three counter-like complex symbols,
$c(\cpundig^2)$, $c(\cpundig^2)$, $c(\cpundig^3)$,
and the two possible application modes of the following high-level ``decrementing'' rule:
\vspace{-0.2cm}
\begin{framed}
\vspace{-0.5cm}
$$(\rho_\alpha) ~S_1 ~c(\cpundig \, X) \rightarrow_{\alpha} S_2 ~c(X),\\
\mathrm{where} \; \alpha \in \{\scriptstyle 1 \displaystyle, \scriptstyle + \displaystyle\}.$$
\vspace{-0.8cm}
\end{framed}
%\vspace{-0.3cm}

The left-hand side of rule $\rho_\alpha$, $c(\cpundig \, X)$, can be unified in three different ways,
to each one of the three $c$ symbols extant in cell $\sigma$.
Conceptually, we instantiate this rule in three different ways,
each one tied and applicable to a distinct symbol:
\begin{eqnarray*}
& (\rho_1)  & ~S_1 ~c(\cpundig^2) \rightarrow S_2 ~c(\cpundig),\\
& (\rho_2)  & ~S_1 ~c(\cpundig^2) \rightarrow S_2 ~c(\cpundig),\\
& (\rho_3) & ~S_1 ~c(\cpundig^3) \rightarrow S_2 ~c(\cpundig^2).
\end{eqnarray*}

\begin{enumerate}
\item If $\alpha = \: \scriptstyle 1 \displaystyle$, rule~$\rho_1$ 
non-deterministically selects and applies one of these virtual rules $\rho_1$, $\rho_2$, $\rho_3$.
Using $\rho_1$ or $\rho_2$, 
cell $\sigma$ ends with counters $c(\cpundig)$, $c(\cpundig^2)$, $c(\cpundig^3)$.
Using $\rho_3$,
cell $\sigma$ ends with counters $c(\cpundig^2)$, $c(\cpundig^2)$, $c(\cpundig^2)$.

\smallskip
\item If $\alpha = \: \scriptstyle + \displaystyle$, rule~$\rho_+$ 
applies in parallel all these virtual rules $\rho_1$, $\rho_2$, $\rho_3$.
Cell $\sigma$ ends with counters $c(\cpundig)$, $c(\cpundig)$, $c(\cpundig^2)$.
\end{enumerate}

Semantically, the $+$ mode is equivalent to a virtual sequential while loop around the same rule in $1$ mode, which is repeated until it is no more applicable.  Note, however, that all such applications of the rule are carried out concurrently in a single step.

\smallskip
\noindent
\textbf{Special cases.}
Simple scenarios involving generic rules are sometimes 
semantically equivalent to sets of non-generic rules defined via bounded loops.
For example, consider the rule
$$
S_1 ~ a(x(I) \; y(J)) ~ \rightarrow_+ ~ S_2 ~ b(I) ~ c(J),
$$
where the cell's contents guarantee that $I$ and $J$ 
only match integers in ranges $[1,n]$ and $[1,m]$, respectively.
Under these assumptions, 
this rule is equivalent to the following set of non-generic rules:
$$
S_1 ~ a_{i,j} ~ \rightarrow S_2 ~ b_i ~ c_j, ~ \forall i \in [1,n], j \in [1,m].
$$

However, unification is a much more powerful concept, 
which cannot be generally reduced to simple bounded loops.

\smallskip
\noindent
\textbf{Benefits.}
This type of generic rules allows (i) a reasonably fast parsing and processing of subcomponents, and
(ii) algorithm descriptions with \emph{fixed-size alphabets} and \emph{fixed-sized rulesets}, 
independent of the size of the problem and number of cells in the system (often \emph{impossible} with only atomic symbols).

% \smallskip
% \noindent
% \textbf{Synchronous vs asynchronous.}
% In our models, we do not make any \emph{syntactic} difference between the synchronous and asynchronous scenarios;
% this is strictly a \emph{runtime} assumption~\cite{N-CMC-LNCS-2012}.
% Any model is able to run on both the synchronous and asynchronous runtime ``engines'',
% albeit the results may differ.
% Our asynchronous model matches closely the standard definition for asynchonicity used in distributed algorithms;
% however, this is not needed in this paper so we don't follow this topic here.

% -------------------------------------------------

% --------------------------------------------------
\subsubsection{Data structures in \gls{cps}}\label{sec-data-structures}
% --------------------------------------------------

In this subsection we sketch the design of two high-level data structures, 
similar to the data structures used in high-level pseudocode or %high-level 
programming languages:
natural numbers and lists, together with alternative more legible notations
% numbers, relations, functions, associative arrays, lists, trees, strings, 
% together with alternative more readable notations.

\medskip
\noindent
\textbf{Natural numbers.} Natural numbers can be represented via \emph{multisets} containing repeated occurrences of the \emph{same} atom.
For example, considering that $\cpundig$ represents an ad-hoc unary digit, 
the following complex symbols can be used to describe 
the contents of a virtual integer \emph{variable} $a$: 
$a () = a(\lambda)$ --- the value of $a$ is 0;
$a(\cpundig^3)$ --- the value of $a$ is 3.
For concise expressions, we may alias these number representations by their corresponding numbers, e.g.~$a() \equiv a(0), b(\cpundig^3) \equiv b(3)$.
Nicolescu et al.~\cite{Nicolescu2014,RN-HW-ROMJIST14} show how the basic arithmetic operations can be efficiently modelled by \gls{ps} with complex symbols.

Here follows a list of simple arithmetic expressions, assignments and comparisons:

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
  $x = 0$ $\equiv$ $x(\lambda)$
  $x = 1$ $\equiv$ $x(\cpundig)$
  $x = 2$ $\equiv$ $x(\cpundig \cpundig)$
  $x = n$ $\equiv$ $x(\cpundig^n)$
  
  $x \leftarrow y + z$ $\equiv$ $y(Y) ~ z(Z) ~ \rightarrow ~ x(YZ)$ #\hfill\textsl{destructive add}\enspace#
  $x \leftarrow y + z$ $\equiv$ $ \rightarrow ~ x(YZ) ~ \mid ~ y(Y) ~ z(Z)$ #\hfill\textsl{preserving add}\enspace#
  
  $x = y$ $\equiv$  $x(X) ~y(X)$ #\hfill\textsl{equality}\enspace#
  $x \leq y$ $\equiv$  $x(X) ~y(XY)$ #\hfill\textsl{less than or equal to}\enspace#
  $x <  y$ $\equiv$  $x(X) ~y(X1Y)$ #\hfill\textsl{strictly less than}\enspace#
\end{lstlisting}

Note that strictly less than (\(<\)) requires the extra \(1\), because \(Y\) can match on \(\lambda\).

% \medskip
% \noindent
% \textbf{Relations and functions.} Consider the \emph{binary relation} $r$, 
% defined by: 
% $r = \{ (a, b)$, $(b, c)$, $(a, d)$, $(d, c) \}$ (which has a diamond-shaped graph). 
% Using complex symbols, relation $r$ can be represented as a \emph{multiset} with four $r$ items,
% $\{ r(\kappa(a) ~ \upsilon(b))$, $r(\kappa(b) ~ \upsilon(c))$, $r(\kappa(a) ~ \upsilon(d))$, $r(\kappa(d) ~ \upsilon(c)) \}$, 
% where ad-hoc atoms $\kappa$ and $\upsilon$ introduce \emph{domain} and \emph{codomain} values (respectively).
% We may also alias the items of this multiset by a more expressive notation such as: $\{ (a \stackrel{r}\rightleftarrows b)$, $(b \stackrel{r}\rightleftarrows c)$, $(a \stackrel{r}\rightleftarrows d)$, $(d \stackrel{r}\rightleftarrows c) \}$.

% If the relation is a \emph{functional relation}, then we can emphasise this by using another operator, such as ``mapsto''. For example, the functional relation 
% $f = \{ (a, b)$, $(b, c)$, $(d, c) \}$ can be represented by multiset
% $\{ f(\kappa(a) ~ \upsilon(b))$, $f(\kappa(b) ~ \upsilon(c))$, $f(\kappa(d) ~ \upsilon(c)) \}$ or by the more suggestive notation: 
% $\{ (a \stackrel{f}\mapsto b)$, $(b \stackrel{f}\mapsto c)$, $(d \stackrel{f}\mapsto c) \}$.
% To highlight the actual mapping value, instead of $a \stackrel{f}\mapsto b$,
% we may also use the succinct abbreviation $f[a] = b$.

% In this context, the $\rightleftarrows$ and $\mapsto$ operators are considered to have a high associative priority, so the enclosing parentheses are mostly used for increasing the readability.

% \medskip
% \noindent
% \textbf{Associative arrays.} Consider the \emph{associative array} $x$, 
% with the following key-value mappings (i.e. functional relation): 
% $\{ \cpundig \mapsto a; \cpundig^3 \mapsto c; \cpundig^7 \mapsto g \}$. 
% Using complex symbols, array $x$ can be represented as a multiset with three items,
% $\{ x(\kappa(\cpundig)\,\upsilon(a))$, $x(\kappa(\cpundig^3)\,\upsilon(c))$, $x(\kappa(\cpundig^7)\,\upsilon(g)) \}$, 
% where ad-hoc atoms $\kappa$ and $\upsilon$ introduce keys and values (respectively).
% We may also alias the items of this multiset by the more expressive notation
% $\{ \cpundig \stackrel{x}\mapsto a$, $\cpundig^3 \stackrel{x}\mapsto c$, $\cpundig^7 \stackrel{x}\mapsto g \}$.

\medskip
\noindent
\textbf{Lists.} Consider the \emph{list} $y$, containing the following sequence of values: 
$[u; v; w]$. 
List $y$ can be represented as the complex symbol
$y(\, \gamma(u~\gamma(v~\gamma(w~\gamma()))))$, 
where the ad-hoc atom $\gamma$ represents the list constructor \emph{cons} and $\gamma()$ the empty list.
We may also alias this list by the more expressive equivalent notation
$y(u\,|\,v\,|\,w)$
-- or by $y(u\,|\,y')$, $y'(v\,|\,w)$ --
where operator $\mid$ separates the head and the tail of the list.
The notation $z(|)$ is shorthand for $z(\gamma())$ and indicates an empty list, $z$.

% \medskip
% \noindent
% \textbf{Trees.} Consider the \emph{binary tree} $z$, described by the structured expression \\
% $(a, (b), (c, (d), (e)))$, 
% i.e.~$z$ points to a root node which has: 
% (i) the value $a$; 
% (ii) a left node with value $b$; and 
% (iii) a right node with value $c$, left leaf $d$, and right leaf $e$. 
% Tree $z$ can be represented as the complex symbol
% $z(a ~ \phi(b) ~ \psi(c ~ \phi(d) ~ \psi(e)))$, 
% where ad-hoc atoms $\phi, \psi$ introduce left subtrees, right subtrees (respectively).

% \medskip
% \noindent
% \textbf{Strings.} Consider the \emph{string} $s = ``abc"$, 
% where $a$, $b$, and $c$ are atoms. 
% Obviously, string $s$ can be interpreted as the list $s = [a; b; c]$, i.e.
% string $s$ can be represented as the complex symbol
% $s(\, \gamma(a~\gamma(b~\gamma(c~\gamma()))))$, etc.

% --------------------------------------------------
\subsubsection{Efficient minimum-finding with cP~rules}\label{sec-min}
% --------------------------------------------------

Consider an unstructured multiset $A \subseteq \mathbb{N}$ of size $n$. 
It is well known that (1) any sequential algorithm that finds its minimum needs at least $n$ steps, and 
(2) any parallel algorithm that finds its minimum needs at least $\log n$ parallel steps.

Without loss of generality, consider a cP~system cell, in state $S_1$, where multiset $A$ is given via functor $a$; 
e.g., multiset $A = \{ 1, 2, 2, 5 \}$ is represented as $a(1) a(2) a(2) a(5)$.
The following rulesets implement various versions of a cP~system minimum-finding algorithm.
All these rulesets transit to state $S_2$ and construct a term with functor $b$, containing $\min A$.
Some of these are destructive processes; if otherwise desired, one could first make a copy of the initial multiset $A$.

The following destructive ruleset is an emulation of the classical sequential minimum finding algorithm, which takes $n$ steps:

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
$S_1$  $a(X)$  $\rightarrow_{1}$  $S_2$  $b(X)$ 
$S_2$  $a(XY)$  $b(X)$  $\rightarrow_{1}$  $S_2$  $b(X)$     #\hfill  $a \geq b  $ \enspace #
$S_2$  $a(X)$  $b(X1Y)$  $\rightarrow_{1}$  $S_2$  $b(X)$   #\hfill  $a < b  $ \enspace #
\end{lstlisting}

The following destructive ruleset is an emulation of the classical parallel minimum finding algorithm, which takes $\log n$ steps.
As long as there are more than one term $a$, the ruleset loops in state $S_1$, keeping minima between pairs.
When only one $a$ remains (containing the minimum value), the ruleset transits to state $S_2$ and tags the minimum. 

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
$S_1$  $a(XY)$  $a(X)$  $\rightarrow_{+}$  $S_1$  $a(X)$     
$S_1$  $a(X)$  $a(X1Y)$  $\rightarrow_{+}$  $S_1$  $a(X)$    
$S_1$  $a(X)$  $\rightarrow_{1}$  $S_2$  $b(X)$  
\end{lstlisting}

However, using the full associative power of \gls{cps}, we can find a non-destructive version with two rules, 
which works in \emph{just two steps} (regardless of the set cardinality). 
This is a substantial improvement over existing classical algorithms (both sequential and parallel). 
It starts by making a full copy of $a$ as $b$, in one $+$-parallel step, 
and then deletes all non-minimal $b$ values in another $+$-parallel step. 

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
$S_1$  $\rightarrow_{+}$  $S_1'$  $b(X)$    $\mid$  $a(X)$  
$S_1'$  $b(X1Y)$  $\rightarrow_{+}$  $S_2$    $\mid$  $a(X)$  
\end{lstlisting}

Note that, if the minimum value appears several times in multiset $A$, 
then we will end with the same multiplicity of $b$'s, each one containing the same value, $\min A$.
If this is required, there are several ways to select only one copy and delete the rest --
but we do not further deal with this issue here.

Moreover, using the full power of cP~inhibitors (as logical negations, with local variables), 
we can even non-destructively solve the problem in just \emph{one single step},
with one or two rules.
This version is implemented by the following ruleset:

\lstset{xleftmargin=.5in, xrightmargin=.5in} 
\begin{lstlisting}
$S_1$  $\rightarrow_{1}$  $S_2$  $b()$    $\mid$  $a()$
$S_1$  $\rightarrow_{1}$  $S_2$  $b(1Z)$     $\mid$  $a(1Z)$     $\neg$  $(Z=XY)$  $a(X)$
\end{lstlisting}

If $A$ contains zero, then there is a term $a()$, and: (1) the first rule applies, constructing $b()$; (2) the second rule is not applicable.
Otherwise (if there is no zero in $A$): (1) the first rule is not applicable; (2) the second rule constructs $b(1Z)$, 
a value which exists among $a$'s, as $a(1Z)$, but there is NO other $a$ containing a strictly lesser value, such as $a(X)$,
where $X$ is a sub-multiset of $Z$, $X \subseteq Z$.
In the end, the newly constructed $b$ will contain one copy of the minimum value of multiset $A$.

If multiset $A$ does not contain zero values, i.e. $A \subseteq \mathbb{N}^+$, then the first rule can be safely omitted (as it will never be applicable). 
A similar ruleset can be devised for finding the maximum of a given set of natural numbers.