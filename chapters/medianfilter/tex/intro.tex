\section{Introduction}
% While parallelism is generally the best (perhaps only) way to achieve improvements in execution time for different algorithms once a reasonably efficient sequential implementation has been created, it is a notoriously challenging affair \cite{Shun2017}.  When working at the level of directly manipulating threads, such as using the pthreads found in POSIX-compliant operating systems, programmers are exposed to a high level of risk of inadvertently introducing concurrency bugs, such as data races, deadlocks and livelocks.  A wide panoply of different approaches to overcoming this challenge, both theoretical and practical, have been proposed and developed over the years, with varying degrees of success, \eg{} \cite{Boyapati2002,Bocq2012,Seinstra2004}.  Almost all large-scale programming languages that use a runtime include some form of parallelism simplification within their standard libraries, \eg{} the Executor system in Java and Swift \& Objective-C's Grand Central Dispatch.

% Most simplifications fairly directly target either data-parallelism by simultaneously applying the same operation over multiple elements in arrays, \eg{} classic SIMD vector instructions in CPUs, or task-parallelism by making provisions for the fork-join model.  These simplifications can be very useful, but not all instances of parallelism fit neatly under their models.  Algorithms that are well-modelled by the Communicating Sequential Processes \cite{Hoare1985} and Actor \cite{Agha1997} models, such as those explicitly centred around concepts of message passing, are not necessarily easy to express using either SIMD or fork-join instructions.

% \Gls{cml}, introduced by Reppy \cite{Reppy1991}, was created to provide a framework for creating concurrent programs with synchronous communications, and was later extended to permit parallelism \cite{Reppy2009a}.  The conceptual framework is built around the idea of lightweight independent sub-processes communicating over channels when they synchronously rendezvous.  Essentially, one process offers on a channel to give or take a value, and another then offers to take or give.  When two processes are offering appropriately on either side of an exchange, it takes place.  The basic concept of communicating via channels has experienced a renaissance in recent years, likely due at least in part to their inclusion as a core feature of Go, but \gls{cml} has a more advanced system that Go (at the time of writing) arguably is not capable of supporting.  It was originally implemented for Standard ML of New Jersey (where ML refers to the earlier programming language \textit{Meta Language}), whence the ML part of the name, but has been implemented in some form for other languages as well -- it is not necessarily connected with machine learning.

Many Computer Vision and Image Processing operations have some potential for parallelism.  Indeed, a number of them can be regarded as `embarrassingly parallel', that is to say that the process involves a considerable number of sub-process steps that do not depend on each other, and so those steps may be performed concurrently without complication.  Some of those algorithms either are explicitly characterised in terms of message passing, such as \gls{sm} with \gls{bp} \cite{Liang2011} or \gls{sgm} \cite{Drory2014}, or could be viewed as such, \eg{} \glspl{mwt} applied to images.

Median filtering \cite[Chap. 3.4.1]{Gimelfarb2018}, \cite{Fisher2016} is an operation in image processing used to remove random `salt \& pepper' noise from images.  Such noise is characterised by pixel colouration values at the extreme high and low ends of the range of possible values.  At its simplest, median filtering recovers an approximation of the non-noisy image by taking the median of all pixel values in a window around each pixel and creating a new image using said median values for the pixels.

% This \namecref{chap:median} seeks to explore whether using \gls{cml} -- as a method of structuring computations around message passing -- could be beneficial when applied to a \gls{mwt}, using the \gls{medianfilter} as its particular example.  The focus is on examining the potential benefit of using a different principle to structure the processing, as much as it is on the achieved results.  It is hypothesised that the same results in terms of processing the image can be achieved, but at slightly slower rates of processing due to overheads from the message passing which, strictly speaking, are unnecessary in the case of a \gls{mwt}.% To the best of the author's knowledge, no exploration of \gls{cml} applied to computer vision or image processing has been performed in the past.  The results presented here are preliminary and a first step in investigating the topic.

This \namecref{chap:median} seeks firstly to model median filtering using \gls{cps}, as another test of the power and versatility of \gls{cps}, and secondly to explore whether using \gls{cml} -- as a method of structuring computations around message passing -- could be beneficial when applied to a \gls{mwt}, using the \gls{medianfilter} as its particular example.  The focus is on examining the potential benefit of using a different principle to structure the processing, as much as it is on the achieved results.  It is hypothesised that the same results in terms of processing the image can be achieved, but at slightly slower rates of processing due to overheads from the message passing which, strictly speaking, are unnecessary in the case of a \gls{mwt}.% To the best of the author's knowledge, no exploration of \gls{cml} applied to computer vision or image processing has been performed in the past.  The results presented here are preliminary and a first step in investigating the topic.