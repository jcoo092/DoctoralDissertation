@book{Syme2015a,
address = {Berkeley, CA},
annote = {QA75.5-76.95},
author = {Syme, Don and Granicz, Adam and Cisternino, Antonio},
% booktitle = {Expert F{\#} 4.0},
doi = {10.1007/978-1-4842-0740-6},
edition = {4 ed.},
isbn = {978-1-4842-0741-3},
publisher = {Apress},
title = {{Expert F{\#} 4.0}},
url = {http://link.springer.com/10.1007/978-1-4842-0740-6},
year = {2015}
}
@book{Butcher2014,
address = {Dallas, TX, USA},
author = {Butcher, Paul},
editor = {Tate, Bruce},
isbn = {9781937785659},
keywords = {Computer multitasking,Parallel programming (Computer science)},
pages = {289},
publisher = {The Pragmatic Programmers LLC},
series = {Pragmatic programmers},
title = {{7 Concurrency Models in 7 Weeks}},
url = {https://pragprog.com/book/pb7con/seven-concurrency-models-in-seven-weeks},
year = {2014}
}
@article{Shi2013,
abstract = {In this day and age of multicore architectures, programming language support is in urgent need for constructing programs that can take great advantage of machines with multiple cores. We present in this paper an approach to safe multicore programming in ATS, a recently developed functional programming language that supports both linear and dependent types. In particular, we formalize a type system capable of guaranteeing safe manipulation of resources on multicore machines and establish its soundness. We also provide concrete examples as well as experimental results in support of the practicality of the presented approach to multicore programming. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
annote = {ID: 271600},
author = {Shi, Rui and Xi, Hongwei},
doi = {10.1016/j.scico.2012.09.005},
file = {:D$\backslash$:/Users/jcoo092/SLR/Papers/Holding/Shi, Xi - A linear type system for multicore programming in ATS - 2013.pdf:pdf},
% isbn = {0167-6423},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {ATS,Linear types,Multicore,Type systems},
month = {8},
number = {8},
pages = {1176--1192},
title = {{A linear type system for multicore programming in ATS}},
url = {http://www.sciencedirect.com.ezproxy.auckland.ac.nz/science/article/pii/S0167642312001700 http://linkinghub.elsevier.com/retrieve/pii/S0167642312001700},
volume = {78},
year = {2013}
}
@incollection{Reppy2011,
abstract = {Concurrent ML (CML) is a higher-order concurrent language embedded in the sequential language Standard ML (SML). CML's basic programming model consists of dynamically created threads that communicate via message passing over dynamically created channels. CML also provides first-class synchronous operations, called event values, which support user-defined synchronization and communication abstractions. While the term “CML” refers to a specific language implementation, it is also used to refer to implementations of its language primitives in other systems.},
address = {Boston, MA},
author = {Reppy, John H.},
booktitle = {Encyclopedia of Parallel Computing},
doi = {10.1007/978-0-387-09766-4_47},
edition = {2011},
editor = {Padua, David},
isbn = {978-0-387-09766-4},
keywords = {Concurrent ML},
pages = {371--377},
publisher = {Springer US},
title = {{Concurrent ML}},
url = {https://doi.org/10.1007/978-0-387-09766-4{\_}47},
year = {2011}
}
@book{Reppy2007,
address = {New York, New York, USA},
author = {Reppy, John H.},
isbn = {978-0-521-71472-3},
keywords = {Concurrent ML,concurrent ml},
pages = {308},
publisher = {Cambridge University Press},
title = {{Concurrent Programming in ML}},
year = {2007}
}
@article{Reppy1991,
abstract = {An abstract is not available.},
author = {Reppy, John H.},
doi = {10.1145/113446.113470},
file = {:D$\backslash$:/jarak/Documents/Reppy - 1991 - CML A Higher-order Concurrent Language.pdf:pdf},
% isbn = {0-89791-428-7},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {Concurrent ML},
month = {6},
number = {6},
pages = {293--305},
title = {{CML: A Higher-order Concurrent Language}},
url = {http://portal.acm.org/citation.cfm?doid=113446.113470},
volume = {26},
year = {1991}
}
@inproceedings{Reppy2007a,
abstract = {Concurrent ML (CML) is a statically-typed higher-order concurrent language that is embedded in Standard ML. Its most notable feature is its support for first-class synchronous operations. This mechanism allows programmers to encapsulate complicated communication and synchronization protocols as first-class abstractions, which encourages a modular style of programming where the underlying channels used to communicate with a given thread are hidden behind data and type abstraction.While CML has been in active use for well over a decade, little attention has been paid to optimizing CML programs. In this paper, we present a new program analysis for statically-typed higher-order concurrent languages that enables the compile-time specialization of communication operations. This specialization is particularly important in a multiprocessor or multicore setting, where the synchronization overhead for general-purpose operations are high. Preliminary results from a prototype that we have built demonstrate that specialized channel operations are much faster than the general-purpose operations.Our analysis technique is modular (i.e., it analyzes and optimizes a single unit of abstraction at a time), which plays to the modular style of many CML programs. The analysis consists of three steps: the first is a type-sensitive control-flow analysis that uses the program's type-abstractions to compute more precise results. The second is the construction of an extended control-flow graph using the results of the CFA. The last step is an iterative analysis over the graph that approximates the usage patterns of known channels. Our analysis is designed to detect special patterns of use, such as one-shot channels, fan-in channels, and fan-out channels. We have proven the safety of our analysis and state those results. Copyright {\textcopyright} 2007 ACM.},
address = {New York, New York, USA},
author = {Reppy, John H. and Xiao, Yingqi},
booktitle = {Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '07},
doi = {10.1145/1190216.1190264},
isbn = {1595935754},
% issn = {07308566},
keywords = {Concurrent ML,Concurrent languages,ML,Message passing,Static analysis},
pages = {315},
publisher = {ACM Press},
title = {{Specialization of CML message-passing primitives}},
url = {http://portal.acm.org/citation.cfm?doid=1190216.1190264},
year = {2007}
}
@inproceedings{Atiya2005,
abstract = {The Ravenscar Profile is a restricted subset of the Ada tasking model, designed to meet the requirements of producing analysable and deterministic code. A central feature of Ravenscar is the use of protected objects to ensure mutually exclusive access to shared data. This paper uses Ravenscar protected objects to implement CSP channels in Ada - the proposed implementation is formally verified using model checking. The advantage of these Ravenscar channels is transforming the data-oriented asynchronous tasking model of Ravenscar into the cleaner message-passing synchronous model of CSP. Thus, formal proofs and techniques for model-checking CSP specifications can be applied to Ravenscar programs. In turn, this increases confidence in these programs and their reliability. Indeed, elsewhere, we use the proposed Ravenscar channels as the basis for a cost-effective technique for verifying concurrent safety-critical system. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Atiya, Diyaa-Addein and King, Steve},
booktitle = {Reliable Software Technology -- Ada-Europe 2005},
doi = {10.1007/11499909_7},
editor = {Vardanega, Tullio and Wellings, Andy},
file = {:H$\backslash$:/2019/Papers/To read/Atiya, King - 2005 - Extending Ravenscar with CSP Channels.pdf:pdf},
isbn = {978-3-540-31666-4},
% issn = {03029743},
pages = {79--90},
publisher = {Springer Berlin Heidelberg},
title = {{Extending Ravenscar with CSP Channels}},
url = {http://link.springer.com/10.1007/11499909{\_}7},
year = {2005}
}

@article{Reppy1988,
abstract = {Synchronous message passing via channels is an interprocess communication (IPC) mechanism found in several concurrent languages, such as CSP, occam, and Amber. Such languages provide a powerful selective I/O operation, which plays a vital role in managing communication with multiple processes. Because the channel IPC mechanism is “operation-oriented,” only procedural abstraction techniques can be used in structuring the communication/synchronization aspects of a system. This has the unfortunate effect of restricting the use of selective I/O, which in turn limits the communication structure. We propose a new, “value-oriented” approach to channel-based synchronization. We make synchronous operations first-class values, called events, in much the same way that functions are first-class values in functional programming languages. Our approach allows the use of data abstraction techniques for structuring IPC. We have incorporated events into PML, a concurrent functional programming language, and have implemented run-time support for them as part of the Pegasus system. {\textcopyright} 1988, ACM. All rights reserved.},
author = {Reppy, John H.},
doi = {10.1145/960116.54015},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Reppy - 1988 - Synchronous Operations as First-Class Values.pdf:pdf},
issn = {15581160},
journal = {ACM SIGPLAN Notices},
keywords = {Concurrency,Concurrent ML},
month = {7},
number = {7},
pages = {250--259},
title = {{Synchronous Operations as First-Class Values}},
url = {https://dl.acm.org/doi/10.1145/960116.54015},
volume = {23},
year = {1988}
}

@manual{Defense1983,
address = {New York, NY},
author = {United States Department of Defense},
title = {Reference Manual for the ADA{\textregistered} Programming Language},
doi = {10.1007/978-1-4612-5016-6},
isbn = {978-0-387-90887-8},
publisher = {Springer New York},
title = {{Reference Manual for the ADA{\textregistered} Programming Language}},
url = {http://link.springer.com/10.1007/978-1-4612-5016-6},
year = {1983}
}

@article{Elizabeth1987,
abstract = {The features of concurrency provide important concepts for problem solving in a wide range of application areas. Many languages have now been developed to support this approach, with various notations being proposed. Occam is a programming language which supports concurrency using the process as its program structure, and provides synchronous communication between these processes. This paper presents the main features of occam and illustrates its use through various examples. {\textcopyright} 1987.},
author = {Elizabeth, M. and Hull, C.},
doi = {10.1016/0096-0551(87)90010-5},
issn = {00960551},
journal = {Computer Languages},
keywords = {Communicating sequential processes,Concurrency,Occam,Process,Transputer},
month = {1},
number = {1},
pages = {27--37},
title = {{Occam-A programming language for multiprocessor systems}},
url = {http://www.sciencedirect.com/science/article/pii/0096055187900105 https://linkinghub.elsevier.com/retrieve/pii/0096055187900105},
volume = {12},
year = {1987}
}

@article{Meyerson2014,
abstract = {Andrew Gerrand, who works on the Go programming language at Google, speaks with Jeff Meyerson in this excerpt from Software Engineering Radio. His conversation with Jeff begins with a history of the language, including the details behind how Go was conceived and how the open source community contributes to it. Andrew explains how Go intends to simplify problems which have been motifs as Google has scaled. The Web extra at http://www.se-radio.net/2014/03/episode-202-andrew-gerrand/is an audio recording of Jeff Meyerson speaking with Andrew Gerrand about the Go programming language.},
author = {Meyerson, Jeff},
doi = {10.1109/MS.2014.127},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {Andrew Gerrand,C,Go,Google,arrays,build times,compilers,garbage collection,golang,imports,interfaces,open source,readability,scalability,slices,standard library,syntax},
month = {9},
number = {5},
pages = {104--104},
title = {{The Go Programming Language}},
url = {http://ieeexplore.ieee.org/document/6898707/},
volume = {31},
year = {2014}
}

@article{Clark2004,
abstract = {Go! is a multi-paradigm programming language that is oriented to the needs of programming secure, production quality, agent based applications. It is multi-threaded, strongly typed and higher order (in the functional programming sense). It has relation, function and action procedure definitions. Threads execute action procedures, calling functions and querying relations as need be. Threads in different agents communicate and coordinate using asynchronous messages. Threads within the same agent can also use shared dynamic relations acting as Linda-style tuple stores. In this paper we introduce the essential features of Go!. We then illustrate them by programming a simple multi-agent application comprising hybrid reactive/deliberative agents interacting in a simulated ballroom. The dancer agents negotiate to enter into joint commitments to dance a particular dance (e.g., polka) they both desire. When the dance is announced, they dance together. The agents' reactive and deliberative components are concurrently executing threads which communicate and coordinate using belief, desire and intention memory stores. We believe such a multi-threaded agent architecture represents a powerful and natural style of agent implementation, for which Go! is well suited.},
author = {Clark, K.L. and McCabe, F.G.},
doi = {10.1023/B:AMAI.0000031195.87297.d9},
issn = {1012-2443},
journal = {Annals of Mathematics and Artificial Intelligence},
keywords = {Agent programming,Multi-paradigm programming,Threads},
month = {8},
number = {2-4},
pages = {171--206},
title = {{Go! – A Multi-Paradigm Programming Language for Implementing Multi-Threaded Agents}},
url = {https://doi.org/10.1023/B:AMAI.0000031195.87297.d9 http://link.springer.com/10.1023/B:AMAI.0000031195.87297.d9},
volume = {41},
year = {2004}
}

@article{Armstrong2010,
abstract = {Erlang is a concurrent programming language designed for programming fault-tolerant distributed systems at Ericsson and has been (since 2000) freely available subject to an open-source license. More recently, we've seen renewed interest in Erlang, as the Erlang way of programming maps naturally to multicore computers. In it the notion of a process is fundamental, with processes created and managed by the Erlang runtime system, not by the underlying operating system. The individual processes, which are programmed in a simple dynamically typed functional programming language, do not share memory and exchange data through message passing, simplifying the programming of multicore computers. Erlang2 is used for programming fault-tolerant, distributed, real-time applications. What differentiates it from most other languages is that it's a concurrent programming language; concurrency belongs to the language, not to the operating system. Its programs are collections of parallel processes cooperating to solve a particular problem that can be created quickly and have only limited memory. {\textcopyright} 2010 ACM 0001-0782/10/0900 {\$}10.00.},
author = {Armstrong, Joe},
doi = {10.1145/1810891.1810910},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Armstrong - 2010 - Erlang.pdf:pdf},
issn = {0001-0782},
journal = {Communications of the ACM},
month = {9},
number = {9},
pages = {68--75},
title = {{Erlang}},
url = {https://dl.acm.org/doi/10.1145/1810891.1810910},
volume = {53},
year = {2010}
}

@article{Varela2001,
abstract = {Applications running on the Internet, or on limited-resource devices, need to be able to adapt to changes in their execution environment at run-time. Current languages and systems fall short of enabling developers to migrate and reconfigure application sub-components at program-execution time. In this paper, we describe essential aspects of the design and implementation of SALSA, an actor-based language for mobile and Internet computing. SALSA simplifies programming dynamically reconfigurable, open applications by providing universal names, active objects, and migration. Moreover, SALSA introduces three language mechanisms to help programmers coordinate asynchronous, mobile computations: token-passing continuations, join continuations and first-class continuations. We provide some examples which illustrate how SALSA programs are not only dynamically reconfigurable and open, but also much more concise and easier to follow than comparable Java code. Furthermore, we provide empirical results which show SALSA's performance to be better than Java code using an actor library, and which illustrate the difference between local, local area, and wide area communication and migration. Finally, we discuss the implementation of our preprocessor which translates SALSA code into Java.},
%address = {New York, NY, USA},
author = {Varela, Carlos A. and Agha, Gul},
doi = {10.1145/583960.583964},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Actors,Continuations,Internet,Java,SALSA},
month = {12},
number = {12},
pages = {20--34},
%publisher = {Association for Computing Machinery},
title = {{Programming dynamically reconfigurable open systems with SALSA}},
url = {https://doi-org.ezproxy.auckland.ac.nz/10.1145/583960.583964 https://dl.acm.org/doi/10.1145/583960.583964},
volume = {36},
year = {2001}
}

@inproceedings{Srinivasan2008,
abstract = {This paper describes Kilim, a framework that employs a combination of techniques to help create robust, massively concurrent systems in mainstream languages such as Java: (i) ultra-lightweight, cooperatively-scheduled threads (actors), (ii) a message-passing framework (no shared memory, no locks) and (iii) isolation-aware messaging. Isolation is achieved by controlling the shape and ownership of mutable messages - they must not have internal aliases and can only be owned by a single actor at a time. We demonstrate a static analysis built around isolation type qualifiers to enforce these constraints. Kilim comfortably scales to handle hundreds of thousands of actors and messages on modest hardware. It is fast as well - task-switching is 1000x faster than Java threads and 60x faster than other lightweight tasking frameworks, and message-passing is 3x faster than Erlang (currently the gold standard for concurrency-oriented programming). {\textcopyright} 2008 Springer-Verlag.},
address = {Berlin, Heidelberg},
author = {Srinivasan, Sriram and Mycroft, Alan},
booktitle = {ECOOP 2008 – Object-Oriented Programming},
editor = {Vitek, Jan},
doi = {10.1007/978-3-540-70592-5_6},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Srinivasan, Mycroft - 2008 - Kilim Isolation-Typed Actors for Java.pdf:pdf},
isbn = {3540705910},
%issn = {03029743},
pages = {104--128},
publisher = {Springer Berlin Heidelberg},
title = {{Kilim: Isolation-Typed Actors for Java}},
url = {http://link.springer.com/10.1007/978-3-540-70592-5{\_}6},
volume = {5142 LNCS},
year = {2008}
}

@article{Charousset2016,
abstract = {The actor model of computation has gained significant popularity over the last decade. Its high level of abstraction makes it appealing for concurrent applications in parallel and distributed systems. However, designing a real-world actor framework that subsumes full scalability, strong reliability, and high resource efficiency requires many conceptual and algorithmic additives to the original model. In this paper, we report on designing and building CAF, the C++ Actor Framework. CAF targets at providing a concurrent and distributed native environment for scaling up to very large, high-performance applications, and equally well down to small constrained systems. We present the key specifications and design concepts—in particular a message-transparent architecture, type-safe message interfaces, and pattern matching facilities—that make native actors a viable approach for many robust, elastic, and highly distributed developments. We demonstrate the feasibility of CAF in three scenarios: first for elastic, upscaling environments, second for including heterogeneous hardware like GPUs, and third for distributed runtime systems. Extensive performance evaluations indicate ideal runtime at very low memory footprint for up to 64 CPU cores, or when offloading work to a GPU. In these tests, CAF continuously outperforms the competing actor environments Erlang, Charm++, SalsaLite, Scala, ActorFoundry, and even the raw message passing framework OpenMPI.},
archivePrefix = {arXiv},
%arxivId = {1505.07368},
author = {Charousset, Dominik and Hiesgen, Raphael and Schmidt, Thomas C.},
doi = {10.1016/j.cl.2016.01.002},
eprint = {1505.07368},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Charousset, Hiesgen, Schmidt - 2016 - Revisiting actor programming in C.pdf:pdf},
issn = {14778424},
journal = {Computer Languages, Systems {\&} Structures},
keywords = {C++ Actor framework,Concurrent programming,Distributed software architecture,GPU computing,Message-oriented middleware,Performance analysis},
month = {4},
pages = {105--131},
%publisher = {Elsevier},
title = {{Revisiting actor programming in C++}},
url = {http://dx.doi.org/10.1016/j.cl.2016.01.002 https://linkinghub.elsevier.com/retrieve/pii/S1477842416000038},
volume = {45},
year = {2016}
}

@book{Armstrong2013,
abstract = {A multi-user game, web site, cloud application, or networked database can have thousands of users all interacting at the same time. You need a powerful, industrial-strength tool to handle the really hard problems inherent in parallel, concurrent environments. You need Erlang. In this second edition of the bestselling Programming Erlang, you'll learn how to write parallel programs that scale effortlessly on multicore systems. Using Erlang, you'll be surprised at how easy it becomes to deal with parallel problems, and how much faster and more efficiently your programs run. That's because Erlang uses sets of parallel processes-not a single sequential process, as found in most programming languages. Joe Armstrong, creator of Erlang, introduces this powerful language in small steps, giving you a complete overview of Erlang and how to use it in common scenarios. You'll start with sequential programming, move to parallel programming and handling errors in parallel programs, and learn to work confidently with distributed programming and the standard Erlang/Open Telecom Platform (OTP) frameworks. You need no previous knowledge of functional or parallel programming. The chapters are packed with hands-on, real-world tutorial examples and insider tips and advice, and finish with exercises for both beginning and advanced users. The second edition has been extensively rewritten. New to this edition are seven chapters covering the latest Erlang features: maps, the type system and the Dialyzer, WebSockets, programming idioms, and a new stand-alone execution environment. You'll write programs that dynamically detect and correct errors, and that can be upgraded without stopping the system. There's also coverage of rebar (the de facto Erlang build system), and information on how to share and use Erlang projects on github, illustrated with examples from cowboy and bitcask. Erlang will change your view of the world, and of how you program. What You Need The Erlang/OTP system. Download it from erlang.org.},
author = {Armstrong, Joe},
edition = {2nd},
editor = {{Davidson Pfalzer}, Susannah},
isbn = {193778553X},
pages = {1--530},
publisher = {Pragmatic Bookshelf},
series = {The Pragmatic Programmers},
title = {{Programming Erlang: Software for a Concurrent World}},
% url = {https://pragprog.com/titles/jaerlang2/programming-erlang-2nd-edition/},
year = {2013}
}

@manual{Taft2013,
address = {Berlin, Heidelberg},
author = {Taft, S. Tucker and Duff, Robert A. and Brukardt, Randall L. and Pl{\"{o}}dereder, Erhard and Leroy, Pascal and Schonberg, Edmond},
doi = {10.1007/978-3-642-45419-6},
editor = {Taft, S. Tucker and Duff, Robert A. and Brukardt, Randall L. and Pl{\"{o}}dereder, Erhard and Leroy, Pascal and Schonberg, Edmond},
isbn = {978-3-642-45418-9},
keywords = {2012,ada,dblp,manual,programming-languages,reference},
number = {8339},
pages = {1--349},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Ada 2012 Reference Manual. Language and Standard Libraries}},
url = {http://dx.doi.org/10.1007/978-3-642-45419-6 http://link.springer.com/10.1007/978-3-642-45419-6},
% volume = {8339},
year = {2013}
}

@inproceedings{Clebsch2015,
abstract = {Combining the actor-model with shared memory for performance is efficient but can introduce data-races. Existing approaches to static data-race freedom are based on uniqueness and immutability, but lack flexibility and high performance implementations. Our approach, based on deny properties, allows reading, writing and traversing unique references, introduces a new form of write uniqueness, and guarantees atomic behaviours.},
address = {New York, New York, USA},
author = {Clebsch, Sylvan and Drossopoulou, Sophia and Blessing, Sebastian and McNeil, Andy},
booktitle = {Proceedings of the 5th International Workshop on Programming Based on Actors, Agents, and Decentralized Control - AGERE! 2015},
doi = {10.1145/2824815.2824816},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Clebsch et al. - 2015 - Deny capabilities for safe, fast actors.pdf:pdf},
isbn = {9781450339018},
keywords = {Actors,Capabilities,Concurrency,Message passing,Type systems},
pages = {1--12},
publisher = {ACM Press},
title = {{Deny capabilities for safe, fast actors}},
url = {http://dl.acm.org/citation.cfm?doid=2824815.2824816},
year = {2015}
}
@article{Clebsch2017,
abstract = {Orca is a concurrent and parallel garbage collector for actor programs, which does not require any stop-the-world steps, or synchronisation mechanisms, and which has been designed to support zero-copy message passing and sharing of mutable data. Orca is part of the runtime of the actor-based language Pony. Pony's runtime was co-designed with the Pony language. This co-design allowed us to exploit certain language properties in order to optimise performance of garbage collection. Namely, Orca relies on the absence of race conditions in order to avoid read/write barriers, and it leverages actor message passing for synchronisation among actors. This paper describes Pony, its type system, and the Orca garbage collection algorithm. An evaluation of the performance of Orca suggests that it is fast and scalable for idiomatic workloads. 1 INTRODUCTION Pony is an object-oriented programming language designed from the ground up to support low-latency, highly concurrent applications written in the actor model of computation (Hewitt et al. 1973). The impetus for a new language comes from the authors' experience with the requirements of fnancial applications, namely a need for i) scalable concurrency, from tens to thousands of concurrent components; ii) performance approaching that of low-level languages; and iii) ease of development and rapid prototyping. Alternatives such as Erlang and Java were considered but performance was felt to be inadequate for the former, and pauses due to garbage collection were a stumbling block for adoption of the latter. This paper introduces Orca, Pony's concurrent garbage collection algorithm. Orca stands for Ownership and Reference Counting-based Garbage Collection in the Actor World. It was co-designed with the language's type system to allow actors to share mutable objects and to reclaim memory without any form of synchronisation between actors. Orca's core design principle},
author = {Clebsch, Sylvan and Franco, Juliana and Drossopoulou, Sophia and Yang, Albert Mingkun and Wrigstad, Tobias and Vitek, Jan},
doi = {10.1145/3133896},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Clebsch et al. - 2017 - Orca GC and type system co-design for actor languages.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {actors, messages},
number = {OOPSLA},
pages = {1--28},
title = {{Orca: GC and type system co-design for actor languages}},
volume = {1},
year = {2017}
}

@incollection{Panangaden1997,
abstract = {Concurrent ML (CML) is a programming language that integrates high-level abstraction mechanisms with concurrency primitives. Like other similar, recent languages, CML embodies the idea that concurrent programming can be done in a modern high-level language like ML. The fundamental new ingredient is the notion of a (polymorphic) event. This is a piece of code packaged as a new abstraction. Combinators are provided to build new events from old ones. The key subtlety is the interaction of external choice with abstraction. Ordinary functional abstraction conceals the communication actions on which choices need to be made. The event mechanism allows one to build abstractions that expose the communication. The language CML features mobility, polymorphism, and ordinary lambda-abstraction as well as events. In this article we discuss the basic features and explain how CML can be used to implement new concurrent abstractions.},
address = {New York, NY},
author = {Panangaden, Prakash and Reppy, John},
booktitle = {ML with Concurrency: Design, Analysis, Implementation, and Application},
chapter = {Two},
doi = {10.1007/978-1-4612-2274-3_2},
editor = {Nielson, Flemming},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop//Panangaden, Reppy - 1997 - The Essence of Concurrent ML.pdf:pdf},
isbn = {978-1-4612-2274-3},
pages = {5--29},
publisher = {Springer New York},
title = {{The Essence of Concurrent ML}},
url = {http://link.springer.com/10.1007/978-1-4612-2274-3{\_}2 https://doi.org/10.1007/978-1-4612-2274-3{\_}2},
year = {1997}
}

@article{Vinoski2012,
abstract = {Developers use the open source Erlang programming language in domains such as telecommunications, database systems, and the Web due to its superior support for concurrency and reliability. Erlang applications comprise numerous processes-lightweight user-space threads-that communicate via message passing. This article focuses on Erlang's concurrency support and details an example 1D Poisson solver program. {\textcopyright} 2011 IEEE.},
author = {Vinoski, Steve},
doi = {10.1109/MCSE.2012.67},
file = {:D\:/jarak/Documents/Mendeley Desktop/Vinoski - 2012 - Concurrency and message passing in erlang.pdf:pdf},
issn = {1521-9615},
journal = {Computing in Science \& Engineering},
keywords = {applicative (functional) programming,concurrent languages,concurrent programming,distributed languages,parallel languages,programming paradigms,scientific computing},
% mendeley-groups = {PhD/FP/SLR},
month = {11},
number = {6},
pages = {24--34},
title = {{Concurrency and Message Passing in Erlang}},
url = {http://ieeexplore.ieee.org/document/6216341/},
volume = {14},
year = {2012}
}
