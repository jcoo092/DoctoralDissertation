%%%%%%%%%%%%%%%%%%%%%%%%%
%  Dynamic Programming  %
%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Gimelfarb1979,
author = {Gimel'farb, Georgy L.},
doi = {10.1007/BF01069335},
file = {:D$\backslash$:/jarak/Documents/Mendeley Desktop/Gimel'farb - 1979 - Symmetrical approach to the problem of automating stereoscopic measurements in photogrammetry.pdf:pdf},
% isbn = {9780080453705},
issn = {1573-8337},
journal = {Cybernetics},
% mendeley-groups = {PhD/Computer Vision/Stereo},
number = {2},
pages = {235--247},
title = {{Symmetrical approach to the problem of automating stereoscopic measurements in photogrammetry}},
url = {https://doi.org/10.1007/BF01069335},
volume = {15},
year = {1979}
}

@article{Ohta1985,
abstract = {This paper presents a stereo matching algorithm using the dynamic programming technique. The stereo matching problem, that is, obtaining a correspondence between right and left images, can be cast as a search problem. When a pair of stereo images is rectified, pairs of corresponding points can be searched for within the same scanlines. We call this search intra-scanline search. This intra-scanline search can be treated as the problem of finding a matching path on a two-dimensional (2D) search plane whose axes are the right and left scanlines. Vertically connected edges in the images provide consistency constraints across the 2D search planes. Inter-scanline search in a three-dimensional (3D) search space, which is a stack of the 2D search planes, is needed to utilize this constraint. Our stereo matching algorithm uses edge-delimited intervals as elements to be matched, and employs the above mentioned two searches: one is inter-scanline search for possible correspondences of connected edges in right and left images and the other is intra-scanline search for correspondences of edge-delimited intervals on each scanline pair. Dynamic programming is used for both searches which proceed simultaneously: the former supplies the consistency constraint to the latter while the latter supplies the matching score to the former. An interval-based similarity metric is used to compute the score. The algorithm has been tested with different types of images including urban aerial images, synthesized images, and block scenes, and its computational requirement has been discussed.},
author = {Ohta, Yuichi and Kanade, Takeo},
doi = {10.1109/TPAMI.1985.4767639},
file = {:D$\backslash$:/jarak/Documents/Mendeley Desktop/Ohta, Kanade - 1985 - Stereo by Intra- and Inter-Scanline Search Using Dynamic Programming.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Dynamic Programming Stereo},
% mendeley-groups = {PhD/Computer Vision/Stereo},
% mendeley-tags = {Dynamic Programming Stereo},
month = {3},
number = {2},
pages = {139--154},
title = {{Stereo by Intra- and Inter-Scanline Search Using Dynamic Programming}},
url = {http://ieeexplore.ieee.org/document/4767639/},
volume = {PAMI-7},
year = {1985}
}

@inproceedings{Salmen2009,
abstract = {Dynamic Programming (DP) is a popular and efficient method for calculating disparity maps from stereo images. It allows for meeting real-time constraints even on low-cost hardware. Therefore, it is frequently used in real-world applications, although more accurate algorithms exist. We present a refined DP stereo processing algorithm which is based on a standard implementation. However it is more flexible and shows increased performance. In particular, we introduce the idea of multi-path backtracking to exploit the information gained from DP more effectively. We show how to automatically tune all parameters of our approach offline by an evolutionary algorithm. The performance was assessed on benchmark data. The number of incorrect disparities was reduced by 40 {\%} compared to the DP reference implementation while the overall complexity increased only slightly.},
address = {Berlin, Heidelberg},
author = {Salmen, Jan and Schlipsing, Marc and Edelbrunner, Johann and Hegemann, Stefan and L{\"{u}}ke, Stefan},
booktitle = {Computer Analysis of Images and Patterns},
doi = {10.1007/978-3-642-03767-2_133},
editor = {Jiang, Xiaoyi and Petkov, Nicolai},
file = {:D$\backslash$:/jarak/Documents/Mendeley Desktop/Salmen et al. - 2009 - Real-Time Stereo Vision Making More Out of Dynamic Programming.pdf:pdf},
isbn = {978-3-642-03767-2},
% issn = {03029743},
% mendeley-groups = {PhD/Computer Vision/Stereo},
pages = {1096--1103},
publisher = {Springer Berlin Heidelberg},
title = {{Real-Time Stereo Vision: Making More Out of Dynamic Programming}},
url = {http://link.springer.com/10.1007/978-3-642-03767-2{\_}133},
volume = {5702 LNCS},
year = {2009}
}


%%%%%%%%%%%%%%%%%%%%%%%%%
%  Belief Propagation   %
%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Felzenszwalb2006,
abstract = {Markov random field models provide a robust and unified framework for early vision problems such as stereo and image restoration. Inference algorithms based on graph cuts and belief propagation have been found to yield accurate results, but despite recent advances are often too slow for practical use. In this paper we present some algorithmic techniques that substantially improve the running time of the loopy belief propagation approach. One of the techniques reduces the complexity of the inference algorithm to be linear rather than quadratic in the number of possible labels for each pixel, which is important for problems such as image restoration that have a large label set. Another technique speeds up and reduces the memory requirements of belief propagation on grid graphs. A third technique is a multi-grid method that makes it possible to obtain good results with a small fixed number of message passing iterations, independent of the size of the input images. Taken together these techniques speed up the standard algorithm by several orders of magnitude. In practice we obtain results that are as accurate as those of other global methods (e.g., using the Middlebury stereo benchmark) while being nearly as fast as purely local methods.},
author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
doi = {10.1007/s11263-006-7899-4},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, Huttenlocher - 2006 - Efficient Belief Propagation for Early Vision.pdf:pdf},
%isbn = {0-7695-2158-4},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {Belief propagation,Efficient algorithms,Image restoration,Markov random fields,Stereo},
month = {10},
number = {1},
pages = {41--54},
title = {{Efficient Belief Propagation for Early Vision}},
url = {http://link.springer.com/10.1007/s11263-006-7899-4},
volume = {70},
year = {2006}
}
@inproceedings{Yang2006,
abstract = {In this paper, we present a belief propagation based global algorithm that generates high quality results while maintaining real-time performance. To our knowledge, it is the first BP based global method that runs at real-time speed. Our efficiency performance gains mainly from the parallelism of graphics hardware, which leads to a 45 times speedup compared to the CPU implementation. To qualify the accurancy of our approach, the experimental results are evaluated on the Middlebury data sets, showing that our approach is among the best (ranked first in the new evaluation system) for all real-time approaches. In addition, since the running time of general BP is linear to the number of iterations, adopting a large number of iterations is not feasible for practical applications. Hence a novel approach is proposed to adaptively update pixel cost. Unlike general BP methods, the running time of our proposed algorithm dramatically converges.},
author = {Yang, Qingxiong and Wang, Liang and Yang, Ruigang and Wang, Shengnan and Liao, Miao and Nist{\'{e}}r, David},
booktitle = {BMVC 2006 - Proceedings of the British Machine Vision Conference 2006},
doi = {10.5244/c.20.101},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2006 - Real-time global stereo matching using hierarchical belief propagation.pdf:pdf},
isbn = {1-901725-32-4},
keywords = {Belief Propagation,belief propagation,computer vision,dense depth estimation,hierarchical clustering,image registration,real time image sequence,stereo vision},
pages = {989--998},
publisher = {British Machine Vision Association},
title = {{Real-time global stereo matching using hierarchical belief propagation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.184.7471 http://www.bmva.org/bmvc/2006/papers/324.html},
year = {2006}
}
@inproceedings{Yang2006a,
abstract = {In this paper, we formulate an algorithm for the stereo matching problem with careful handling of disparity, discontinuity and occlusion. The algorithm works with a global matching stereo model based on an energy-minimization framework. The global energy contains two terms, the data term and the smoothness term. The data term is first approximated by a color-weighted correlation, then refined in occluded and low-texture areas in a repeated application of a hierarchical loopy belief propagation algorithm. The experimental results are evaluated on the Middlebury data set, showing that our algorithm is the top performer. {\textcopyright} 2006 IEEE.},
address = {New York, NY, USA},
author = {Yang, Qingxiong and Wang, Liang and Yang, Ruigang and Stew{\'{e}}nius, Henrik and Nist{\'{e}}r, David},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2006.292},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qingxiong Yang et al. - 2006 - Stereo Matching with Color-Weighted Correlation, Hierachical Belief Propagation and Occlusion Handling.pdf:pdf},
isbn = {0769525970},
% issn = {10636919},
keywords = {Belief Propagation},
pages = {2347--2354},
% pmid = {19147877},
publisher = {IEEE},
title = {{Stereo matching with color-weighted correlation, hierarchical belief propagation and occlusion handling}},
url = {http://ieeexplore.ieee.org/document/1641041/},
volume = {2},
year = {2006}
}
@article{Xiang2012,
abstract = {In this paper, a global optimum stereo matching algorithm based on improved belief propagation is presented which is demonstrated to generate high quality results while maintaining real-time performance. These results are achieved using a foundation based on the hierarchical belief propagation architecture combined with a novel asymmetric occlusion handling model, as well as parallel graphical processing. Compared to the other real-time methods, the experimental results on Middlebury data show the efficiency of our approach. {\textcopyright} Springer-Verlag 2012.},
author = {Xiang, Xueqin and Zhang, Mingmin and Li, Guangxia and He, Yuyong and Pan, Zhigeng},
doi = {10.1007/s00138-011-0405-1},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiang et al. - 2012 - Real-time stereo matching based on fast belief propagation.pdf:pdf},
%isbn = {0013801104051},
issn = {09328092},
journal = {Machine Vision and Applications},
keywords = {Belief Propagation,Hierarchical belief propagation,Occlusion handling,Stereo matching},
month = {11},
number = {6},
pages = {1219--1227},
title = {{Real-time stereo matching based on fast belief propagation}},
url = {http://link.springer.com/10.1007/s00138-011-0405-1},
volume = {23},
year = {2012}
}
@article{Tan2017,
abstract = {Fully connected Markov random fields and conditional random fields have recently been shown to be advantageous in many early vision tasks being formulated as multi-labeling problems, such as stereo matching and image segmentation. The maximum posterior marginal (MPM) inference method in solving fully connected models uses a hybrid framework of mean-field (MF) method and a filtering like approach, and yields excellent results. In this paper, we extend this framework in several aspects. First, we provide an alternative inference method employing fractional belief propagation based method instead of MF. Second, we reformulate the MPM problem into a maximum a posterior (MAP) problem and provide efficient algorithms for solving this. Third, we extend the fully connected model into a multi-resolution approach. Finally, we propose an integral image based approach which makes it possible for efficiently integrating the local linear regression technique into this framework. Comparisons are carried out among different algorithms and different formulations to find the best combination. We demonstrate that the use of our multi-resolution approach with MAP formulation substantially outperforms the ordinary MF-based inference scheme.},
author = {Tan, Xiao and Sun, Changming and Shen, Fumin and Wong, Kwan-Yee K.},
doi = {10.1109/TIP.2017.2750406},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2017 - Connected Models for Early Vision.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
keywords = {Belief Propagation},
month = {12},
number = {12},
pages = {5994--6005},
title = {{Efficient Message Passing Methods With Fully Connected Models for Early Vision}},
url = {http://ieeexplore.ieee.org/document/8030105/},
volume = {26},
year = {2017}
}
@article{Liang2011,
abstract = {Loopy belief propagation (BP) is an effective solution for assigning labels to the nodes of a graphical model such as the Markov random field (MRF), but it requires high memory, bandwidth, and computational costs. Furthermore, the iterative, pixel-wise, and sequential operations of BP make it difficult to parallelize the computation. In this paper, we propose two techniques to address these issues. The first technique is a new message passing scheme named tile-based BP that reduces the memory and bandwidth to a fraction of the ordinary BP algorithms without performance degradation by splitting the MRF into many tiles and only storing the messages across the neighboring tiles. The tile-wise processing also enables data reuse and pipeline, resulting in efficient hardware implementation. The second technique is an O(L) fast message construction algorithm that exploits the properties of robust functions for parallelization. We apply these two techniques to a very large-scale integration circuit for stereo matching that generates high-resolution disparity maps in near real-time. We also implement the proposed schemes on graphics processing unit (GPU) which is four-time faster than standard BP on GPU. {\textcopyright} 2011 IEEE.},
author = {Liang, Chia Kai and Cheng, Chao Chung and Lai, Yen Chieh and Chen, Liang Gee and Chen, Homer H.},
doi = {10.1109/TCSVT.2011.2125570},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chia-Kai Liang et al. - 2011 - Hardware-Efficient Belief Propagation.pdf:pdf},
%isbn = {9781424439935},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Belief Propagation,Belief propagation,Markov random field,VLSI circuit design,embedded systems,energy minimization,general-purpose computation on GPU},
month = {5},
number = {5},
pages = {525--537},
title = {{Hardware-efficient belief propagation}},
url = {http://ieeexplore.ieee.org/document/5733391/},
volume = {21},
year = {2011}
}
@inproceedings{Perez2010,
abstract = {Tele-presence systems will enable participants to feel like they are physically together. In order to improve this feeling, these systems are starting to include depth estimation capabilities. A typical requirement for these systems includes high definition, good quality results and low latency. Benchmarks demonstrate that stereo-matching algorithms using Belief Propagation (BP) produce the best results. The execution time of the BP algorithm in a CPU cannot satisfy real-time requirements with high-definition images. GPU-based implementations of BP algorithms are only able to work in real-time with small-medium size images because the traffic with memory limits their applicability. The inherent parallelism of the BP algorithm makes FPGA-based solutions a good choice. However, even though the memory traffic of a commercial FPGA-based ASIC-prototyping board is high, it is still not enough to comply with realtime, high definition and good immersive feeling requirements. The work presented estimates depth maps in less than 40 milliseconds for high-definition images at 30fps with 80 disparity levels. The proposed double BP topology and the new data-cost estimation improve the overall classical BP performance while they reduce the memory traffic by about 21{\%}. Moreover, the adaptive message compression method and message distribution in memory reduce the number of memory accesses by more than 70{\%} with an almost negligible loss of performance. The total memory traffic reduction is about 90{\%}, demonstrating sufficient quality to be classified within the first 40 positions in the Middlebury ranking. {\textcopyright} 2010 Copyright SPIE - The International Society for Optical Engineering.},
author = {P{\'{e}}rez, J. and S{\'{a}}nchez, P. and Mart{\'{i}}nez, M.},
booktitle = {Three-Dimensional Image Processing (3DIP) and Applications},
doi = {10.1117/12.838352},
editor = {Baskurt, Atilla M.},
file = {:H$\backslash$:/2019/Papers/To read/Stereo matching/Belief propagation/P{\'{e}}rez, S{\'{a}}nchez, Mart{\'{i}}nez - 2010 - Memory efficient belief propagation for high-definition real-time stereo matching systems.pdf:pdf},
isbn = {9780819479198},
%issn = {0277786X},
keywords = {Belief Propagation},
month = {2},
number = {February 2010},
pages = {75260N},
title = {{Memory efficient belief propagation for high-definition real-time stereo matching systems}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.838352},
volume = {7526},
year = {2010}
}
@inproceedings{Balossino2007,
abstract = {The paper deals with the design and implementation of a stereo algorithm. Disparity map is formulated as a Markov Random Field with a new smoothness constraint depending not only on image derivatives, but also on segmentation results and gradient directions. With these constraints we force disparity continuity inside each segmented object, while its contours are well preserved. Moreover we have designed a modified version of Belief Propagation which gives the solution to the stereo matching problem: the optimization has remarkable improvements and especially with respect to message propagation, which is actually driven by segmentation and boundary knowledge. Preliminary results are presented both on synthetic and benchmark images to demonstrate the effectiveness of our method. {\textcopyright} 2007 IEEE.},
author = {Balossino, Nello and Lucenteforte, Maurizio and Piovano, Luca and Pettiti, Giuseppe and Spertino, Massimiliano},
booktitle = {14th International Conference on Image Analysis and Processing (ICIAP 2007)},
doi = {10.1109/ICIAP.2007.4362867},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Balossino et al. - 2007 - A New Stereo Algorithm Integrating Luminance, Gradient and Segmentation Informations in a Belief-Propagation F.pdf:pdf},
isbn = {0-7695-2877-5},
keywords = {Belief Propagation},
month = {9},
number = {Iciap},
pages = {757--762},
publisher = {IEEE},
title = {{A New Stereo Algorithm Integrating Luminance, Gradient and Segmentation Informations in a Belief-Propagation Framework}},
url = {http://ieeexplore.ieee.org/document/4362867/},
year = {2007}
}
@inproceedings{Yang2010,
abstract = {In this paper, we consider the problem of stereo matching using loopy belief propagation. Unlike previous methods which focus on the original spatial resolution, we hierarchically reduce the disparity search range. By fixing the number of disparity levels on the original resolution, our method solves the message updating problem in a time linear in the number of pixels contained in the image and requires only constant memory space. Specifically, for a 800 x 600 image with 300 disparities, our message updating method is about 30 x faster (1.5 second) than standard method, and requires only about 0.6{\%} memory (9 MB). Also, our algorithm lends itself to a parallel implementation. Our GPU implementation (NVIDIA Geforce 8800GTX) is about 10 x faster than our CPU implementation. Given the trend toward higher-resolution images, stereo matching using belief propagation with large number of disparity levels as efficient as the small ones makes our method future-proof. In addition to the computational and memory advantages, our method is straightforward to implement. {\textcopyright}2010 IEEE.},
author = {Yang, Qingxiong and Wang, Liang and Ahuja, Narendra},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539797},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Wang, Ahuja - 2010 - A constant-space belief propagation algorithm for stereo matching.pdf:pdf},
isbn = {9781424469840},
%issn = {10636919},
keywords = {Belief Propagation},
month = {6},
pages = {1458--1465},
publisher = {IEEE},
title = {{A constant-space belief propagation algorithm for stereo matching}},
url = {http://ieeexplore.ieee.org/document/5539797/},
year = {2010}
}
@phdthesis{Gong2011,
abstract = {Belief propagation based stereo matching algorithms are explored with the main focus on taking account of visibility constraints. This approach approximates the minimum energy solution on graphical models such as Markov Chains, or Markov Random Field (MRF) of disparities. Our approach exploits a symmetric Cyclopean matching model, which accounts for visibility conditions, to construct epipolar profiles which are close to the human perception. Unlike traditional asymmetric matching models, this model can construct disparity maps with respect to the left, right or Cyclopean reference frame, as well as a Cyclopean image of a 3D scene depicted in a stereo pair, simultaneously. We focused on both one-dimensional (1D), and two-dimensional (2D) belief propagation. 1D belief propagation has the advantage of fast computation, and low memory usage, but suffers matching errors due to the lack of vertical information. This algorithm was mapped to Graphics Processing Unit (GPU) using CUDA, to achieve real-time stereo. Our research also uncovered one hidden problem of non-unique solutions. Further research into this problem could lead to new ways to improve the matching accuracy. 2D belief propagation is more memory intensive, and has slower computation speed, but it can achieve high quality results using the powerful 2D message passing, where matching information is passed around the MRF, and decisions are made using all the image information.},
author = {Gong, Rui},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong - 2011 - Belief Propagation Based Stereo Matching with Due Account of Visibility Conditions.pdf:pdf},
keywords = {Belief Propagation},
school = {University of Auckland},
title = {{Belief Propagation Based Stereo Matching with Due Account of Visibility Conditions}},
type = {mastersthesis},
year = {2011}
}
@article{Sun2003,
abstract = {In this paper, we formulate the stereo matching problem as a Markov network consisting of three coupled Markov random fields (MRF's). These three MRF's model a smooth field for depth/disparity, a line process for depth discontinuity and a binary process for occlusion, respectively. After eliminating the line process and the binary process by introducing two robust functions, we obtain the maximum a posteriori (MAP) estimation in the Markov network by applying a Bayesian belief propagation (BP) algorithm. Furthermore, we extend our basic stereo model to incorporate other visual cues (e.g., image segmentation) that are not modeled in the three MRF's, and again obtain the MAP solu- tion. Experimental results demonstrate that our method outperforms the state-of-art stereo algorithms for most test cases.},
author = {Sun, Jian and Zheng, Nan Ning and Shum, Heung Yeung},
doi = {10.1109/TPAMI.2003.1206509},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Zheng, Shum - 2003 - Stereo matching using belief propagation.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Bayesian inference,Belief Propagation,Belief propagation,Markov network,Stereoscopic vision},
month = {7},
number = {7},
pages = {787--800},
title = {{Stereo matching using belief propagation}},
url = {http://ieeexplore.ieee.org/document/1206509/},
volume = {25},
year = {2003}
}

@inproceedings{Tappen2003,
abstract = {Recent stereo algorithms have achieved impressive results by modelling the disparity image as a Markov Random Field (MRF). An important component of an MRF-based approach is the inference algorithm used to find the most likely setting of each node in the MRF. Algorithms have been proposed which use Graph Cuts or Belief Propagation for inference. These stereo algorithms differ in both the inference algorithm used and the formulation of the MRF. It is unknown whether to attribute the responsibility for differences in performance to the MRF or the inference algorithm. We address this through controlled experiments by comparing the Belief Propagation algorithm and the Graph Cuts algorithm on the same MRF's, which have been created for calculating stereo disparities. We find that the labellings produced by the two algorithms are comparable. The solutions produced by Graph Cuts have a lower energy than those produced with Belief Propagation, but this does not necessarily lead to increased performance relative to the ground-truth.},
author = {Tappen, Marshall F. and Freeman, William T.},
booktitle = {Proceedings of the Ninth IEEE International Conference on Computer Vision},
doi = {10.1109/iccv.2003.1238444},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Tappen, Freeman - 2003 - Comparison of graph cuts with belief propagation for stereo, using identical MRF parameters.pdf:pdf},
isbn = {0-7695-1950-4},
keywords = {Belief Propagation,Graph Cuts},
pages = {900--906},
publisher = {IEEE},
title = {{Comparison of graph cuts with belief propagation for stereo, using identical MRF parameters}},
url = {http://ieeexplore.ieee.org/document/1238444/},
volume = {2},
year = {2003}
}

@article{Hazan2010,
abstract = {In this paper we treat both forms of probabilistic inference, estimating marginal probabilities of the joint distribution and finding the most probable assignment, through a unified message-passing algorithm architecture. We generalize the Belief Propagation (BP) algorithms of sum-product and max-product and tree-rewaighted (TRW) sum and max product algorithms (TRBP) and introduce a new set of convergent algorithms based on "convex-free-energy" and Linear-Programming (LP) relaxation as a zero-temprature of a convex-free-energy. The main idea of this work arises from taking a general perspective on the existing BP and TRBP algorithms while observing that they all are reductions from the basic optimization formula of {\$}f + \backslashsum{\_}i h{\_}i{\$} where the function {\$}f{\$} is an extended-valued, strictly convex but non-smooth and the functions {\$}h{\_}i{\$} are extended-valued functions (not necessarily convex). We use tools from convex duality to present the "primal-dual ascent" algorithm which is an extension of the Bregman successive projection scheme and is designed to handle optimization of the general type {\$}f + \backslashsum{\_}i h{\_}i{\$}. Mapping the fractional-free-energy variational principle to this framework introduces the "norm-product" message-passing. Special cases include sum-product and max-product (BP algorithms) and the TRBP algorithms. When the fractional-free-energy is set to be convex (convex-free-energy) the norm-product is globally convergent for estimating of marginal probabilities and for approximating the LP-relaxation. We also introduce another branch of the norm-product, the "convex-max-product". The convex-max-product is convergent (unlike max-product) and aims at solving the LP-relaxation.},
author = {Hazan, Tamir and Shashua, Amnon},
doi = {10.1109/TIT.2010.2079014},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Shashua - 2010 - Norm-Product Belief Propagation Primal-Dual Message-Passing for Approximate Inference.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Approximate inference,Belief Propagation,Bethe free energy,Bregman projection,Fenchel duality,Markov random fields (MRF),convex free energy,dual block ascent,graphical models,linear programming (LP) relaxation,max-product algorithm,maximum a posteriori probability (MAP) estimation,sum-product algorithm},
month = {12},
number = {12},
pages = {6294--6316},
publisher = {IEEE},
title = {{Norm-Product Belief Propagation: Primal-Dual Message-Passing for Approximate Inference}},
url = {http://ieeexplore.ieee.org/document/5625635/},
volume = {56},
year = {2010}
}
@article{Kolmogorov2015,
abstract = {We propose a new family of message passing techniques for MAP estimation in graphical models which we call {\{}$\backslash$em Sequential Reweighted Message Passing{\}} (SRMP). Special cases include well-known techniques such as {\{}$\backslash$em Min-Sum Diffusion{\}} (MSD) and a faster {\{}$\backslash$em Sequential Tree-Reweighted Message Passing{\}} (TRW-S). Importantly, our derivation is simpler than the original derivation of TRW-S, and does not involve a decomposition into trees. This allows easy generalizations. We present such a generalization for the case of higher-order graphical models, and test it on several real-world problems with promising results.},
author = {Kolmogorov, Vladimir},
doi = {10.1109/TPAMI.2014.2363465},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolmogorov - 2015 - A New Look at Reweighted Message Passing.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Belief Propagation,MAP estimation,graphical models,message passing algorithms},
month = {5},
number = {5},
pages = {919--930},
%publisher = {IEEE},
title = {{A New Look at Reweighted Message Passing}},
url = {http://ieeexplore.ieee.org/document/6926846/},
volume = {37},
year = {2015}
}
@article{Ha2016,
abstract = {This study investigates the directed acyclic subgraph (DAS) algorithm, which is used to solve discrete labeling problems much more rapidly than other Markov-random-field-based inference methods but at a competitive accuracy. However, the mechanism by which the DAS algorithm simultaneously achieves competitive accuracy and fast execution speed, has not been elucidated by a theoretical derivation. We analyze the DAS algorithm by comparing it with a message passing algorithm. Graphical models, inference methods, and energy-minimization frameworks are compared between DAS and message passing algorithms. Moreover, the performances of DAS and other message passing methods [sum-product belief propagation (BP), max-product BP, and tree-reweighted message passing] are experimentally compared.},
author = {Ha, Jeongmok and Jeong, Hong},
doi = {10.1117/1.JEI.25.4.043016},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ha, Jeong - 2016 - Theoretic derivation of directed acyclic subgraph algorithm and comparisons with message passing algorithm.pdf:pdf},
% isbn = {1017-9909},
issn = {1017-9909},
journal = {Journal of Electronic Imaging},
keywords = {17,18,2015,2016,23,Belief Propagation,accepted for publication feb,distributed learning and evaluation,large-scale traffic datasets,negative mining,paper 15912ss received dec,positive mining,published online mar,real-time vehicle detec-,sample selection,tion},
month = {7},
number = {4},
pages = {043016},
title = {{Theoretic derivation of directed acyclic subgraph algorithm and comparisons with message passing algorithm}},
url = {http://electronicimaging.spiedigitallibrary.org/article.aspx?doi=10.1117/1.JEI.25.4.043016},
volume = {25},
year = {2016}
}
@article{Gupta2012,
abstract = {In this paper, a new algorithm is presented to compute the disparity map from a stereo pair of images by using Belief Propagation (BP). While many algorithms have been proposed in recent years, the real-time computation of an accurate disparity map is still a challenging task. The computation time and run-time memory requirements are two very important factors for all real-time applications. The proposed algorithm divides the matching process into two steps; they are initial matching and disparity map refinement. Initial matching is performed by memory efficient hierarchical belief propagation algorithm that uses less than half memory at run-time and minimizes the energy function at much faster rate as compare to other hierarchical BP algorithms that makes it more suitable for real-time applications. Disparity map refinement uses a simple but very effective single-pass approach that improves the accuracy without affecting the computation cost. Experiments by using Middlebury dataset demonstrate that the performance of our algorithm is the best among other real-time stereo matching algorithms. {\textcopyright} 2012 Springer-Verlag London Limited.},
author = {Gupta, Raj Kumar and Cho, Siu Yeung},
doi = {10.1007/s00521-012-0831-7},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Cho - 2012 - Stereo correspondence using efficient hierarchical belief propagation.pdf:pdf},
issn = {09410643},
journal = {Neural Computing and Applications},
keywords = {Belief Propagation,Disparity map refinement,Hierarchical belief propagation,Stereo vision},
month = {10},
number = {7},
pages = {1585--1592},
title = {{Stereo correspondence using efficient hierarchical belief propagation}},
url = {http://link.springer.com/10.1007/s00521-012-0831-7},
volume = {21},
year = {2012}
}
@article{Scharstein2002,
abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms.},
author = {Scharstein, Daniel and Szeliski, Richard},
doi = {10.1023/A:1014573219977},
issn = {1573-1405},
journal = {International Journal of Computer Vision},
keywords = {Belief Propagation},
month = {4},
number = {1},
pages = {7--42},
title = {{A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms}},
url = {https://doi.org/10.1023/A:1014573219977},
volume = {47},
year = {2002}
}
@article{Pearl1982,
abstract = {This paper presents generalizations of Bayes likelihood-ratio updating rule which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables. The computational scheme proposed specifies a set of belief parameters, communication messages and updating rules which guarantee that the diffusion of updated beliefs is accomplished in a single pass and complies with the tenets of Bayes calculus.},
author = {Pearl, Judea},
%isbn = {0865760438},
issn = {19326203},
journal = {Proceedings of the AAAI National Conference on AI},
keywords = {Belief Propagation},
pages = {133--136},
title = {{Reverend Bayes on inference engines: A distributed hierarchical approach}},
% url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Reverend+Bayes+on+Inference+Engines{\#}0},
year = {1982}
}
@inproceedings{Yu2007,
abstract = {Belief Propagation (BP) has been successfully used to approximate the solutions of various Markov Random Field (MRF) formulated energy minimization problems. However, large MRFs require a significant amount of memory to store the intermediate belief messages. We observe that these messages have redundant information due to the imposed smoothness prior. In this paper, we study the feasibility of applying compression techniques to the messages in the min-sum/max-product BP algorithm with 1D labels to improve the memory efficiency and reduce the read/write bandwidth. We articulate properties that an efficient message representation should satisfy. We investigate two common compression schemes, predictive coding and linear transform coding (PCA), and then propose a novel Envelope Point Transform (EPT) method. Predictive coding is efficient and supports linear operations directly in the compressed domain, but it is only compatible with the L1 smoothness function. PCA has the disadvantage that it does not guarantee the preservation of the minimal label. EPT is not limited to L1 smoothness cost and allows a flexible quality vs. compression ratio tradeoff compared with predictive coding. Experiments on dense stereo reconstruction have shown that the predictive scheme and EPT can achieve 8x or more compression without significant loss of depth accuracy. {\textcopyright}2007 IEEE.},
author = {Yu, Tianli and Lin, Ruei-Sung and Super, Boaz and Tang, Bei},
booktitle = {2007 IEEE 11th International Conference on Computer Vision},
doi = {10.1109/ICCV.2007.4408905},
file = {:D$\backslash$:/jcoo092/OneDrive - The University of Auckland/Readings/Lit Review papers/Computer Vision/BP/Yu et al. - 2007 - Efficient message representations for belief propagation.pdf:pdf},
isbn = {978-1-4244-1630-1},
keywords = {Belief Propagation},
pages = {1--8},
publisher = {IEEE},
title = {{Efficient Message Representations for Belief Propagation}},
url = {http://ieeexplore.ieee.org/document/4408905/},
year = {2007}
}




%Semi-global matching
@inproceedings{Gong2015,
author = {Gong, Rui and Gimel'farb, Georgy L. and Delmas, Patrice},
booktitle = {2015 International Conference on Image and Vision Computing New Zealand (IVCNZ)},
doi = {10.1109/IVCNZ.2015.7761553},
file = {:D$\backslash$:/jarak/Documents/Gong, Gimel'farb, Delmas - 2015 - Semi-global stereo matching under large and spatially variant perceptive deviations.pdf:pdf},
isbn = {978-1-5090-0357-0},
% issn = {21512205},
month = {11},
number = {1},
pages = {1--6},
publisher = {IEEE},
title = {{Semi-global stereo matching under large and spatially variant perceptive deviations}},
url = {http://ieeexplore.ieee.org/document/7761553/},
volume = {2016-Novem},
year = {2015}
}
@inproceedings{Gong2013a,
address = {Wellington, New Zealand},
author = {Gong, Rui and Gimel'farb, Georgy L. and Nicolescu, Radu and Delmas, Patrice},
booktitle = {2013 28th International Conference on Image and Vision Computing New Zealand (IVCNZ 2013)},
doi = {10.1109/IVCNZ.2013.6726998},
file = {:D$\backslash$:/jarak/Documents/Gong et al. - 2013 - Towards structural analysis of solution spaces for ill-posed discrete 1D optimisation problems(2).pdf:pdf},
isbn = {978-1-4799-0883-7},
% issn = {21512191},
month = {11},
pages = {94--99},
publisher = {IEEE},
title = {{Towards structural analysis of solution spaces for ill-posed discrete 1D optimisation problems}},
url = {http://ieeexplore.ieee.org/document/6726998/},
year = {2013}
}
@article{Hamzah2016b,
abstract = {This paper presents a literature survey on existing disparity map algorithms. It focuses on four main stages of processing as proposed by Scharstein and Szeliski in a taxonomy and evaluation of dense two-frame stereo correspondence algorithms performed in 2002. To assist future researchers in developing their own stereo matching algorithms, a summary of the existing algorithms developed for every stage of processing is also provided. The survey also notes the implementation of previous software-based and hardware-based algorithms. Generally, the main processing module for a software-based implementation uses only a central processing unit. By contrast, a hardware-based implementation requires one or more additional processors for its processing module, such as graphical processing unit or a field programmable gate array. This literature survey also presents a method of qualitative measurement that is widely used by researchers in the area of stereo vision disparity mappings.},
author = {Hamzah, Rostam Affendi and Ibrahim, Haidi},
doi = {10.1155/2016/8742920},
file = {:D$\backslash$:/jarak/Documents/Hamzah, Ibrahim - 2016 - Literature Survey on Stereo Vision Disparity Map Algorithms.pdf:pdf},
issn = {1687-725X},
journal = {Journal of Sensors},
pages = {1--23},
publisher = {Hindawi Publishing Corporation},
title = {{Literature Survey on Stereo Vision Disparity Map Algorithms}},
url = {http://www.hindawi.com/journals/js/2016/8742920/},
volume = {2016},
year = {2016}
}
@collection{Blake2011,
abstract = {This volume demonstrates the power of the Markov random field (MRF) in vision, treating the MRF both as a tool for modeling image data and, utilizing recently developed algorithms, as a means of making inferences about images. These inferences concern underlying image and scene structure as well as solutions to such problems as image reconstruction, image segmentation, 3D vision, and object labeling. It offers key findings and state-of-the-art research on both algorithms and applications. After an introduction to the fundamental concepts used in MRFs, the book reviews some of the main algorithms for performing inference with MRFs; presents successful applications of MRFs, including segmentation, super-resolution, and image restoration, along with a comparison of various optimization methods; discusses advanced algorithmic topics; addresses limitations of the strong locality assumptions in the MRFs discussed in earlier chapters; and showcases applications that use MRFs in more complex ways, as components in bigger systems or with multiterm energy functions. The book will be an essential guide to current research on these powerful mathematical tools.},
address = {Cambridge, Mass.},
doi = {10.7551/mitpress/8579.001.0001},
editor = {Blake, Andrew and Kohli, Pushmeet and Rother, Carsten},
isbn = {9780262298353},
keywords = {Computer graphics -- Mathematics,Computer vision -- Mathematics,Electronic books,Image processing -- Mathematics,Markov random fields},
publisher = {The MIT Press},
title = {{Markov Random Fields for Vision and Image Processing}},
url = {https://direct.mit.edu/books/book/2128/markov-random-fields-for-vision-and-image},
year = {2011}
}
@article{Tippetts2016,
abstract = {A significant amount of research in the field of stereo vision has been published in the past decade. Considerable progress has been made in improving accuracy of results as well as achieving real-time performance in obtaining those results. This work provides a comprehensive review of stereo vision algorithms with specific emphasis on real-time performance to identify those suitable for resource-limited systems. An attempt has been made to compile and present accuracy and runtime performance data for all stereo vision algorithms developed in the past decade. Algorithms are grouped into three categories: (1) those that have published results of real-time or near real-time performance on standard processors, (2) those that have real-time performance on specialized hardware (i.e. GPU, FPGA, DSP, ASIC), and (3) those that have not been shown to obtain near real-time performance. This review is intended to aid those seeking algorithms suitable for real-time implementation on resource-limited systems, and to encourage further research and development of the same by providing a snapshot of the status quo.},
author = {Tippetts, Beau and Lee, Dah Jye and Lillywhite, Kirt and Archibald, James},
doi = {10.1007/s11554-012-0313-2},
file = {:D$\backslash$:/jarak/Documents/Tippetts et al. - 2016 - Review of stereo vision algorithms and their suitability for resource-limited systems.pdf:pdf},
isbn = {1861-8200},
issn = {1861-8200},
journal = {Journal of Real-Time Image Processing},
month = {1},
number = {1},
pages = {5--25},
publisher = {Springer-Verlag},
title = {{Review of stereo vision algorithms and their suitability for resource-limited systems}},
url = {http://dx.doi.org/10.1007/s11554-012-0313-2 http://link.springer.com/10.1007/s11554-012-0313-2},
volume = {11},
year = {2016}
}

%%%%%%%%%%%%%%%%%%%%%%%%%
%   Miscellaneous       %
%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Geman1984,
abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (“annealing”) or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel “relaxation” algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios. {\textcopyright} 1984, IEEE.},
author = {Geman, Stuart and Geman, Donald},
doi = {10.1109/TPAMI.1984.4767596},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Annealing,Gibbs distribution,MAP estimate,Markov random field,image restoration,line process,relaxation scene modeling,spatial degradation},
month = {11},
number = {6},
pages = {721--741},
title = {{Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images}},
url = {http://ieeexplore.ieee.org/document/4767596/},
volume = {PAMI-6},
year = {1984}
}

@book{Gimelfarb1999,
abstract = {This book presents novel techniques for describing image textures. Contrary to the usual practice of embedding the images to known modelling frameworks borrowed from statistical physics or other domains, this book deduces the Gibbs models from basic image features and tailors the modelling framework to the images. This approach results in more general Gibbs models than can be either Markovian or non-Markovian and possess arbitrary interaction structures and strengths. The book presents computationally feasible algorithms for parameter estimation and image simulation and demonstrates their abilities and limitations by numerous experimental results. The book avoids too abstract mathematical constructions and gives explicit image-based explanations of all the notions involved. Audience: The book can be read by both specialists and graduate students in computer science and electrical engineering who take an interest in texture analysis and synthesis. Also, the book may be interesting to specialists and graduate students in applied mathematics who explore random fields. Instead of introduction -- 1 Texture, Structure, and Pairwise Interactions -- 1.1 Human and computational views -- 1.2 Spatial homogeneity, or self-similarity of textures -- 1.3 Basic notation and notions -- 1.4 Random fields and probabilistic image modelling -- 1.5 Physics and image modelling: what an interaction means -- 1.6 GPDs and exponential families of distributions -- 1.7 Stochastic relaxation and stochastic approximation -- 2 Markov and Non-Markov Gibbs Image Models -- 2.1 Traditional Markov/Gibbs image models -- 2.2 Generalized Gibbs models of homogeneous textures -- 2.3 Prior Markov/Gibbs models of region maps -- 2.4 Piecewise-homogeneous textures -- 2.5 Basic features of the models -- 3 Supervised MLE-Based Parameter Learning -- 3.1 Affine independence of sample histograms -- 3.2 MLE of Gibbs potentials -- 3.3 Analytic first approximation of potentials -- 3.4 Most characteristic interaction structure -- 3.5 Stochastic approximation to refine potentials -- 4 Supervised Conditional MLE-Based Learning -- 4.1 The least upper bound condition -- 4.2 Potentials in analytic form -- 4.3 Practical consistency of the MLEs -- 5 Experiments in Simulating Natural Textures -- 5.1 Comparison of natural and simulated textures -- 5.2 “Brodatz” image database -- 5.3 Interaction maps and texture features -- 5.4 CSA vs. traditional modelling scenario -- 5.5 “MIT VisTex” image database -- 6 Experiments in Retrieving Natural Textures -- 6.1 Query-by-image texture retrieval -- 6.2 Similarity under scale and orientation variations -- 6.3 Matching two textures -- 6.4 Experiments with natural textures -- 6.5 Complexity and practicality -- 7 Experiments in Segmenting Natural Textures -- 7.1 Initial and final segmentation -- 7.2 Artificial collages of Brodatz textures -- 7.3 Natural piecewise-homogeneous images -- 7.4 How to choose an interaction structure -- 7.5 Do Gibbs models learn what we expect? -- Texture Modelling: Theory vs. Heuristics -- References.},
address = {Dordrecht},
author = {Gimel'farb, Georgy L.},
doi = {10.1007/978-94-011-4461-2},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gimel'farb - 1999 - Image Textures and Gibbs Random Fields.pdf:pdf},
isbn = {978-94-010-5912-1},
pages = {251},
publisher = {Springer Netherlands},
series = {Computational Imaging and Vision},
title = {{Image Textures and Gibbs Random Fields}},
url = {http://link.springer.com/10.1007/978-94-011-4461-2},
volume = {16},
year = {1999}
}
@inproceedings{Yoon2005,
abstract = {In this paper, we present a new area-based method for visual correspondence search that focuses on the dissimilarity computation. Local and area-based matching methods generally measure the similarity (or dissimilarity) between the image pixels using local support windows. In this approach, an appropriate support window should be selected adaptively for each pixel to make the measure reliable and certain. Finding the optimal support window with an arbitrary shape and size is, however, very difficult and generally known as an NP-hard problem. For this reason,unlike the existing methods that try to find an optimal support window, we adjusted the support-weight of each pixel in a given support window. The adaptive support-weight of a pixel is computed based on the photometric and geometric relationship with the pixel under consideration. Dissimilarity is then computed using the raw matching costs and support-weights of both support windows, and the correspondence is finally selected by the WTA (Winner-Takes-All) method. The experimental results for the rectified real images show that the proposed method successfully produces piecewise smooth disparity maps while preserving sharp depth discontinuities accurately.},
author = {Yoon, Kuk Jin and Kweon, In So},
booktitle = {Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005},
doi = {10.1109/CVPR.2005.218},
isbn = {0769523722},
pages = {924--931},
publisher = {IEEE},
title = {{Locally adaptive support-weight approach for visual correspondence search}},
url = {http://ieeexplore.ieee.org/document/1467541/},
volume = {II},
year = {2005}
}
@article{Comaniciu2002,
abstract = {A general nonparametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure, the mean shift. We prove for discrete data the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators of location is also established. Algorithms for two low-level vision tasks, discontinuity preserving smoothing and image segmentation, are described as applications. In these algorithms, the only user set parameter is the resolution of the analysis and either gray level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.},
author = {Comaniciu, Dorin and Meer, Peter},
doi = {10.1109/34.1000236},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Clustering,Feature space,Image segmentation,Image smoothing,Low-level vision,Mean shift},
month = {5},
number = {5},
pages = {603--619},
title = {{Mean shift: a robust approach toward feature space analysis}},
url = {http://ieeexplore.ieee.org/document/1000236/},
volume = {24},
year = {2002}
}
@article{Yoon2006,
abstract = {We present a new window-based method for correspondence search using varying support-weights. We adjust the support-weights of the pixels in a given support window based on color similarity and geometric proximity to reduce the image ambiguity. Our method outperforms other local methods on standard stereo benchmarks. {\textcopyright} 2006 IEEE.},
author = {Yoon, Kuk Jin and Kweon, In So},
doi = {10.1109/TPAMI.2006.70},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D/stereo scene analysis,Stereo},
month = {4},
number = {4},
pages = {650--656},
title = {{Adaptive support-weight approach for correspondence search}},
url = {http://ieeexplore.ieee.org/document/1597121/},
volume = {28},
year = {2006}
}
@inproceedings{Tao2000,
abstract = {In this paper, we present a new analysis by synthesis computational framework for stereo vision. It is designed to achieve the following goals: (1) enforcing global visibility constraints, (2) obtaining reliable depth for depth boundaries and thin structures, (3) obtaining correct depth for textureless regions, and (4) hypothesizing correct depth for unmatched regions. The framework employs depth and visibility based rendering within a global matching criterion to compute depth in contrast with approaches that rely on local matching measures and relaxation. A color segmentation based depth representation guarantees smoothness in textureless regions. Hypothesizing depth from neighboring segments enables propagation of correct depth and produces reasonable depth values for unmatched region. A practical algorithm that integrates all these aspects is presented in this paper. Comparative experimental results are shown for real images. Results on new view rendering based on a single stereo pair are also demonstrated.},
author = {Tao, Hai and Sawhney, H. S.},
booktitle = {Proceedings of IEEE Workshop on Applications of Computer Vision},
doi = {10.1109/WACV.2000.895429},
isbn = {0769508138},
% issn = {21583986},
keywords = {Cameras,Computer vision,Data mining,Focusing,Image matching,Image segmentation,Layout,Rendering (computer graphics),Stereo vision,Surface fitting},
pages = {246--253},
publisher = {IEEE Comput. Soc},
title = {{Global matching criterion and color segmentation based stereo}},
url = {http://ieeexplore.ieee.org/document/895429/},
volume = {2000-Janua},
year = {2000}
}
@article{Birchfield1998,
abstract = {Because of image sampling, traditional measures of pixel dissimilarity can assign a large value to two corresponding pixels in a stereo pair, even in the absence of noise and other degrading effects. We propose a measure of dissimilarity that is provably insensitive to sampling because it uses the linearly interpolated intensity functions surrounding the pixels. Experiments on real images show that our measure alleviates the problem of sampling with little additional computational overhead.},
author = {Birchfield, Stan and Tomasi, Carlo},
doi = {10.1109/34.677269},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Birchfield, Tomasi - 1998 - A pixel dissimilarity measure that is insensitive to image sampling.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Correspondence,Dissimilarity,Stereo matching},
month = {4},
number = {4},
pages = {401--406},
title = {{A pixel dissimilarity measure that is insensitive to image sampling}},
url = {http://ieeexplore.ieee.org/document/677269/},
volume = {20},
year = {1998}
}
@inproceedings{Cooper2018,
abstract = {Many approaches to simplifying/enabling the use of parallelism in programming tasks exist. A substantial number of those concentrate solely either on data-parallelism or fork-join-based task-parallelism. Concurrent ML is an alternative approach based around the concept of lightweight individual sub-processes synchronously exchanging messages. This work explores the usefulness of the CML approach in image processing, by applying it to the basic median filter operation and contrasting it with other simple implementations. The results strongly suggest that it is a comparatively poor fit to such an operation, with the one slight advantage of apparently having better peak memory requirements. It is not clear, however, how efficient are either the algorithm implementation or the library it is based on.},
address = {Auckland, New Zealand},
author = {Cooper, James},
booktitle = {2018 International Conference on Image and Vision Computing New Zealand (IVCNZ)},
doi = {10.1109/IVCNZ.2018.8634712},
file = {:D$\backslash$:/Users/jcoo092/Writing/2018/IVCNZ18/Cooper - Concurrent ML as an Alternative Parallel Programming Style for Image Processing - 2018.pdf:pdf},
isbn = {978-1-7281-0125-5},
issn = {21512205},
keywords = {Concurrent ML,F{\#},Hopac,Image processing,Median filter},
month = {11},
publisher = {IEEE},
title = {{Concurrent ML as an Alternative Parallel Programming Style for Image Processing}},
url = {https://ieeexplore.ieee.org/document/8634712/},
year = {2018}
}
@article{Guo1989,
abstract = {Two parallel thinning algorithms are presented and evaluated in this article. The two algorithms use two-subiteration approaches: 1989 alternatively deleting north and east and then south and west boundary pixels and (2) alternately applying a thinning operator to one of two subfields. Image connectivities are proven to be preserved and the algorithms' speed and medial curve thinness are compared to other two-subiteration approaches and a fully parallel approach. Both approaches produce very thin medial curves and the second achieves the fastest overall parallel thinning. {\textcopyright} 1989, ACM. All rights reserved.},
author = {Guo, Zicheng and Hall, Richard W.},
doi = {10.1145/62065.62074},
issn = {15577317},
journal = {Communications of the ACM},
month = {3},
number = {3},
pages = {359--373},
title = {{Parallel Thinning with Two-Subiteration Algorithms}},
url = {http://portal.acm.org/citation.cfm?doid=62065.62074},
volume = {32},
year = {1989}
}

@inbook{Nixon2012,
abstract = {We shall define low-level features to be those basic features that can be extracted automatically from an image without any shape information (information about spatial relationships). As such, thresholding is actually a form of low-level feature extraction performed as a point operation. Naturally, all of these approaches can be used in high-level feature extraction, where we find shapes in images. It is well known that we can recognize people from caricaturists' portraits. That is the first low-level feature we shall encounter. It is called edge detection and it aims to produce a line drawing, something akin to a caricaturist's sketch, though without the exaggeration a caricaturist would imbue. There are very basic techniques and more advanced ones and we shall look at some of the most popular approaches. The first-order detectors are equivalent to first-order differentiation and, naturally, the second-order edge-detection operators are equivalent to a one-higher level of differentiation. An alternative form of edge detection is called phase congruency and we shall again see the frequency domain used to aid analysis, this time for low-level feature extraction. We shall also consider corner detection which can be thought of as detecting those points where lines bend very sharply with high curvature. These are another low-level feature that again can be extracted automatically from the image. These are largely techniques for localized feature extraction, in this case the curvature, and the more modern approaches extend to the detection of localized regions or patches of interest. Finally, we shall investigate a technique that describes motion, called optical flow. All of these can provide a set of points, albeit points with different properties, but all are suitable for grouping for shape extraction. Consider a square box moving through a sequence of images. The edges are the perimeter of the box; the corners are the apices; the flow is how the box moves. All these can be collected together to find the moving box. We shall start with the edge-detection techniques, with the first-order operators, which accord with the chronology of development. The first-order techniques date back by more than 30 years. Keywords Edge detection, first order, Roberts, Prewitt, Sobel, Canny, frequency domain, second order, Laplacian, Zero-crossing detection, Marr–Hildreth, Laplacian of Gaussian, difference of Gaussian, scale space, phase congruency, planar curvature, corners, curvature estimation, Harris corner detector, SIFT, SURF, Saliency, optical flow, aperture problem, differential, Horn and Schunk, correlation.},
address = {Oxford},
author = {Nixon, Mark S. and Aguado, Alberto S.},
booktitle = {Feature Extraction {\&} Image Processing for Computer Vision},
chapter = {Four},
doi = {10.1016/b978-0-12-396549-3.00004-5},
edition = {Third},
editor = {Nixon, Mark S and Aguado, Alberto S},
isbn = {978-0-12-396549-3},
pages = {137--216},
publisher = {Elsevier},
title = {{Low-level feature extraction (including edge detection)}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123965493000045 https://linkinghub.elsevier.com/retrieve/pii/B9780123965493000045},
year = {2012}
}

@book{Szeliski2011,
address = {London},
author = {Szeliski, Richard},
doi = {10.1007/978-1-84882-935-0},
editor = {Gries, David and Schneider, Fred B.},
file = {:D$\backslash$:/Users/jcoo092/Documents/Mendeley Desktop/Szeliski - 2011 - Computer Vision.pdf:pdf},
isbn = {978-1-84882-935-0},
pages = {823},
publisher = {Springer London},
series = {Texts in Computer Science},
title = {{Computer Vision}},
url = {http://link.springer.com/10.1007/978-1-84882-935-0},
volume = {42},
year = {2011}
}

@inproceedings{Liu2005,
abstract = {Conventional stereo correspondence algorithms which search for a ‘best' match are defeated by the many sources of noise possible in a pair of stereo images. We propose a new reconstruction paradigm, Concurrent Stereo Matching (CSM), that starts with a noise model and marks regions which could not be considered matches - given the noise model. The work presented here uses spatially varying noise values obtained empirically from segmented images. These noise levels determine admissable matches and define candidate surfaces, which are then processed using local constraints only to a final set of reconstructed surfaces. For a complex scene with many small surfaces, CSM ranks highly amongst existing benchmarked algorithms. The current CSM implementation does not handle large sloping surfaces well but work is underway to rectify this.},
address = {Queensland, Australia},
author = {Liu, Jiang and Delmas, P. and Gimel'farb, Georgy L. and Morris, J.},
booktitle = {Digital Image Computing: Techniques and Applications (DICTA'05)},
doi = {10.1109/dicta.2005.77},
file = {:D$\backslash$:/jarak/Documents/Mendeley Desktop//Jiang Liu et al. - 2006 - Stereo Reconstruction Using an Image Noise Model.pdf:pdf},
isbn = {0-7695-2467-2},
keywords = {Noise-driven Concurrent Stereo Matching},
pages = {69--69},
publisher = {IEEE},
title = {{Stereo Reconstruction Using an Image Noise Model}},
url = {http://ieeexplore.ieee.org/document/1587671/},
year = {2006}
}

@misc{bsmpcvpic,
author = "James Cooper",
title = "{Pictorial Representation of the Basic Stereo Matching Process in Computer Vision}",
year = "2020",
month = "8",
url = "https://auckland.figshare.com/articles/figure/Pictorial_Representation_of_the_Basic_Stereo_Matching_Process_in_Computer_Vision/12787604",
doi = "10.17608/k6.auckland.12787604.v1"
}

@misc{lbpmpsmpic,
author = "James Cooper",
title = "{Pictorial Representation of Loopy Belief Propagation Message Passing for Stereo Matching}",
year = "2020",
month = "8",
url = "https://auckland.figshare.com/articles/figure/Pictorial_Representation_of_Loopy_Belief_Propagation_Message_Passing_for_Stereo_Matching/12786815",
doi = "10.17608/k6.auckland.12786815.v1"
}

@inproceedings{Kolmogorov2001,
abstract = {Several new algorithms for visual correspondence based on graph cuts [7, 14, 17] have recently been developed. While these methods give very strong results in practice, they do not handle occlusions properly. Specifically, they treat the two input images asymmetrically, and they do not ensure that a pixel corresponds to at most one pixel in the other image. In this paper, we present a new method which properly addresses occlusions, while preserving the advantages of graph cut algorithms. We give experimental results for stereo as well as motion, which demonstrate that our method performs well both at detecting occlusions and computing disparities.},
author = {Kolmogorov, V. and Zabih, R.},
booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
doi = {10.1109/ICCV.2001.937668},
isbn = {0-7695-1143-0},
keywords = {Graph Cuts},
% mendeley-groups = {PhD/Computer Vision,PhD/Computer Vision/Stereo},
% mendeley-tags = {Graph Cuts},
pages = {508--515},
publisher = {IEEE Comput. Soc},
title = {{Computing visual correspondence with occlusions using graph cuts}},
url = {http://ieeexplore.ieee.org/document/937668/},
volume = {2},
year = {2001}
}
