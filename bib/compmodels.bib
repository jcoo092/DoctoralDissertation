@book{Varela2013,
abstract = {An introduction to fundamental theories of concurrent computation and associated programming languages for developing distributed and mobile computing systems. Starting from the premise that understanding the foundations of concurrent programming is key to developing distributed computing systems, this book first presents the fundamental theories of concurrent computing and then introduces the programming languages that help develop distributed computing systems at a high level of abstraction. The major theories of concurrent computation—including the $\pi$-calculus, the actor model, the join calculus, and mobile ambients—are explained with a focus on how they help design and reason about distributed and mobile computing systems. The book then presents programming languages that follow the theoretical models already described, including Pict, SALSA, and JoCaml. The parallel structure of the chapters in both part one (theory) and part two (practice) enable the reader not only to compare the different theories but also to see clearly how a programming language supports a theoretical model. The book is unique in bridging the gap between the theory and the practice of programming distributed computing systems. It can be used as a textbook for graduate and advanced undergraduate students in computer science or as a reference for researchers in the area of programming technology for distributed computing. By presenting theory first, the book allows readers to focus on the essential components of concurrency, distribution, and mobility without getting bogged down in syntactic details of specific programming languages. Once the theory is understood, the practical part of implementing a system in an actual programming language becomes much easier.},
address = {Cambridge, Mass.},
author = {Varela, Carlos A.},
isbn = {9780262018982},
pages = {296},
publisher = {MIT Press},
title = {{Programming Distributed Computing Systems : A Foundational Approach}},
% url = {https://mitpress.mit.edu/books/programming-distributed-computing-systems},
year = {2013}
}

@techreport{Asanovic2006,
abstract = {The recent switch to parallel microprocessors is a milestone in the history of computing. Industry has laid out a roadmap for multicore designs that preserves the programming paradigm of the past via binary compatibility and cache coherence. Conventional wisdom is now to double the number of cores on a chip with each silicon generation. A multidisciplinary group of Berkeley researchers met nearly two years to discuss this change. Our view is that this evolutionary approach to parallel hardware and software may work from 2 or 8 processor systems, but is likely to face diminishing returns as 16 and 32 processor systems are realized, just as returns fell with greater instruction-level parallelism. We believe that much can be learned by examining the success of parallelism at the extremes of the computing spectrum, namely embedded computing and high performance computing. This led us to frame the parallel landscape with seven questions, and to recommend the following: The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS per development dollar. Instead of traditional benchmarks, use 13 "Dwarfs" to design and evaluate parallel programming models and architectures. (A dwarf is an algorithmic method that captures a pattern of computation and communication.) "Autotuners" should play a larger role than conventional compilers in translating parallel programs. To maximize programmer productivity, future programming models must be more human-centric than the conventional focus on hardware or applications. To be successful, programming models should be independent of the number of processors. To maximize application efficiency, programming models should support a wide range of data types and successful models of parallelism: task-level parallelism, word-level parallelism, and bit-level parallelism. Architects should not include features that significantly affect performance or energy if programmers cannot accurately measure their impact via performance counters and energy counters. Traditional operating systems will be deconstructed and operating system functionality will be orchestrated using libraries and virtual machines. To explore the design space rapidly, use system emulators based on Field Programmable Gate Arrays (FPGAs) that are highly scalable and low cost. Since real world applications are naturally parallel and hardware is naturally parallel, what we need is a programming model, system software, and a supporting architecture that are naturally parallel. Researchers have the rare opportunity to re-invent these cornerstones of computing, provided they simplify the efficient programming of highly parallel systems.},
address = {Berkeley, CA},
author = {Asanovic, Krste and Bodik, Rastislav and Catanzaro, Bryan Christopher and Gebis, Joseph James and Husbands, Parry and Keutzer, Kurt and Patterson, David A. and Plishker, William Lester and Shalf, John and Williams, Samuel Webb and Yelick, Katherine},
file = {:C$\backslash$:/Users/jcoo092/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Asanovic et al. - 2006 - A view of the parallel computing landscape.pdf:pdf},
% institution = {University of California at Berkeley},
institution = {EECS Department, University of California, Berkeley},
month = {12},
pages = {56},
% publisher = {EECS Department, University of California, Berkeley},
title = {{A view of the parallel computing landscape}},
url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-183.html},
year = {2006}
}

@article{Gorlatch2004,
abstract = {During the software crisis of the 1960s, Dijkstra's famous thesis "goto considered harmful" paved the way for structured programming. This short communication suggests that many current difficulties of parallel programming based on message passing are caused by poorly structured communication, which is a consequence of using low-level send-receive primitives. We argue that, like goto in sequential programs, send-receive should be avoided as far as possible and replaced by collective operations in the setting of message passing. We dispute some widely held opinions about the apparent superiority of pairwise communication over collective communication and present substantial theoretical and empirical evidence to the contrary in the context of MPI (Message Passing Interface).},
author = {Gorlatch, Sergei},
doi = {10.1145/963778.963780},
file = {:D$\backslash$:/jcoo092/OneDrive - The University of Auckland/Readings/Lit Review papers/Concurrent ML/Gorlatch - 2004 - Send-Receive Considered Harmful Myths and Realities of Message Passing.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
keywords = {Message Passing Interface (MPI),Programming methodology},
month = {1},
number = {1},
pages = {47--56},
title = {{Send-Receive Considered Harmful: Myths and Realities of Message Passing}},
url = {http://portal.acm.org/citation.cfm?doid=963778.963780},
volume = {26},
year = {2004}
}

@incollection{Roscoe2011,
address = {Boston, MA},
author = {Roscoe, A. W. and Davies, Jim},
booktitle = {Encyclopedia of Parallel Computing},
doi = {10.1007/978-0-387-09766-4_2073},
pages = {341--341},
publisher = {Springer US},
title = {{Communicating Sequential Processes (CSP)}},
url = {http://link.springer.com/10.1007/978-0-387-09766-4{_}2073},
editor = {Padua, David},
year = {2011}
}

@book{Hoare1985,
abstract = {This book introduces a new mathematical approach to the study of concurrency and communication. Most suitable application of this new field is to the specification, design and implementation of computer systems which continuously act and interact with their environment.},
address = {Englewood Cliffs, N.J.},
author = {Hoare, Charles Antony Richard},
isbn = {0131532898},
keywords = {Communicating Sequential Processes,Computer programming,Parallel processing (Electronic computers)},
pages = {256},
publisher = {Prentice/Hall International},
series = {Prentice-Hall international series in computer science},
title = {{Communicating sequential processes}},
year = {1985}
}

@article{Milner1993,
author = {Milner, Robin},
doi = {10.1145/151233.151240},
file = {:D$\backslash$:/jarak/Documents/Milner - 1993 - Elements of Interaction Turing Award Lecture.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
keywords = {CCS,Communicating Sequential Processes,Pi Calculus,interaction,naming and reference,pi calculus,process algebra,process calculus,reduction rule},
month = {1},
number = {1},
pages = {78--89},
title = {{Elements of Interaction: Turing Award Lecture}},
url = {http://portal.acm.org/citation.cfm?doid=151233.151240},
volume = {36},
year = {1993}
}

@book{Agha1986,
address = {Cambridge, Mass.},
author = {Agha, Gul A},
isbn = {0262010925},
keywords = {Actors,Electronic data processing -- Distributed processi,Parallel processing (Electronic computers)},
publisher = {MIT Press},
series = {MIT Press series in artificial intelligence},
title = {{ACTORS : a model of concurrent computation in distributed systems}},
year = {1986}
}

@book{Padua2011,
abstract = {Containing over 300 entries in an A-Z format, the Encyclopedia of Parallel Computing provides easy, intuitive access to relevant information for professionals and researchers seeking access to any aspect within the broad field of parallel computing. Topics for this comprehensive reference were selected, written, and peer-reviewed by an international pool of distinguished researchers in the field. The Encyclopedia is broad in scope, covering machine organization, programming languages, algorithms, and applications. Within each area, concepts, designs, and specific implementations are presented. The highly-structured essays in this work comprise synonyms, a definition and discussion of the topic, bibliographies, and links to related literature. Extensive cross-references to other entries within the Encyclopedia support efficient, user-friendly searchers for immediate access to useful information. Key concepts presented in the Encyclopedia of Parallel Computing include; laws and metrics; specific numerical and non-numerical algorithms; asynchronous algorithms; libraries of subroutines; benchmark suites; applications; sequential consistency and cache coherency; machine classes such as clusters, shared-memory multiprocessors, special-purpose machines and dataflow machines; specific machines such as Cray supercomputers, IBM's cell processor and Intel's multicore machines; race detection and auto parallelization; parallel programming languages, synchronization primitives, collective operations, message passing libraries, checkpointing, and operating systems. Topics covered: Speedup, Efficiency, Isoefficiency, Redundancy, Amdahls law, Computer Architecture Concepts, Parallel Machine Designs, Benmarks, Parallel Programming concepts {\&} design, Algorithms, Parallel applications.{\&}160;This authoritative reference will be published in two formats: print and online. The online edition features hyperlinks to cross-references and to additional significant research. Related Subjects: supercomputing, high-performance computing, distributed computing},
address = {Boston, MA},
booktitle = {Encyclopedia of Parallel Computing},
doi = {10.1007/978-0-387-09766-4},
editor = {Padua, David},
isbn = {978-0-387-09765-7},
publisher = {Springer US},
title = {{Encyclopedia of Parallel Computing}},
url = {http://link.springer.com/10.1007/978-0-387-09766-4},
year = {2011}
}

@book{Milner1980,
address = {Berlin, Heidelberg},
author = {Milner, Robin},
doi = {10.1007/3-540-10235-3},
isbn = {978-3-540-10235-9},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Calculus of Communicating Systems}},
url = {http://link.springer.com/10.1007/3-540-10235-3},
volume = {92},
year = {1980}
}

@book{Barendregt1984,
abstract = {The revised edition contains a new chapter which provides an elegant description of the semantics. The various classes of lambda calculus models are described in a uniform manner. Some didactical improvements have been made to this edition. An example of a simple model is given and then the general theory (of categorical models) is developed. Indications are given of those parts of the book which can be used to form a coherent course.},
author = {Barendregt, Henk},
doi = {10.1016/C2009-0-14341-6},
isbn = {9780444875082},
pages = {1--621},
publisher = {Elsevier},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{The Lambda Calculus - Its Syntax and Semantics}},
url = {https://linkinghub.elsevier.com/retrieve/pii/C20090143416},
volume = {103},
year = {1984}
}

@online{Welsh2013,
author = {Welsh, Noel},
day = {4},
month = {3},
title = {{Why I Don't Like Akka Actors}},
url = {https://noelwelsh.com/posts/2013-03-04-why-i-dont-like-akka-actors.html},
urldate = {2021-01-06},
year = {2013}
}

@online{Stucchio2013,
abstract = {Don't use actors for concurrency. Instead, use actors for state and use futures for concurrency.},
author = {Stucchio, Chris},
day = {2},
month = {12},
title = {{Don't use Actors for concurrency}},
url = {https://www.chrisstucchio.com/blog/2013/actors_vs_futures.html},
urldate = {2021-01-06},
year = {2013}
}

@inproceedings{Hewitt1973,
abstract = {This paper proposes a modular ACTOR architecture and definitional method for artificial intelligence that is conceptually based on a single kind of object: actors [or, if you will, virtual processors, activation frames, or streams]. The formalism makes no presuppositions about the representation of primitive data structures and control structures. Such structures can be programmed, micro-coded, or hard wired in a uniform modular fashion. In fact it is impossible to determine whether a given object is "really" represented as a list, a vector, a hash table, a function, or a process. The architecture will efficiently run the coming generation of PLANNER-like artificial intelligence languages including those requiring a high degree of parallelism. The efficiency is gained without loss of programming generality because it only makes certain actors more efficient; it does not change their behavioral characteristics. The architecture is general with respect to control structure and does not have or need goto, interrupt, or semaphore primitives. The formalism achieves the goals that the disallowed constructs are intended to achieve by other more structured methods.},
address = {San Francisco, CA, USA},
author = {Hewitt, Carl and Bishop, Peter and Steiger, Richard},
booktitle = {Proceedings of the 3rd International Joint Conference on Artificial Intelligence},
pages = {235--245},
publisher = {Morgan Kaufmann Publishers Inc.},
series = {IJCAI'73},
title = {{A Universal Modular ACTOR Formalism for Artificial Intelligence}},
year = {1973}
}

@article{Petri2008,
abstract = {A Petri net is a graphical tool for the description and analysis of concurrent processes which arise in systems with many components(distributed systems). The graphics, together with the rules for their coarsening and refinement, were invented in August 1939 by the German Carl Adam Petri -- at the age of 13 -- for the purpose of describing chemical processes},
author = {Petri, Carl Adam and Reisig, Wolfgang},
doi = {10.4249/scholarpedia.6477},
journaltitle = {Scholarpedia},
number = {4},
pages = {6477},
title = {{Petri net}},
url = {http://www.scholarpedia.org/article/Petri_net},
version = {91647},
volume = {3},
year = {2008}
}

@inbook{Dennis2011,
abstract = {A Petri Net is a graph model for the control behavior of systems exhibiting concurrency in their operation. The graph is bipartite, the two node types being places drawn as circles, and transitions drawn as bars. The arcs of the graph are directed and run from places to transitions or vice versa. Each place may be empty, or hold a finite number of tokens. The state of a Petri net is the distribution of tokens on its places, called a marking of the net. A transition is enabled if each of its input places holds at least one token. Firing a transition means removing one token from each input place and adding one token to each output place. A run of a Petri net is any sequence of firings of enabled transitions; a run defines a sequence of markings. Because many transitions may be enabled in a state, there are often many possible distinct runs of a Petri net. Hence, a Petri net represents a kind of nondeterministic state machine, but in a convenient form for modeling and analyzing concurrent systems. Various extensions and generalizations of Petri nets have been found useful in applications.},
address = {Boston, MA},
author = {Dennis, Jack B.},
booktitle = {Encyclopedia of Parallel Computing},
doi = {10.1007/978-0-387-09766-4_134},
editor = {Padua, David},
isbn = {978-0-387-09766-4},
keywords = {Concurrency},
pages = {1525--1530},
publisher = {Springer US},
title = {{Petri Nets}},
url = {https://doi.org/10.1007/978-0-387-09766-4{_}134 http://link.springer.com/10.1007/978-0-387-09766-4{_}134},
year = {2011}
}

@inproceedings{Koopman2014,
abstract = {From the $\lambda$-calculus it is known how to represent (recursive) data structures by ordinary $\lambda$-terms. Based on this idea one can represent algebraic data types in a functional programming language by higher-order functions. Using this encoding we only have to im- plement functions to achieve an implementation of the functional language with data structures. In this paper we compare the famous Church encoding of data types with the less familiar Scott and Parigot encoding. We show that one can use the encoding of data types by functions in a Hindley-Milner typed language by adding a single constructor for each data type. In an untyped context, like an efficient implementation, this constructor can be omitted. By collecting the basic operations of a data type in a type constructor class and providing instances for the various encodings, these encodings can coexist in a single program. This shows the differences and similarities of the encodings clearly. By changing the instance of this class we can execute the same algorithm in a different encoding. We show that in the Church encoding selectors of constructors yielding the recursive type, like the tail of a list, have an undesir- able strictness in the spine of the data structure. The Scott encoding does not hamper lazy evaluation in any way. The evaluation of the recursive spine by the Church encoding makes the complexity of these destructors O(n). The same destructors in the Scott encoding requires only constant time. Moreover, the Church encoding has serious problems with graph reduction. The Parigot encoding combines the best of both worlds, but in practice this does not offer an advantage.},
address = {New York, NY, USA},
author = {Koopman, Pieter and Plasmeijer, Rinus and Jansen, Jan Martin},
booktitle = {Proceedings of the 26nd 2014 International Symposium on Implementation and Application of Functional Languages},
doi = {10.1145/2746325.2746330},
file = {:D\:/jarak/Documents/Mendeley Desktop/Koopman, Plasmeijer, Jansen - 2014 - Church Encoding of Data Types Considered Harmful for Implementations.pdf:pdf},
isbn = {9781450332842},
keywords = {Church numbers,Data types,Implementation,Parigot encoding,Scott encoding},
month = {10},
pages = {1--12},
publisher = {ACM},
title = {{Church Encoding of Data Types Considered Harmful for Implementations}},
url = {https://dl.acm.org/doi/10.1145/2746325.2746330},
% volume = {01-03-Octo},
year = {2014}
}

@article{Hinze2005,
abstract = {This pearl explains Church numerals, twice. The first explanation links Church numerals to Peano numerals via the well-known encoding of data types in the polymorphic $\lambda$-calculus. This view suggests that Church numerals are folds in disguise. The second explanation, which is more elaborate, but also more insightful, derives Church numerals from first principles, that is, from an algebraic specification of addition and multiplication. Additionally, we illustrate the use of the parametricity theorem by proving exponentiation as reverse application correct.},
author = {Hinze, Ralf},
doi = {10.1017/S0956796804005313},
file = {:D\:/jarak/Documents/Mendeley Desktop/Hinze - 2005 - Church numerals, twice!.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {1},
number = {1},
pages = {1--13},
title = {{Church numerals, twice!}},
url = {http://www.journals.cambridge.org/abstract_S0956796804005313},
volume = {15},
year = {2005}
}

@article{Korec1996,
abstract = {Several small universal register machines are constructed. The number of instructions vary from 32 to 14, depending on the chosen instruction base and the chosen notion of universality. The proof uses a special coding function for finite sequences of positive integers and some strong classical results concerning distribution of primes.},
author = {Korec, Ivan},
doi = {10.1016/S0304-3975(96)00080-1},
file = {:D\:/jarak/Documents/Mendeley Desktop/Korec - 1996 - Small universal register machines.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {11},
number = {2},
pages = {267--301},
title = {{Small universal register machines}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397596000801},
volume = {168},
year = {1996}
}

@article{Bernstein2016,
abstract = {Orleans provides a straightforward approach to building distributed interactive applications for the Cloud, without having to learn complex programming patterns for handling concurrency, fault tolerance, and resource management. Orleans was made available as open source in January 2015.},
author = {Bernstein, Philip A. and Bykov, Sergey},
doi = {10.1109/MIC.2016.108},
file = {:D\:/jarak/Documents/Mendeley Desktop/Bernstein, Bykov - 2016 - Developing Cloud Services Using the Orleans Virtual Actor Model.pdf:pdf},
issn = {1089-7801},
journal = {IEEE Internet Computing},
keywords = {Internet/Web technologies,Orleans,cloud computing,cloud services,scalable distributed computing,virtual actors},
month = {9},
number = {5},
pages = {71--75},
title = {{Developing Cloud Services Using the Orleans Virtual Actor Model}},
url = {https://ieeexplore.ieee.org/document/7676196/},
volume = {20},
year = {2016}
}

@inbook{McCool2012,
abstract = {This chapter describes the fork–join pattern and gives several examples, including its use to implement other patterns such as map, reduce, recurrence, and scan. Applied recursively, fork–join can generate a high degree of potential parallelism. This can, in turn, be efficiently scheduled onto actual parallelism mechanisms by the Cilk Plus and Intel Threading Building Blocks (TBB) work-stealing schedulers.},
author = {Michael McCool and Arch D. Robison and James Reinders},
booktitle = {Structured Parallel Programming},
booksubtitle = {Patterns for Efficient Computation},
chapter = {8},
doi = {10.1016/B978-0-12-415993-8.00008-6},
% editor = {Michael McCool and Arch D. Robison and James Reinders},
isbn = {978-0-12-415993-8},
location = {Boston},
pages = {209-251},
publisher = {Morgan Kaufmann},
title = {Fork–Join},
url = {https://www.sciencedirect.com/science/article/pii/B9780124159938000086},
year = {2012},
}

@book{Hughes2015,
abstract = {Having hit power limitations to even more aggressive out-of-order execution in processor cores, many architects in the past decade have turned to single-instruction-multiple-data (SIMD) execution to increase single-threaded performance. SIMD execution, or having a single instruction drive execution of an identical operation on multiple data items, was already well established as a technique to efficiently exploit data parallelism. Furthermore, support for it was already included in many commodity processors. However, in the past decade, SIMD execution has seen a dramatic increase in the set of applications using it, which has motivated big improvements in hardware support in mainstream microprocessors. The easiest way to provide a big performance boost to SIMD hardware is to make it wider -i.e., increase the number of data items hardware operates on simultaneously. Indeed, microprocessor vendors have done this. However, as we exploit more data parallelism in applications, certain challenges can negatively impact performance. In particular, conditional execution, non-contiguous memory accesses, and the presence of some dependences across data items are key roadblocks to achieving peak performance with SIMD execution. This book first describes data parallelism, and why it is so common in popular applications. We then describe SIMD execution, and explain where its performance and energy benefits come from compared to other techniques to exploit parallelism. Finally, we describe SIMD hardware support in current commodity microprocessors. This includes both expected design tradeoffs, as well as unexpected ones, as we work to overcome challenges encountered when trying to map real software to SIMD execution.},
author = {Hughes, Christopher J.},
doi = {10.2200/S00647ED1V01Y201505CAC032},
editor = {Martonosi, Margaret},
file = {:D\:/jarak/Documents/Mendeley Desktop/Hughes - 2015 - Single-instruction multiple-data execution.pdf:pdf},
isbn = {9781627057639},
% issn = {1935-3243},
keywords = {Autovectorization,Conflict detection,Control divergence,Data parallelism,Gather/scatter,Horizontal operations,Non-contiguous accesses,Permute,SIMD,Shuffle,Unaligned accesses,Vector masks,Vector processor,Vector reductions},
month = {5},
number = {32},
pagetotal = {121},
publisher = {Morgan \& Claypool},
series = {Synthesis Lectures on Computer Architecture},
title = {{Single-Instruction Multiple-Data execution}},
url = {http://www.morganclaypool.com/doi/10.2200/S00647ED1V01Y201505CAC032},
% volume = {32},
year = {2015}
}

@inbook{Terrell2018,
author = {Terrell, Riccardo},
booktitle = {Concurrency in .NET},
chapter = {3},
isbn = {9781617292996},
publisher = {Manning Publications},
title = {Functional Data Structures and Immutability},
year = {2018},
}

@book{Fokkink2013,
abstract = {A comprehensive guide to distributed algorithms that emphasizes examples and exercises rather than mathematical argumentation.This book offers students and researchers a guide to distributed algorithms that emphasizes examples and exercises rather than the intricacies of mathematical models. It avoids mathematical argumentation, often a stumbling block for students, teaching algorithmic thought rather than proofs and logic. This approach allows the student to learn a large number of algorithms within a relatively short span of time. Algorithms are explained through brief, informal descriptions, illuminating examples, and practical exercises. The examples and exercises allow readers to understand algorithms intuitively and from different perspectives. Proof sketches, arguing the correctness of an algorithm or explaining the idea behind fundamental results, are also included. An appendix offers pseudocode descriptions of many algorithms.Distributed algorithms are performed by a collecti},
address = {Cambridge, Massachusetts},
author = {Fokkink, Wan},
isbn = {9780262026772},
language = {English},
publisher = {The MIT Press},
series = {The MIT Press},
title = {{Distributed Algorithms : An Intuitive Approach}},
volume = {53},
year = {2013}
}

@incollection{Petricek2011,
abstract = {Modern challenges led to a design of a wide range of programming models for reactive, parallel and concurrent programming, but these are often difficult to encode in general purpose languages. We present an abstract type of computations called joinads together with a syntactic language extension that aims to make it easier to use joinads in modern functional languages. Our extension generalizes pattern matching to work on abstract computations. It keeps a familiar syntax and semantics of pattern matching making it easy to reason about code, even in a non-standard programming model. We demonstrate our extension using three important programming models - a reactive model based on events; a concurrent model based on join calculus and a parallel model using futures. All three models are implemented as libraries that benefit from our syntactic extension. This makes them easier to use and also opens space for exploring new useful programming models. {\textcopyright} 2011 Springer-Verlag.},
author = {Petricek, Tomas and Syme, Don},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-18378-2_17},
editor = {Rocha, Ricardo and Launchbury, John},
file = {:D\:/jarak/Documents/Mendeley Desktop/Petricek, Syme - 2011 - Joinads A Retargetable Control-Flow Construct for Reactive, Parallel and Concurrent Programming.pdf:pdf},
isbn = {9783642183775},
% issn = {03029743},
pages = {205--219},
title = {{Joinads: A Retargetable Control-Flow Construct for Reactive, Parallel and Concurrent Programming}},
url = {http://link.springer.com/10.1007/978-3-642-18378-2_17},
volume = {6539},
year = {2011}
}

@article{Petricek2012,
abstract = {Sequencing of effectful computations can be neatly captured using monads and elegantly written using do notation. In practice such monads often allow additional ways of composing computations, which have to be written explicitly using combinators. We identify joinads, an abstract notion of computation that is stronger than monads and captures many such ad-hoc extensions. In particular, joinads are monads with three additional operations: one of type m a → m b → m (a, b) captures various forms of parallel composition, one of type m a → m a → m a that is inspired by choice and one of type m a → m (m a) that captures aliasing of computations. Algebraically, the first two operations form a near-semiring with commutative multiplication. We introduce docase notation that can be viewed as a monadic version of case. Joinad laws imply various syntactic equivalences of programs written using docase that are analogous to equivalences about case. Examples of joinads that benefit from the notation include speculative parallelism, waiting for a combination of user interface events, but also encoding of validation rules using the intersection of parsers. Copyright {\textcopyright} 2011 ACM.},
author = {Petricek, Tomas and Mycroft, Alan and Syme, Don},
doi = {10.1145/2096148.2034677},
file = {:D\:/jarak/Documents/Mendeley Desktop/Petricek, Mycroft, Syme - 2012 - Extending monads with pattern matching.pdf:pdf},
isbn = {978-1-4503-0860-1},
issn = {15232867},
journal = {ACM SIGPLAN Notices},
month = {1},
number = {12},
pages = {1--12},
title = {{Extending monads with pattern matching}},
url = {http://dl.acm.org/citation.cfm?doid=2096148.2034677 https://dl.acm.org/doi/10.1145/2096148.2034677},
volume = {46},
year = {2011}
}

@article{Turon2012,
abstract = {Efficient communication and synchronization is crucial for finegrained parallelism. Libraries providing such features, while indispensable, are difficult to write, and often cannot be tailored or composed to meet the needs of specific users. We introduce reagents, a set of combinators for concisely expressing concurrency algorithms. Reagents scale as well as their hand-coded counterparts, while providing the composability existing libraries lack. {\textcopyright} 2012 ACM.},
% address = {Beijing, China},
author = {Turon, Aaron},
doi = {10.1145/2345156.2254084},
file = {:D\:/jarak/Documents/Mendeley Desktop/Turon - 2012 - Reagents.pdf:pdf},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Arrows,Compositional concurrency,Fine-grained concurrency,Join Calculus,Monads,Nonblocking algorithms},
month = {8},
number = {6},
pages = {157--168},
% publisher = {ACM},
title = {{Reagents}},
url = {http://doi.acm.org/10.1145/2345156.2254084%5Cnhttp://dl.acm.org/ft_gateway.cfm?id=2254084&type=pdf http://dl.acm.org/citation.cfm?doid=2345156.2254084 https://dl.acm.org/doi/10.1145/2345156.2254084},
volume = {47},
year = {2012}
}

@inproceedings{Fournet1996,
abstract = {By adding reflexion to the chemical machine of Berry and Boudol, we obtain a formal model of concurrency that is consistent with mobility and distribution. Our model provides the foundations of a programming language with functional and object-oriented features. It can also be seen as a process calculus, the join-calculus, which we prove equivalent to the $\pi$-calculus of Milner, Parrow and Walker.},
address = {New York, New York, USA},
author = {Fournet, C{\'{e}}dric and Gonthier, Georges},
booktitle = {Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '96},
doi = {10.1145/237721.237805},
file = {:D\:/jarak/Documents/Mendeley Desktop/Fournet, Gonthier - 1996 - The reflexive CHAM and the join-calculus.pdf:pdf},
isbn = {0897917693},
% issn = {07308566},
pages = {372--385},
publisher = {ACM Press},
title = {{The reflexive CHAM and the join-calculus}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:reflexive+chemical+abstract+machine+and+the+join+calculus#0 http://portal.acm.org/citation.cfm?doid=237721.237805},
year = {1996}
}

@incollection{Fournet2003,
abstract = {In these lecture notes, we give an overview of concurrent, distributed, and mobile programming using JoCaml. JoCaml is an extension of the Objective Caml language. It extends OCaml with support for concurrency and synchronization, the distributed execution of programs, and the dynamic relocation of active program fragments during execution. The programming model of JoCaml is based on the join calculus. This model is characterized by an explicit notion of locality, a strict adherence to local synchronization, and a natural embedding of functional programming {\`{a}} la ML. Local synchronization means that messages always travel to a set destination, and can interact only after they reach that destination; this is required for an efficient asynchronous implementation. Specifically, the join calculus uses ML's function bindings and pattern-matching on messages to express local synchronizations. The lectures and lab sessions illustrate how to use JoCaml to program concurrent and distributed applications in a much higher-level fashion than the traditional threads-and-locks approach. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
author = {Fournet, C{\'{e}}dric and {Le Fessant}, Fabrice and Maranget, Luc and Schmitt, Alan},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-44833-4_5},
editor = {Jeuring, Johan and Jones, Simon L. Peyton},
file = {:D\:/jarak/Documents/Mendeley Desktop/Fournet et al. - 2003 - JoCaml A Language for Concurrent Distributed and Mobile Programming.pdf:pdf},
% issn = {16113349},
pages = {129--158},
title = {{JoCaml: A Language for Concurrent Distributed and Mobile Programming}},
url = {http://link.springer.com/10.1007/978-3-540-44833-4_5},
volume = {2638},
year = {2003}
}

@incollection{Fournet2002,
abstract = {In these notes, we give an overview of the join calculus, its semantics, and its equational theory. The join calculus is a language that models distributed and mobile programming. It is characterized by an explicit notion of locality, a strict adherence to local synchronization, and a direct embedding of the ML programming language. The join calculus is used as the basis for several distributed languages and implementations, such as JoCaml and functional nets. Local synchronization means that messages always travel to a set destination, and can interact only after they reach that destination; this is required for an efficient implementation. Specifically, the join calculus uses ML's function bindings and pattern-matching on messages to program these synchronizations in a declarative manner. Formally, the language owes much to concurrency theory, which provides a strong basis for stating and proving the properties of asynchronous programs. Because of several remarkable identities, the theory of process equivalences admits simplifications when applied to the join calculus. We prove several of these identities, and argue that equivalences for the join calculus can be rationally organized into a five-tiered hierarchy, with some trade-off between expressiveness and proof techniques. We describe the mobility extensions of the core calculus, which allow the programming of agent creation and migration. We briefly present how the calculus has been extended to model distributed failures on the one hand, and cryptographic protocols on the other. {\textcopyright} Springer-Verlag Berlin Heidelberg 2002.},
author = {Fournet, C{\'{e}}dric and Gonthier, Georges},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-45699-6_6},
editor = {Barthe, Gilles and Dybjer, Peter and Pinto, Lu{\'i}s and Saraiva, Jo{\~a}o},
file = {:D\:/jarak/Documents/Mendeley Desktop/Fournet, Gonthier - 2002 - The Join Calculus A Language for Distributed Mobile Programming.pdf:pdf},
isbn = {3540440445},
% issn = {16113349},
pages = {268--332},
title = {{The Join Calculus: A Language for Distributed Mobile Programming}},
url = {http://www.springerlink.com/content/rytewy8h1d2arnpv/fulltext.pdf http://link.springer.com/10.1007/3-540-45699-6_6},
volume = {2395},
year = {2002}
}

@book{Lynch1996,
abstract = {In Distributed Algorithms, Nancy Lynch provides a blueprint for designing, implementing, and analyzing distributed algorithms. She directs her book at a wide audience, including students, programmers, system designers, and researchers. Distributed Algorithms contains the most significant algorithms and impossibility results in the area, all in a simple automata-theoretic setting. The algorithms are proved correct, and their complexity is analyzed according to precisely defined complexity measures. The problems covered include resource allocation, communication, consensus among distributed processes, data consistency, deadlock detection, leader election, global snapshots, and many others. The material is organized according to the system model-first by the timing model and then by the interprocess communication mechanism. The material on system models is isolated in separate chapters for easy reference. The presentation is completely rigorous, yet is intuitive enough for immediate comprehension. This book familiarizes readers with important problems, algorithms, and impossibility results in the area: readers can then recognize the problems when they arise in practice, apply the algorithms to solve them, and use the impossibility results to determine whether problems are unsolvable. The book also provides readers with the basic mathematical tools for designing new algorithms and proving new impossibility results. In addition, it teaches readers how to reason carefully about distributed algorithms-to model them formally, devise precise specifications for their required behavior, prove their correctness, and evaluate their performance with realistic measures. Table of Contents 1 Introduction 2 Modelling I; Synchronous Network Model 3 Leader Election in a Synchronous Ring 4 Algorithms in General Synchronous Networks 5 Distributed Consensus with Link Failures 6 Distributed Consensus with Process Failures 7 More Consensus Problems 8 Modelling II: Asynchronous System Model 9 Modelling III: Asynchronous Shared Memory Model 10 Mutual Exclusion 11 Resource Allocation 12 Consensus 13 Atomic Objects 14 Modelling IV: Asynchronous Network Model 15 Basic Asynchronous Network Algorithms 16 Synchronizers 17 Shared Memory versus Networks 18 Logical Time 19 Global Snapshots and Stable Properties 20 Network Resource Allocation 21 Asynchronous Networks with Process Failures 22 Data Link Protocols 23 Partially Synchronous System Models 24 Mutual Exclusion with Partial Synchrony 25 Consensus with Partial Synchrony},
address = {San Francisco, CA, USA},
author = {Lynch, Nancy A.},
isbn = {978-0-08-050470-4},
pages = {1--904},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Distributed Algorithms}},
year = {1996}
}

@book{Tel2000,
abstract = {Distributed algorithms have been the subject of intense development over the last twenty years. The second edition of this successful textbook provides an up-to-date introduction both to the topic, and to the theory behind the algorithms. The clear presentation makes the book suitable for advanced undergraduate or graduate courses, whilst the coverage is sufficiently deep to make it useful for practising engineers and researchers. The author concentrates on algorithms for the point-to-point message passing model, and includes algorithms for the implementation of computer communication networks. Other key areas discussed are algorithms for the control of distributed applications (wave, broadcast, election, termination detection, randomized algorithms for anonymous networks, snapshots, deadlock detection, synchronous systems), and fault-tolerance achievable by distributed algorithms. The two new chapters on sense of direction and failure detectors are state-of-the-art and will provide an entry to research in these still-developing topics.},
author = {Tel, Gerard},
% booktitle = {Introduction to Distributed Algorithms},
doi = {10.1017/CBO9781139168724},
edition = {2},
isbn = {9780521794831},
month = {9},
publisher = {Cambridge University Press},
title = {{Introduction to Distributed Algorithms}},
url = {https://www.cambridge.org/core/product/identifier/9781139168724/type/book},
year = {2000}
}

@inproceedings{Roscoe1995,
abstract = {We discuss the issues involved in modelling and verifying key-exchange protocols within the framework of CSP and its model-checking tool FDR. Expressing such protocols within a process algebra forces careful consideration of exception handling, and makes it natural to consider the closely connected issues of commitment and no-loss-of service. We argue that it is often better to specify key exchange mechanisms in the context of an enclosing system rather than in isolation.},
author = {Roscoe, A.W.},
booktitle = {Proceedings The Eighth IEEE Computer Security Foundations Workshop},
doi = {10.1109/CSFW.1995.518556},
file = {:D\:/jarak/Documents/Mendeley Desktop/Roscoe - 1995 - Modelling and verifying key-exchange protocols using CSP and FDR.pdf:pdf},
isbn = {0-8186-7033-9},
% issn = {10636900},
pages = {98--107},
publisher = {IEEE Comput. Soc. Press},
title = {{Modelling and verifying key-exchange protocols using CSP and FDR}},
url = {http://ieeexplore.ieee.org/document/518556/},
year = {1995}
}

@incollection{Lowe1996,
abstract = {In this paper we analyse the well known Needham-Schroeder Public-Key Protocol using FDR, a refinement checker for CSP. We use FDR to discover an attack upon the protocol, which allows an intruder to impersonate another agent. We adapt the protocol, and then use FDR to show that the new protocol is secure, at least for a small system. Finally we prove a result which tells us that if this small system is secure, then so is a system of arbitrary size.},
author = {Lowe, Gavin},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-61042-1_43},
editor = {Margaria, Tiziana and Steffen, Bernhard},
file = {:D\:/jarak/Documents/Mendeley Desktop/Lowe - 1996 - Breaking and fixing the Needham-Schroeder Public-Key Protocol using FDR.pdf:pdf},
isbn = {3540610421},
% issn = {16113349},
pages = {147--166},
title = {{Breaking and fixing the Needham-Schroeder Public-Key Protocol using FDR}},
url = {http://link.springer.com/10.1007/3-540-61042-1_43},
volume = {1055},
year = {1996}
}

@inproceedings{Koltuksuz2010,
abstract = {Communicating Sequential Processes (CSP) is a process algebra, designed for modeling and analyzing the behavior of concurrent systems. Several security protocols are modeled with CSP and verified using model-checking or theorem proving techniques successfully. Unlike other authentication protocols modeled using CSP, each of the Efficient Multi-chained Stream Signature (EMSS) protocol messages are linked to the previous messages, forming hash chains, which introduces difficulties for modeling and verification. In this paper; we model the EMSS stream authentication protocol using CSP and verify its authentication properties with model checking, by building an infinite state model of the protocol which is reduced into a finite state model. {\textcopyright} 2010 IEEE.},
author = {Koltuksuz, Ahmet and Ozkan, Murat and Kulahcioglu, Burcu},
booktitle = {2010 Fourth International Conference on Secure Software Integration and Reliability Improvement Companion},
doi = {10.1109/SSIRI-C.2010.23},
file = {:D\:/jarak/Documents/Mendeley Desktop/Koltuksuz, Ozkan, Kulahcioglu - 2010 - Modeling efficient multi-chained stream signature protocol using communicating sequential process.pdf:pdf},
isbn = {978-1-4244-7644-2},
keywords = {Communicating Sequential Processeses,Model checking,Security protocol verification},
month = {6},
pages = {54--61},
publisher = {IEEE},
title = {{Modeling Efficient Multi-chained Stream Signature Protocol Using Communicating Sequential Processes}},
url = {http://ieeexplore.ieee.org/document/5521561/},
year = {2010}
}

@book{Sun2016,
author = {Sun, Jun and Lai, Choi-Hong and Wu, Xiao-Jun},
% booktitle = {Particle Swarm Optimisation},
doi = {10.1201/b11579},
edition = {1},
isbn = {9780429105999},
month = {4},
publisher = {CRC Press},
title = {{Particle Swarm Optimisation}},
url = {https://www.taylorfrancis.com/books/9781439835777},
year = {2016}
}


@incollection{Deserable2012,
abstract = {The void propagation defines a long-range interaction in granular matter. We detail a logic scheme simulating the propagation and implemented in a 2d cellular automata applied to granular flow. The CA belongs to the family of lattice-grain automata (LGrA) with one particle per cell. We focus first on the influence of inertia, or memory effect, on the flow patterns. The propagative mode is presented afterwards: it implies that transition and timestep must be considered at two different time scales. Although a CA is usually driven by local, nearest-neighbor communications, it follows here that the timestep termination must be detected at each transition, that involves a perpetual and global communication within the network to synchronize the timestep. An all-to-all systolic gossiping underlies the framework of this void propagation model. {\textcopyright} 2012 Springer-Verlag Berlin Heidelberg.},
author = {D{\'{e}}s{\'{e}}rable, Dominique},
% booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-33350-7_3},
% isbn = {9783642333491},
% issn = {16113349},
keywords = {lattice-grain (cellular) automata (LGrA),memory effect,systolic gossiping,time evolution,timestep synchronization,void propagation},
pages = {20--31},
% publisher = {Springer},
title = {{Propagative Mode in a Lattice-Grain CA: Time Evolution and Timestep Synchronization}},
url = {http://link.springer.com/10.1007/978-3-642-33350-7_3},
volume = {7495},
year = {2012},
% author="D{\'e}s{\'e}rable, Dominique",
editor="Sirakoulis, Georgios Ch.
and Bandini, Stefania",
% title="Propagative Mode in a Lattice-Grain CA: Time Evolution and Timestep Synchronization",
booktitle="Cellular Automata",
% year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
% pages="20--31",
% abstract="The void propagation defines a long-range interaction in granular matter. We detail a logic scheme simulating the propagation and implemented in a 2d cellular automata applied to granular flow. The CA belongs to the family of ``lattice-grain'' automata (LGrA) with one particle per cell. We focus first on the influence of inertia, or ``memory effect'', on the flow patterns. The propagative mode is presented afterwards: it implies that transition and timestep must be considered at two different time scales. Although a CA is usually driven by local, nearest-neighbor communications, it follows here that the timestep termination must be detected at each transition, that involves a perpetual and global communication within the network to synchronize the timestep. An all-to-all ``systolic gossiping'' underlies the framework of this void propagation model.",
isbn="978-3-642-33350-7"
}

@phdthesis{Hollander2015,
abstract = {.},
author = {Hollander, Christopher D.},

pages = {1--132},
school = {University of Central Florida},
title = {{Information Propagation Algorithms for Consensus Formation in Decentralized Multi-Agent Systems}},
type = {phd},
url = {https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=2135&context=etd},
year = {2015}
}

% @article{Banatre1993,
%   title={Programming by multiset transformation},
%   author={Jean-Pierre Ban{\^a}tre and Daniel Le M{\'e}tayer},
%   journal={Communications of the ACM},
%   year={1993},
%   volume={36},
%   pages={98-111}
% }

@article{Banatre1993,
author = {Ban\^{a}tre, Jean-Pierre and Le M\'{e}tayer, Daniel},
title = {Programming by Multiset Transformation},
year = {1993},
% issue_date = {Jan. 1993},
% publisher = {Association for Computing Machinery},
% address = {New York, NY, USA},
volume = {36},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/151233.151242},
doi = {10.1145/151233.151242},
journal = {Commun. ACM},
month = {1},
pages = {98–111},
% numpages = {14},
keywords = {logical parallelism, nondeterminism, UNITY, locality, GAMMA, program construction}
}

% @inproceedings{Berry1989,
% author = {Berry, Gerard and Boudol, Gerard},
% title = {The Chemical Abstract Machine},
% year = {1989},
% isbn = {0897913434},
% publisher = {Association for Computing Machinery},
% address = {New York, NY, USA},
% url = {https://doi.org/10.1145/96709.96717},
% doi = {10.1145/96709.96717},
% abstract = {We introduce a new kind of abstract machine based on the chemical metaphor used in the Γ language of Ban\^{a}tre &amp; al. States of a machine are chemical solutions where floating molecules can interact according to reaction rules. Solutions can be stratified by encapsulating subsolutions within membranes that force reactions to occur locally. We illustrate the use of this model by describing the operational semantics of the TCCS and CCS process calculi. We also show how to extract a higher-order concurrent λ-calculus out of the basic concepts of the chemical abstract machine.},
% booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
% pages = {81–94},
% numpages = {14},
% location = {San Francisco, California, USA},
% series = {POPL '90}
% }

@article{Berry1992,
title = {The chemical abstract machine},
journal = {Theoretical Computer Science},
volume = {96},
number = {1},
pages = {217-248},
year = {1992},
issn = {0304-3975},
doi = {10.1016/0304-3975(92)90185-I},
url = {https://www.sciencedirect.com/science/article/pii/030439759290185I},
author = {Gérard Berry and Gérard Boudol},
abstract = {We introduce a new kind of abstract machine based on the chemical metaphor used in the Γ language of Banâtre and Le Métayer. States of a machine are chemical solutions where floating molecules can interact according to reaction rules. Solutions can be stratified by encapsulating subsolutions within membranes that force reactions to occur locally. We illustrate the use of this model by describing the operational semantics of the TCCS and CCS process calculi and of the fragment of Milner, Parrow and Walker's Calculus of Mobile Processes used by Milner to encode the lambda-calculus. We also give ideas on how to extract a higher-order concurrent λ-calculus out of the basic concepts of the chemical abstract machine.}
}

@article{Banatre1988,
title = {A parallel machine for multiset transformation and its programming style},
journal = {Future Generation Computer Systems},
volume = {4},
number = {2},
pages = {133-144},
year = {1988},
issn = {0167-739X},
doi = {10.1016/0167-739X(88)90012-X},
url = {https://www.sciencedirect.com/science/article/pii/0167739X8890012X},
author = {J.-P. Banâtre and A. Coutant and D. {Le Metayer}},
abstract = {One of the most challenging problems in the field of computing science today concerns the development of software for more and more powerful parallel machines. In order to tackle this issue we present a new paradigm for parallel processing; this model, called Γ, is based on the chemical reaction metaphor: the only data structure is the multiset and the computation can be seen as a succession of chemical reactions consuming elements of the multiset and producing new elements according to specific rules. We detail some examples showing the relevance of this model for AI applications. Furthermore, due to its lack of imperative features, this language can be very naturally implemented in a distributed way. We describe an implementation of Γ on a vector architecture. The advantages of this architecture is that it needs very simple processors (with two ports) and all the processors perform the same job. So we advocate the separation of the design of programs for massively parallel machines into two steps which can be verified in a formal way: the construction of a program with implicit parallelism (Γ-program) and its translation into a network of processes.}
}

@inbook{Cardelli2005,
   abstract = {We introduce a family of process calculi with dynamic nested membranes. In contrast to related calculi, including some developed for biological applications, active entities here are tightly coupled to membranes, and can perform interactions on both sides of a membrane. That is, computation happens on the membrane, not inside of it.},
   author = {Luca Cardelli},
%   city = {Berlin, Heidelberg},
   doi = {10.1007/978-3-540-25974-9_24},
   editor = {Vincent Danos and Vincent Schachter},
   isbn = {978-3-540-25974-9},
   booktitle = {Computational Methods in Systems Biology},
   pages = {257-278},
   publisher = {Springer Berlin Heidelberg},
   subtitle = {{Interactions of Biological Membranes}},
   title = {{Brane Calculi}},
   url = {http://link.springer.com/10.1007/978-3-540-25974-9_24},
   year = {2005},
}

@article{Danos2004,
   abstract = {A language of formal proteins, the κ-calculus, is introduced. Interactions are modeled at the domain level, bonds are represented by means of shared names, and reactions are required to satisfy a causality requirement of monotonicity. An example of a simplified signalling pathway is introduced to illustrate how standard biological events can be expressed in our protein language. A more comprehensive example, the lactose operon, is also developed, bringing some confidence in the formalism considered as a modeling language. Then a finer-grained concurrent model, the mκ-calculus, is considered, where interactions have to be at most binary. We show how to embed the coarser-grained language in the latter, a property which we call self-assembly. Finally we show how the finer-grained language can itself be encoded in π-calculus, a standard foundational language for concurrency theory.},
   author = {Vincent Danos and Cosimo Laneve},
   doi = {10.1016/j.tcs.2004.03.065},
   issn = {03043975},
   issue = {1},
   journal = {Theoretical Computer Science},
   month = {9},
   note = {Computational Systems Biology},
   pages = {69-110},
   title = {Formal molecular biology},
   volume = {325},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397504002336},
   year = {2004},
}

@incollection{Boudol1989,
abstract = {We introduce a calculus for concurrent and communicating processes, which is a direct and simple extension of the $\lambda$-calculus. The communication mechanism we use is that of Milner's calculus CCS: to communicate consists in synchronously sending and receiving a value through a shared port. Then the calculus is parameterized on a given set of port names, which are used in the two primitives for sending and receiving a value — as in the $\lambda$-calculus, a value can be any term. We use two parallel constructs: the first is interleaving, which does not allow communication between agents. The second, called cooperation, is a synchronizing construct which forces two agents to communicate on every port name. We show that the $\lambda$-calculus is a simple sub-calculus of ours: $\lambda$-abstraction is a particular case of reception (on a port named $\lambda$), and application is a particular case of cooperation.},
author = {Boudol, G{\'{e}}rard},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-50939-9_130},
editor = {D{\'{i}}az, J. and Orejas, F.},
file = {:D\:/jarak/Documents/Mendeley Desktop/Boudol - 1989 - Towards a lambda-calculus for concurrent and communicating systems.pdf:pdf},
isbn = {9783540509394},
% issn = {16113349},
pages = {149--161},
title = {{Towards a lambda-calculus for concurrent and communicating systems}},
url = {http://link.springer.com/10.1007/3-540-50939-9_130},
volume = {351},
year = {1989}
}


@incollection{Milner1991,
abstract = {In process algebras, bisimulation equivalence is typically defined directly in terms of the operational rules of action; it also has an alternative characterisation in terms of a simple modal logic (sometimes called Hennessy-Milner logic. This paper first defines two forms of bisimulation equivalence for the $\Pi$-calculus, a process algebra which allows dynamic reconfiguration among processes; it then explores a family of possible logics, with different modal operators. It is proven that two of these logics characterise the two bisimulation equivalences. Also, the relative expressive power of all the logics is exhibited as a lattice.},
author = {Milner, Robin and Parrow, Joachim and Walker, David},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-54430-5_80},
editor = {Baeten, J.C.M. and Groote, J.F.},
file = {:D\:/jarak/Documents/Mendeley Desktop/Milner, Parrow, Walker - 1991 - Modal logics for mobile processes.pdf:pdf},
isbn = {9783540544302},
% issn = {16113349},
pages = {45--60},
title = {{Modal logics for mobile processes}},
url = {http://link.springer.com/10.1007/3-540-54430-5_80},
volume = {527},
year = {1991}
}

@article{Unyapoth2001,
abstract = {This paper addresses the design and verification of infrastructure for mobile computation. In particular, we study language primitives for communication between mobile agents. They can be classified into two groups. At a low level there are location dependent primitives that require a programmer to know the current site of a mobile agent in order to communicate with it. At a high level there are location independent primitives that allow communication with a mobile agent irrespective of any migrations. Implementation of the high level requires delicate distributed infrastructure algorithms. In earlier work with Wojciechowski and Pierce we made the two levels precise as process calculi, allowing such algorithms to be expressed as encodings of the high level into the low level; we built NOMADIC PICT, a distributed programming language for experimenting with such encodings. In this paper we turn to semantics, giving a definition of the core language and proving correctness of an example infrastructure. This requires novel techniques: we develop equivalences that take migration into account, and reasoning principles for agents that are temporarily immobile (eg. waiting on a lock elsewhere in the system). {\textcopyright} 2001 ACM.},
% address = {New York, NY, USA},
author = {Unyapoth, Asis and Sewell, Peter},
doi = {10.1145/373243.360214},
issn = {03621340},
journal = {SIGPLAN Notices (ACM Special Interest Group on Programming Languages)},
month = {3},
number = {3},
pages = {116--127},
% publisher = {Association for Computing Machinery},
title = {{Nomadic pict: Correct communication infrastructure for mobile computation}},
url = {https://doi-org.ezproxy.auckland.ac.nz/10.1145/373243.360214 https://dl.acm.org/doi/10.1145/373243.360214},
volume = {36},
year = {2001}
}
